{"cells":[{"cell_type":"markdown","source":"# Word2Vec models comparison\n\nWe compare the different models of word2vec against different intrinsic word embeddings tasks.","metadata":{"tags":[],"cell_id":"00000-3e5dd85b-a83f-41e3-81ec-63465c987242"}},{"cell_type":"markdown","source":"### Import and load datasets","metadata":{"tags":[],"cell_id":"00001-1d47f6bc-3830-48d3-969f-6f724ac6e2ca"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-9e2b57be-6c76-439b-9f0e-24ee9215ace3"},"source":"# imports\n!pip install ray\nimport ray\nray.init()\n\n!pip install nltk\nimport nltk\nnltk.download('wordnet')\nimport glob\n!pip install tqdm\nfrom tqdm import tqdm\nimport pandas as pd\n!pip install gensim\nfrom gensim.models import KeyedVectors\nfrom gensim.models.word2vec import Word2Vec\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# load the files\ndef load_similarity_datasets():\n    \"\"\"Load all (13) datasets which can be used to test word interchangeable similarity\n    \"\"\"\n    sim_data = {}\n    for file_path in glob.glob(\"../data/word-sim/*\"):\n        file_name = file_path[17:].replace(\".txt\", \"\")\n        print(file_name)\n        try:\n            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n            df.columns = ['word_1', 'word_2', 'similarity_score']\n        except:\n            df = pd.read_csv(file_path, sep=\" \", header=None)\n            df.columns = ['word_1', 'word_2', 'similarity_score']\n        sim_data[file_name] = df\n    return sim_data\n\n# load similarity datasets\nsimilarity_datasets = load_similarity_datasets()","execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ray\n  Downloading ray-0.8.7-cp37-cp37m-manylinux1_x86_64.whl (22.0 MB)\n\u001b[K     |████████████████████████████████| 22.0 MB 3.0 MB/s eta 0:00:01    |████▊                           | 3.3 MB 3.0 MB/s eta 0:00:07\n\u001b[?25hCollecting pyyaml\n  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n\u001b[K     |████████████████████████████████| 269 kB 74.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.16 in /opt/venv/lib/python3.7/site-packages (from ray) (1.18.5)\nCollecting colorful\n  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n\u001b[K     |████████████████████████████████| 201 kB 61.0 MB/s eta 0:00:01\n\u001b[?25hCollecting msgpack<2.0.0,>=1.0.0\n  Downloading msgpack-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (275 kB)\n\u001b[K     |████████████████████████████████| 275 kB 59.7 MB/s eta 0:00:01\n\u001b[?25hCollecting redis<3.5.0,>=3.3.2\n  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)\n\u001b[K     |████████████████████████████████| 71 kB 10.5 MB/s eta 0:00:01\n\u001b[?25hCollecting colorama\n  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\nCollecting py-spy>=0.2.0\n  Downloading py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 55.2 MB/s eta 0:00:01\n\u001b[?25hCollecting gpustat\n  Downloading gpustat-0.6.0.tar.gz (78 kB)\n\u001b[K     |████████████████████████████████| 78 kB 8.7 MB/s  eta 0:00:01\n\u001b[?25hCollecting google\n  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n\u001b[K     |████████████████████████████████| 45 kB 4.3 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/venv/lib/python3.7/site-packages (from ray) (3.12.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from ray) (0.8.0)\nCollecting aiohttp\n  Downloading aiohttp-3.6.2-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n\u001b[K     |████████████████████████████████| 1.2 MB 56.0 MB/s eta 0:00:01\n\u001b[?25hCollecting opencensus\n  Downloading opencensus-0.7.10-py2.py3-none-any.whl (126 kB)\n\u001b[K     |████████████████████████████████| 126 kB 75.6 MB/s eta 0:00:01\n\u001b[?25hCollecting filelock\n  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from ray) (2.24.0)\nRequirement already satisfied: grpcio>=1.28.1 in /opt/venv/lib/python3.7/site-packages (from ray) (1.31.0)\nRequirement already satisfied: jsonschema in /opt/venv/lib/python3.7/site-packages (from ray) (3.2.0)\nCollecting click>=7.0\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n\u001b[K     |████████████████████████████████| 82 kB 1.6 MB/s  eta 0:00:01\n\u001b[?25hCollecting aioredis\n  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 5.4 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.7 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray) (1.15.0)\nCollecting nvidia-ml-py3>=7.352.0\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\nCollecting psutil\n  Downloading psutil-5.7.2.tar.gz (460 kB)\n\u001b[K     |████████████████████████████████| 460 kB 45.2 MB/s eta 0:00:01\n\u001b[?25hCollecting blessings>=1.6\n  Downloading blessings-1.7-py3-none-any.whl (18 kB)\nCollecting beautifulsoup4\n  Downloading beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n\u001b[K     |████████████████████████████████| 115 kB 53.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from protobuf>=3.8.0->ray) (47.3.1)\nCollecting async-timeout<4.0,>=3.0\n  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\nCollecting yarl<2.0,>=1.0\n  Downloading yarl-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (258 kB)\n\u001b[K     |████████████████████████████████| 258 kB 48.4 MB/s eta 0:00:01\n\u001b[?25hCollecting multidict<5.0,>=4.5\n  Downloading multidict-4.7.6-cp37-cp37m-manylinux1_x86_64.whl (149 kB)\n\u001b[K     |████████████████████████████████| 149 kB 62.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray) (19.3.0)\nRequirement already satisfied: chardet<4.0,>=2.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray) (3.0.4)\nCollecting google-api-core<2.0.0,>=1.0.0\n  Downloading google_api_core-1.22.1-py2.py3-none-any.whl (91 kB)\n\u001b[K     |████████████████████████████████| 91 kB 13.3 MB/s eta 0:00:01\n\u001b[?25hCollecting opencensus-context==0.1.1\n  Downloading opencensus_context-0.1.1-py2.py3-none-any.whl (4.4 kB)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (2020.6.20)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (1.7.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (0.16.0)\nCollecting hiredis\n  Downloading hiredis-1.1.0-cp37-cp37m-manylinux2010_x86_64.whl (62 kB)\n\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s  eta 0:00:01\n\u001b[?25hCollecting soupsieve>1.2\n  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\nCollecting typing-extensions>=3.7.4; python_version < \"3.8\"\n  Downloading typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)\nRequirement already satisfied: google-auth<2.0dev,>=1.19.1 in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.20.1)\nCollecting googleapis-common-protos<2.0dev,>=1.6.0\n  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n\u001b[K     |████████████████████████████████| 100 kB 13.7 MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: pytz in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2020.1)\nRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray) (3.1.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.1.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\nBuilding wheels for collected packages: pyyaml, gpustat, nvidia-ml-py3, psutil\n  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=74d988c94ece68240a3ab9bb264750ffa4c0651aa08753ca8b166c736934424f\n  Stored in directory: /home/jovyan/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n  Building wheel for gpustat (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=d29c6ee221f7e2d7e73eab0d86ea6b7303c5bc84eb9517df78f555effa392d36\n  Stored in directory: /home/jovyan/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19189 sha256=31ea7aad31eabfbce9bfdbca525c18d8e2fdf47a0195b42b2f465b29ab64ad03\n  Stored in directory: /home/jovyan/.cache/pip/wheels/df/99/da/c34f202dc8fd1dffd35e0ecf1a7d7f8374ca05fbcbaf974b83\n  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.2-cp37-cp37m-linux_x86_64.whl size=282599 sha256=c5bc0ff2400f2f5458f1aea33a86ba2aaaba90eabd703884094a603cf14278c2\n  Stored in directory: /home/jovyan/.cache/pip/wheels/2d/43/97/00701864a7bee6d9e1a52dd682537dcbf1d013d0e2e6f0c1f1\nSuccessfully built pyyaml gpustat nvidia-ml-py3 psutil\nInstalling collected packages: pyyaml, colorful, msgpack, redis, colorama, py-spy, nvidia-ml-py3, psutil, blessings, gpustat, soupsieve, beautifulsoup4, google, async-timeout, typing-extensions, multidict, yarl, aiohttp, googleapis-common-protos, google-api-core, opencensus-context, opencensus, filelock, click, hiredis, aioredis, ray\nSuccessfully installed aiohttp-3.6.2 aioredis-1.3.1 async-timeout-3.0.1 beautifulsoup4-4.9.1 blessings-1.7 click-7.1.2 colorama-0.4.3 colorful-0.5.4 filelock-3.0.12 google-3.0.0 google-api-core-1.22.1 googleapis-common-protos-1.52.0 gpustat-0.6.0 hiredis-1.1.0 msgpack-1.0.0 multidict-4.7.6 nvidia-ml-py3-7.352.0 opencensus-0.7.10 opencensus-context-0.1.1 psutil-5.7.2 py-spy-0.3.3 pyyaml-5.3.1 ray-0.8.7 redis-3.4.1 soupsieve-2.0.1 typing-extensions-3.7.4.2 yarl-1.5.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n2020-08-18 14:57:58,174\tINFO resource_spec.py:231 -- Starting Ray with 12.94 GiB memory available for workers and up to 6.47 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n2020-08-18 14:57:58,676\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n2020-08-18 14:57:58,681\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n2020-08-18 14:57:58,696\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n2020-08-18 14:57:59,839\tWARNING worker.py:1134 -- The dashboard on node p-302a6336-d27e-43af-93d1-276242f3b519 failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/venv/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 961, in <module>\n    dashboard.run()\n  File \"/opt/venv/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 576, in run\n    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web.py\", line 433, in run_app\n    reuse_port=reuse_port))\n  File \"/usr/local/lib/python3.7/asyncio/base_events.py\", line 584, in run_until_complete\n    return future.result()\n  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web.py\", line 359, in _run_app\n    await site.start()\n  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web_runner.py\", line 104, in start\n    reuse_port=self._reuse_port)\n  File \"/usr/local/lib/python3.7/asyncio/base_events.py\", line 1378, in create_server\n    % (sa, err.strerror.lower())) from None\nOSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n\nCollecting nltk\n  Downloading nltk-3.5.zip (1.4 MB)\n\u001b[K     |████████████████████████████████| 1.4 MB 3.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: click in /opt/venv/lib/python3.7/site-packages (from nltk) (7.1.2)\nRequirement already satisfied: joblib in /opt/venv/lib/python3.7/site-packages (from nltk) (0.16.0)\nCollecting regex\n  Downloading regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660 kB)\n\u001b[K     |████████████████████████████████| 660 kB 18.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (from nltk) (4.48.2)\nBuilding wheels for collected packages: nltk\n  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434676 sha256=3f778d5ff421c14d0458ded89f2e78f1232e84ff8170bda385409be645900447\n  Stored in directory: /home/jovyan/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\nSuccessfully built nltk\nInstalling collected packages: regex, nltk\nSuccessfully installed nltk-3.5 regex-2020.7.14\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\nRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (4.48.2)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: gensim in /opt/venv/lib/python3.7/site-packages (3.8.3)\nRequirement already satisfied: six>=1.5.0 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.15.0)\nRequirement already satisfied: numpy>=1.11.3 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.18.5)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (2.1.0)\nRequirement already satisfied: scipy>=0.18.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.5.1)\nRequirement already satisfied: boto in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\nRequirement already satisfied: boto3 in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.44)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\nRequirement already satisfied: botocore<1.18.0,>=1.17.44 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.44)\nRequirement already satisfied: docutils<0.16,>=0.10 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.44->boto3->smart-open>=1.8.1->gensim) (0.15.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.44->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nEN-VERB-143\nEN-SimVerb-3500\nEN-RG-65\nEN-RW-STANFORD\nEN-MTurk-771\nEN-MEN-TR-3k\nEN-MC-30\nEN-MTurk-287\nEN-SIMLEX-999\nEN-WS-353-REL\nEN-YP-130\nEN-WS-353-ALL\nEN-WS-353-SIM\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load word2vec models","metadata":{"tags":[],"cell_id":"00003-7aa5267f-439e-4e0e-bce0-1c113f44ced3"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-b38d3970-71ec-445e-8d56-ee126cda621c"},"source":"# model = Word2Vec.load(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0/word2vec_wikiEn20171001_millionSentences_mc=10_iter=5_size=100_window=5_sg=0\")","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Word2vec similarity computing method","metadata":{"tags":[],"cell_id":"00005-0d59b9b7-fd9e-4264-b365-928853de76d4"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-53360c62-c699-4129-99da-de30347538ce"},"source":"def word2vec_get_index_by_word(model, word):\n    \"\"\"Return the index of the word in the model\n    \"\"\"\n    return model.wv.index2word.index(word)\n\ndef word2vec_get_word_by_index(model, index):\n    \"\"\"Return the word by the provided index\n    \"\"\"\n    return model.wv.index2word[index]\n\ndef word2vec_find_top_similar_words(model, source_word, method='IN-IN', top_n=5, no_self_similarity=True):\n    \"\"\"\n    Provided a word, find the top_n most similar from the model following the method\n    \"\"\"\n    score = []\n    input_weights = model.wv.vectors\n    output_weights = model.trainables.syn1neg\n    source_word_index = word2vec_get_index_by_word(model, source_word)\n    if method==\"IN-IN\":\n        weights1, weights2 = input_weights, input_weights\n    elif method==\"IN-OUT\":\n        weights1, weights2 = input_weights, output_weights\n    elif method==\"OUT-IN\":\n        weights1, weights2 = output_weights, input_weights\n    elif method==\"OUT-OUT\":\n        weights1, weights2 = output_weights, output_weights\n    score = cosine_similarity(weights1[source_word_index].reshape(1, -1), weights2)[0]\n    if no_self_similarity:\n        score[source_word_index] = -1 # negate self-similarity\n    top_n_similar_words = np.argpartition(-score, top_n)[:top_n]\n    return sorted([(word2vec_get_word_by_index(model, index), score[index]) for index in top_n_similar_words], \n                key=lambda x: x[1], \n                reverse=True)\n\ndef word2vec_find_similarity(model, source_word, target_word, method=\"IN-IN\"):\n    \"\"\"Return the cosine similarity between two words based on the suggested method\n    \"\"\"\n    input_weights = model.wv.vectors\n    output_weights = model.trainables.syn1neg\n    source_word_index = word2vec_get_index_by_word(model, source_word)\n    target_word_index = word2vec_get_index_by_word(model, target_word)\n    if method==\"IN-IN\":\n        weights1, weights2 = input_weights, input_weights\n    elif method==\"IN-OUT\":\n        weights1, weights2 = input_weights, output_weights\n    elif method==\"OUT-IN\":\n        weights1, weights2 = output_weights, input_weights\n    elif method==\"OUT-OUT\":\n        weights1, weights2 = output_weights, output_weights\n    score = cosine_similarity(weights1[source_word_index].reshape(1, -1), \n                              weights2[target_word_index].reshape(1, -1))[0]\n    return score\n# word2vec_find_similarity(model, \"car\", \"truck\", \"IN-OUT\")\n# word2vec_find_top_similar_words(model, \"car\", \"IN-IN\")\n# word2vec_find_top_similar_words(model, \"car\", \"IN-OUT\")","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate stats for one similarity dataset","metadata":{"tags":[],"cell_id":"00007-d3aa3594-05aa-4e59-81cc-bc78b820a6e1"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00008-80a352e0-31e8-49d8-aa79-e3b9cb2d4f2d"},"source":"df = similarity_datasets['EN-SIMLEX-999'].copy()\nscore_table = []\ndimension = model.trainables.syn1neg.shape[1]\nfor row in df.to_dict(orient=\"records\"):\n    methods = [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]\n    for method in methods:\n        try:\n            sim_score = word2vec_find_similarity(model, row['word_1'], row['word_2'], method)[0]\n        except:\n            sim_score = None\n        row[f'word2vec_{dimension}_{method}_sim_score'] = sim_score\n    score_table.append(row)\nscore_table = pd.DataFrame.from_dict(score_table)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00009-338dc9c3-5d82-453c-bc7f-66de541b50f9"},"source":"score_table.dropna().corr(\"pearson\")","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":5,"column_count":5,"columns":[{"name":"similarity_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0.26776649163249067,"max":1,"histogram":[{"bin_start":0.26776649163249067,"bin_end":0.3409898424692416,"count":3},{"bin_start":0.3409898424692416,"bin_end":0.41421319330599254,"count":1},{"bin_start":0.41421319330599254,"bin_end":0.4874365441427435,"count":0},{"bin_start":0.4874365441427435,"bin_end":0.5606598949794944,"count":0},{"bin_start":0.5606598949794944,"bin_end":0.6338832458162453,"count":0},{"bin_start":0.6338832458162453,"bin_end":0.7071065966529964,"count":0},{"bin_start":0.7071065966529964,"bin_end":0.7803299474897473,"count":0},{"bin_start":0.7803299474897473,"bin_end":0.8535532983264982,"count":0},{"bin_start":0.8535532983264982,"bin_end":0.9267766491632491,"count":0},{"bin_start":0.9267766491632491,"bin_end":1,"count":1}]}},{"name":"word2vec_100_IN-IN_sim_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0.378299293895258,"max":1,"histogram":[{"bin_start":0.378299293895258,"bin_end":0.4404693645057322,"count":1},{"bin_start":0.4404693645057322,"bin_end":0.5026394351162065,"count":0},{"bin_start":0.5026394351162065,"bin_end":0.5648095057266806,"count":0},{"bin_start":0.5648095057266806,"bin_end":0.6269795763371548,"count":0},{"bin_start":0.6269795763371548,"bin_end":0.689149646947629,"count":2},{"bin_start":0.689149646947629,"bin_end":0.7513197175581032,"count":0},{"bin_start":0.7513197175581032,"bin_end":0.8134897881685774,"count":1},{"bin_start":0.8134897881685774,"bin_end":0.8756598587790516,"count":0},{"bin_start":0.8756598587790516,"bin_end":0.9378299293895258,"count":0},{"bin_start":0.9378299293895258,"bin_end":1,"count":1}]}},{"name":"word2vec_100_IN-OUT_sim_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0.28433528941977404,"max":1,"histogram":[{"bin_start":0.28433528941977404,"bin_end":0.35590176047779665,"count":1},{"bin_start":0.35590176047779665,"bin_end":0.42746823153581925,"count":0},{"bin_start":0.42746823153581925,"bin_end":0.4990347025938418,"count":1},{"bin_start":0.4990347025938418,"bin_end":0.5706011736518644,"count":0},{"bin_start":0.5706011736518644,"bin_end":0.642167644709887,"count":1},{"bin_start":0.642167644709887,"bin_end":0.7137341157679096,"count":0},{"bin_start":0.7137341157679096,"bin_end":0.7853005868259322,"count":0},{"bin_start":0.7853005868259322,"bin_end":0.8568670578839548,"count":0},{"bin_start":0.8568670578839548,"bin_end":0.9284335289419774,"count":1},{"bin_start":0.9284335289419774,"bin_end":1,"count":1}]}},{"name":"word2vec_100_OUT-IN_sim_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0.26776649163249067,"max":1,"histogram":[{"bin_start":0.26776649163249067,"bin_end":0.3409898424692416,"count":1},{"bin_start":0.3409898424692416,"bin_end":0.41421319330599254,"count":0},{"bin_start":0.41421319330599254,"bin_end":0.4874365441427435,"count":1},{"bin_start":0.4874365441427435,"bin_end":0.5606598949794944,"count":0},{"bin_start":0.5606598949794944,"bin_end":0.6338832458162453,"count":0},{"bin_start":0.6338832458162453,"bin_end":0.7071065966529964,"count":1},{"bin_start":0.7071065966529964,"bin_end":0.7803299474897473,"count":0},{"bin_start":0.7803299474897473,"bin_end":0.8535532983264982,"count":0},{"bin_start":0.8535532983264982,"bin_end":0.9267766491632491,"count":1},{"bin_start":0.9267766491632491,"bin_end":1,"count":1}]}},{"name":"word2vec_100_OUT-OUT_sim_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0.3268358962361852,"max":1,"histogram":[{"bin_start":0.3268358962361852,"bin_end":0.39415230661256667,"count":1},{"bin_start":0.39415230661256667,"bin_end":0.46146871698894815,"count":0},{"bin_start":0.46146871698894815,"bin_end":0.5287851273653297,"count":2},{"bin_start":0.5287851273653297,"bin_end":0.5961015377417112,"count":0},{"bin_start":0.5961015377417112,"bin_end":0.6634179481180926,"count":0},{"bin_start":0.6634179481180926,"bin_end":0.7307343584944741,"count":0},{"bin_start":0.7307343584944741,"bin_end":0.7980507688708556,"count":1},{"bin_start":0.7980507688708556,"bin_end":0.865367179247237,"count":0},{"bin_start":0.865367179247237,"bin_end":0.9326835896236185,"count":0},{"bin_start":0.9326835896236185,"bin_end":1,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"similarity_score":1,"word2vec_100_IN-IN_sim_score":0.378299293895258,"word2vec_100_IN-OUT_sim_score":0.28433528941977404,"word2vec_100_OUT-IN_sim_score":0.26776649163249067,"word2vec_100_OUT-OUT_sim_score":0.3268358962361852,"_deepnote_index_column":"similarity_score"},{"similarity_score":0.378299293895258,"word2vec_100_IN-IN_sim_score":1,"word2vec_100_IN-OUT_sim_score":0.6290711764425195,"word2vec_100_OUT-IN_sim_score":0.64211004201536,"word2vec_100_OUT-OUT_sim_score":0.7906238382155103,"_deepnote_index_column":"word2vec_100_IN-IN_sim_score"},{"similarity_score":0.28433528941977404,"word2vec_100_IN-IN_sim_score":0.6290711764425195,"word2vec_100_IN-OUT_sim_score":1,"word2vec_100_OUT-IN_sim_score":0.9209477013494461,"word2vec_100_OUT-OUT_sim_score":0.4752112857861825,"_deepnote_index_column":"word2vec_100_IN-OUT_sim_score"},{"similarity_score":0.26776649163249067,"word2vec_100_IN-IN_sim_score":0.64211004201536,"word2vec_100_IN-OUT_sim_score":0.9209477013494461,"word2vec_100_OUT-IN_sim_score":1,"word2vec_100_OUT-OUT_sim_score":0.4751503500242323,"_deepnote_index_column":"word2vec_100_OUT-IN_sim_score"},{"similarity_score":0.3268358962361852,"word2vec_100_IN-IN_sim_score":0.7906238382155103,"word2vec_100_IN-OUT_sim_score":0.4752112857861825,"word2vec_100_OUT-IN_sim_score":0.4751503500242323,"word2vec_100_OUT-OUT_sim_score":1,"_deepnote_index_column":"word2vec_100_OUT-OUT_sim_score"}],"rows_bottom":null},"text/plain":"                                similarity_score  \\\nsimilarity_score                        1.000000   \nword2vec_100_IN-IN_sim_score            0.378299   \nword2vec_100_IN-OUT_sim_score           0.284335   \nword2vec_100_OUT-IN_sim_score           0.267766   \nword2vec_100_OUT-OUT_sim_score          0.326836   \n\n                                word2vec_100_IN-IN_sim_score  \\\nsimilarity_score                                    0.378299   \nword2vec_100_IN-IN_sim_score                        1.000000   \nword2vec_100_IN-OUT_sim_score                       0.629071   \nword2vec_100_OUT-IN_sim_score                       0.642110   \nword2vec_100_OUT-OUT_sim_score                      0.790624   \n\n                                word2vec_100_IN-OUT_sim_score  \\\nsimilarity_score                                     0.284335   \nword2vec_100_IN-IN_sim_score                         0.629071   \nword2vec_100_IN-OUT_sim_score                        1.000000   \nword2vec_100_OUT-IN_sim_score                        0.920948   \nword2vec_100_OUT-OUT_sim_score                       0.475211   \n\n                                word2vec_100_OUT-IN_sim_score  \\\nsimilarity_score                                     0.267766   \nword2vec_100_IN-IN_sim_score                         0.642110   \nword2vec_100_IN-OUT_sim_score                        0.920948   \nword2vec_100_OUT-IN_sim_score                        1.000000   \nword2vec_100_OUT-OUT_sim_score                       0.475150   \n\n                                word2vec_100_OUT-OUT_sim_score  \nsimilarity_score                                      0.326836  \nword2vec_100_IN-IN_sim_score                          0.790624  \nword2vec_100_IN-OUT_sim_score                         0.475211  \nword2vec_100_OUT-IN_sim_score                         0.475150  \nword2vec_100_OUT-OUT_sim_score                        1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>similarity_score</th>\n      <th>word2vec_100_IN-IN_sim_score</th>\n      <th>word2vec_100_IN-OUT_sim_score</th>\n      <th>word2vec_100_OUT-IN_sim_score</th>\n      <th>word2vec_100_OUT-OUT_sim_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>similarity_score</th>\n      <td>1.000000</td>\n      <td>0.378299</td>\n      <td>0.284335</td>\n      <td>0.267766</td>\n      <td>0.326836</td>\n    </tr>\n    <tr>\n      <th>word2vec_100_IN-IN_sim_score</th>\n      <td>0.378299</td>\n      <td>1.000000</td>\n      <td>0.629071</td>\n      <td>0.642110</td>\n      <td>0.790624</td>\n    </tr>\n    <tr>\n      <th>word2vec_100_IN-OUT_sim_score</th>\n      <td>0.284335</td>\n      <td>0.629071</td>\n      <td>1.000000</td>\n      <td>0.920948</td>\n      <td>0.475211</td>\n    </tr>\n    <tr>\n      <th>word2vec_100_OUT-IN_sim_score</th>\n      <td>0.267766</td>\n      <td>0.642110</td>\n      <td>0.920948</td>\n      <td>1.000000</td>\n      <td>0.475150</td>\n    </tr>\n    <tr>\n      <th>word2vec_100_OUT-OUT_sim_score</th>\n      <td>0.326836</td>\n      <td>0.790624</td>\n      <td>0.475211</td>\n      <td>0.475150</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Generate similarity score for each similarity datasets","metadata":{"tags":[],"cell_id":"00010-0ee6049a-6cce-4f29-b41d-db37bcd57547"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00011-8f52192d-aa1f-495d-89ad-5b52b2a358df"},"source":"# lemmatizer - noun lemma -- https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\ndef lemma(word): return nltk.stem.WordNetLemmatizer().lemmatize(word)\n\n# preprocss the word - lowercase and lemma\ndef pre(word): return lemma(word.lower())\n\nall_df_res = []\nall_missing_words = []\n\n@ray.remote\ndef compare_word2vec_model_with_dataset(model, model_name, dataset_name, dataset):\n    missing_words = 0\n    score_table = []\n    for row in dataset.to_dict(orient=\"records\"):\n        methods = [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]\n        for method in methods:\n            try:\n                sim_score = word2vec_find_similarity(model, pre(row['word_1']), pre(row['word_2']), method)[0]\n            except:\n                sim_score = None\n                missing_words += 1\n            row[f\"{model_name}_{method}\"] = sim_score\n        score_table.append(row)\n    score_table = pd.DataFrame.from_dict(score_table)\n    score_table = score_table.dropna().corr(\"pearson\")[['similarity_score']].tail(4)\n    score_table.columns = [dataset_name]\n    missing_words = missing_words/len(methods)\n    return score_table, dataset_name, missing_words\n\nfor model_dir in tqdm(glob.glob(\"../../../embeddings_lemma/word2vec_*\")[3:]):\n    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n    model = Word2Vec.load(model_path)\n    # print(\"Running analysis on each dataset\")\n    futures = [compare_word2vec_model_with_dataset.remote(model, model_name, dataset_name, dataset) \\\n                    for dataset_name, dataset in similarity_datasets.items()]\n    res = ray.get(futures)    \n    # print(\"Post processing and Saving results\")\n    # pd.concat(res, axis=1)\n    df_res = pd.concat([df_res for df_res, _, _ in res], axis=1)\n    missing_words = {key:val for _, key, val in res}\n    all_df_res.append(df_res)\n    all_missing_words.append(missing_words)\n    with open(\"word2vec_results1.pickle\", \"wb\") as f:\n        pickle.dump({\"score_matrix\": all_df_res, 'missing_words': all_missing_words}, f)","execution_count":null,"outputs":[{"output_type":"error","ename":"KernelInterrupted","evalue":"Execution interrupted by the Jupyter kernel.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."]}]},{"cell_type":"code","metadata":{"tags":[],"allow_embed":false,"cell_id":"00012-1bf4c181-882e-4c11-8704-ec97b5fa2b31"},"source":"# glob.glob(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0/*\")\nimport pickle\nwith open(\"word2vec_results1.pickle\", \"rb\") as f:\n    _ = pickle.load(f)\n_['score_matrix'][0]","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":4,"column_count":13,"columns":[{"name":"EN-VERB-143","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.2001814236225654,"max":0.34838461692281036,"histogram":[{"bin_start":0.2001814236225654,"bin_end":0.21500174295258992,"count":1},{"bin_start":0.21500174295258992,"bin_end":0.2298220622826144,"count":0},{"bin_start":0.2298220622826144,"bin_end":0.2446423816126389,"count":2},{"bin_start":0.2446423816126389,"bin_end":0.2594627009426634,"count":0},{"bin_start":0.2594627009426634,"bin_end":0.2742830202726879,"count":0},{"bin_start":0.2742830202726879,"bin_end":0.2891033396027124,"count":0},{"bin_start":0.2891033396027124,"bin_end":0.3039236589327369,"count":0},{"bin_start":0.3039236589327369,"bin_end":0.31874397826276135,"count":0},{"bin_start":0.31874397826276135,"bin_end":0.3335642975927859,"count":0},{"bin_start":0.3335642975927859,"bin_end":0.34838461692281036,"count":1}]}},{"name":"EN-SimVerb-3500","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.12034858040268838,"max":0.155178603549839,"histogram":[{"bin_start":0.12034858040268838,"bin_end":0.12383158271740344,"count":1},{"bin_start":0.12383158271740344,"bin_end":0.1273145850321185,"count":0},{"bin_start":0.1273145850321185,"bin_end":0.13079758734683355,"count":0},{"bin_start":0.13079758734683355,"bin_end":0.13428058966154863,"count":1},{"bin_start":0.13428058966154863,"bin_end":0.1377635919762637,"count":1},{"bin_start":0.1377635919762637,"bin_end":0.14124659429097874,"count":0},{"bin_start":0.14124659429097874,"bin_end":0.14472959660569382,"count":0},{"bin_start":0.14472959660569382,"bin_end":0.1482125989204089,"count":0},{"bin_start":0.1482125989204089,"bin_end":0.15169560123512393,"count":0},{"bin_start":0.15169560123512393,"bin_end":0.155178603549839,"count":1}]}},{"name":"EN-RG-65","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6623447151038436,"max":0.6991905563969207,"histogram":[{"bin_start":0.6623447151038436,"bin_end":0.6660292992331514,"count":1},{"bin_start":0.6660292992331514,"bin_end":0.6697138833624591,"count":0},{"bin_start":0.6697138833624591,"bin_end":0.6733984674917668,"count":0},{"bin_start":0.6733984674917668,"bin_end":0.6770830516210745,"count":0},{"bin_start":0.6770830516210745,"bin_end":0.6807676357503822,"count":0},{"bin_start":0.6807676357503822,"bin_end":0.6844522198796898,"count":0},{"bin_start":0.6844522198796898,"bin_end":0.6881368040089976,"count":0},{"bin_start":0.6881368040089976,"bin_end":0.6918213881383053,"count":1},{"bin_start":0.6918213881383053,"bin_end":0.695505972267613,"count":1},{"bin_start":0.695505972267613,"bin_end":0.6991905563969207,"count":1}]}},{"name":"EN-RW-STANFORD","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.3251233267738106,"max":0.3752077509540524,"histogram":[{"bin_start":0.3251233267738106,"bin_end":0.3301317691918348,"count":1},{"bin_start":0.3301317691918348,"bin_end":0.33514021160985896,"count":0},{"bin_start":0.33514021160985896,"bin_end":0.34014865402788313,"count":0},{"bin_start":0.34014865402788313,"bin_end":0.3451570964459073,"count":0},{"bin_start":0.3451570964459073,"bin_end":0.35016553886393154,"count":1},{"bin_start":0.35016553886393154,"bin_end":0.3551739812819557,"count":0},{"bin_start":0.3551739812819557,"bin_end":0.3601824236999799,"count":1},{"bin_start":0.3601824236999799,"bin_end":0.36519086611800405,"count":0},{"bin_start":0.36519086611800405,"bin_end":0.3701993085360282,"count":0},{"bin_start":0.3701993085360282,"bin_end":0.3752077509540524,"count":1}]}},{"name":"EN-MTurk-771","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.5224939266811585,"max":0.599915601768258,"histogram":[{"bin_start":0.5224939266811585,"bin_end":0.5302360941898684,"count":1},{"bin_start":0.5302360941898684,"bin_end":0.5379782616985783,"count":0},{"bin_start":0.5379782616985783,"bin_end":0.5457204292072884,"count":0},{"bin_start":0.5457204292072884,"bin_end":0.5534625967159983,"count":0},{"bin_start":0.5534625967159983,"bin_end":0.5612047642247082,"count":0},{"bin_start":0.5612047642247082,"bin_end":0.5689469317334181,"count":1},{"bin_start":0.5689469317334181,"bin_end":0.5766890992421281,"count":1},{"bin_start":0.5766890992421281,"bin_end":0.5844312667508381,"count":0},{"bin_start":0.5844312667508381,"bin_end":0.592173434259548,"count":0},{"bin_start":0.592173434259548,"bin_end":0.599915601768258,"count":1}]}},{"name":"EN-MEN-TR-3k","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6559665706578095,"max":0.7073081241783694,"histogram":[{"bin_start":0.6559665706578095,"bin_end":0.6611007260098655,"count":1},{"bin_start":0.6611007260098655,"bin_end":0.6662348813619214,"count":0},{"bin_start":0.6662348813619214,"bin_end":0.6713690367139775,"count":0},{"bin_start":0.6713690367139775,"bin_end":0.6765031920660335,"count":0},{"bin_start":0.6765031920660335,"bin_end":0.6816373474180895,"count":0},{"bin_start":0.6816373474180895,"bin_end":0.6867715027701454,"count":0},{"bin_start":0.6867715027701454,"bin_end":0.6919056581222014,"count":0},{"bin_start":0.6919056581222014,"bin_end":0.6970398134742575,"count":0},{"bin_start":0.6970398134742575,"bin_end":0.7021739688263134,"count":0},{"bin_start":0.7021739688263134,"bin_end":0.7073081241783694,"count":3}]}},{"name":"EN-MC-30","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6762726201193515,"max":0.7748469709939656,"histogram":[{"bin_start":0.6762726201193515,"bin_end":0.6861300552068129,"count":1},{"bin_start":0.6861300552068129,"bin_end":0.6959874902942743,"count":0},{"bin_start":0.6959874902942743,"bin_end":0.7058449253817357,"count":1},{"bin_start":0.7058449253817357,"bin_end":0.7157023604691971,"count":0},{"bin_start":0.7157023604691971,"bin_end":0.7255597955566586,"count":0},{"bin_start":0.7255597955566586,"bin_end":0.73541723064412,"count":0},{"bin_start":0.73541723064412,"bin_end":0.7452746657315814,"count":0},{"bin_start":0.7452746657315814,"bin_end":0.7551321008190428,"count":1},{"bin_start":0.7551321008190428,"bin_end":0.7649895359065042,"count":0},{"bin_start":0.7649895359065042,"bin_end":0.7748469709939656,"count":1}]}},{"name":"EN-MTurk-287","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6630860089204689,"max":0.6971743222467025,"histogram":[{"bin_start":0.6630860089204689,"bin_end":0.6664948402530922,"count":1},{"bin_start":0.6664948402530922,"bin_end":0.6699036715857156,"count":0},{"bin_start":0.6699036715857156,"bin_end":0.673312502918339,"count":0},{"bin_start":0.673312502918339,"bin_end":0.6767213342509624,"count":0},{"bin_start":0.6767213342509624,"bin_end":0.6801301655835856,"count":0},{"bin_start":0.6801301655835856,"bin_end":0.683538996916209,"count":1},{"bin_start":0.683538996916209,"bin_end":0.6869478282488324,"count":1},{"bin_start":0.6869478282488324,"bin_end":0.6903566595814558,"count":0},{"bin_start":0.6903566595814558,"bin_end":0.6937654909140791,"count":0},{"bin_start":0.6937654909140791,"bin_end":0.6971743222467025,"count":1}]}},{"name":"EN-SIMLEX-999","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.212155724774273,"max":0.2586126724774914,"histogram":[{"bin_start":0.212155724774273,"bin_end":0.21680141954459484,"count":1},{"bin_start":0.21680141954459484,"bin_end":0.22144711431491668,"count":0},{"bin_start":0.22144711431491668,"bin_end":0.22609280908523852,"count":0},{"bin_start":0.22609280908523852,"bin_end":0.23073850385556036,"count":0},{"bin_start":0.23073850385556036,"bin_end":0.23538419862588222,"count":0},{"bin_start":0.23538419862588222,"bin_end":0.24002989339620406,"count":0},{"bin_start":0.24002989339620406,"bin_end":0.2446755881665259,"count":1},{"bin_start":0.2446755881665259,"bin_end":0.24932128293684774,"count":0},{"bin_start":0.24932128293684774,"bin_end":0.2539669777071696,"count":1},{"bin_start":0.2539669777071696,"bin_end":0.2586126724774914,"count":1}]}},{"name":"EN-WS-353-REL","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.4785822534151125,"max":0.6065138896293149,"histogram":[{"bin_start":0.4785822534151125,"bin_end":0.49137541703653276,"count":1},{"bin_start":0.49137541703653276,"bin_end":0.504168580657953,"count":0},{"bin_start":0.504168580657953,"bin_end":0.5169617442793732,"count":0},{"bin_start":0.5169617442793732,"bin_end":0.5297549079007935,"count":0},{"bin_start":0.5297549079007935,"bin_end":0.5425480715222137,"count":0},{"bin_start":0.5425480715222137,"bin_end":0.555341235143634,"count":0},{"bin_start":0.555341235143634,"bin_end":0.5681343987650541,"count":0},{"bin_start":0.5681343987650541,"bin_end":0.5809275623864744,"count":1},{"bin_start":0.5809275623864744,"bin_end":0.5937207260078946,"count":0},{"bin_start":0.5937207260078946,"bin_end":0.6065138896293149,"count":2}]}},{"name":"EN-YP-130","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.2640276380721901,"max":0.41790984098086836,"histogram":[{"bin_start":0.2640276380721901,"bin_end":0.27941585836305793,"count":1},{"bin_start":0.27941585836305793,"bin_end":0.29480407865392577,"count":0},{"bin_start":0.29480407865392577,"bin_end":0.3101922989447936,"count":0},{"bin_start":0.3101922989447936,"bin_end":0.3255805192356614,"count":0},{"bin_start":0.3255805192356614,"bin_end":0.34096873952652923,"count":0},{"bin_start":0.34096873952652923,"bin_end":0.35635695981739707,"count":0},{"bin_start":0.35635695981739707,"bin_end":0.3717451801082649,"count":1},{"bin_start":0.3717451801082649,"bin_end":0.3871334003991327,"count":0},{"bin_start":0.3871334003991327,"bin_end":0.4025216206900005,"count":0},{"bin_start":0.4025216206900005,"bin_end":0.41790984098086836,"count":2}]}},{"name":"EN-WS-353-ALL","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.5689648828217478,"max":0.6438547286508106,"histogram":[{"bin_start":0.5689648828217478,"bin_end":0.5764538674046541,"count":1},{"bin_start":0.5764538674046541,"bin_end":0.5839428519875604,"count":0},{"bin_start":0.5839428519875604,"bin_end":0.5914318365704667,"count":0},{"bin_start":0.5914318365704667,"bin_end":0.598920821153373,"count":0},{"bin_start":0.598920821153373,"bin_end":0.6064098057362792,"count":0},{"bin_start":0.6064098057362792,"bin_end":0.6138987903191855,"count":0},{"bin_start":0.6138987903191855,"bin_end":0.6213877749020917,"count":0},{"bin_start":0.6213877749020917,"bin_end":0.6288767594849981,"count":1},{"bin_start":0.6288767594849981,"bin_end":0.6363657440679044,"count":0},{"bin_start":0.6363657440679044,"bin_end":0.6438547286508106,"count":2}]}},{"name":"EN-WS-353-SIM","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6521803038725271,"max":0.7087197740128679,"histogram":[{"bin_start":0.6521803038725271,"bin_end":0.6578342508865612,"count":1},{"bin_start":0.6578342508865612,"bin_end":0.6634881979005953,"count":0},{"bin_start":0.6634881979005953,"bin_end":0.6691421449146293,"count":0},{"bin_start":0.6691421449146293,"bin_end":0.6747960919286634,"count":0},{"bin_start":0.6747960919286634,"bin_end":0.6804500389426975,"count":0},{"bin_start":0.6804500389426975,"bin_end":0.6861039859567316,"count":0},{"bin_start":0.6861039859567316,"bin_end":0.6917579329707657,"count":1},{"bin_start":0.6917579329707657,"bin_end":0.6974118799847997,"count":0},{"bin_start":0.6974118799847997,"bin_end":0.7030658269988338,"count":0},{"bin_start":0.7030658269988338,"bin_end":0.7087197740128679,"count":2}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"EN-VERB-143":0.34838461692281036,"EN-SimVerb-3500":0.1364659926036458,"EN-RG-65":0.6895579203091267,"EN-RW-STANFORD":0.3752077509540524,"EN-MTurk-771":0.599915601768258,"EN-MEN-TR-3k":0.7054288643887612,"EN-MC-30":0.7480747755671264,"EN-MTurk-287":0.6971743222467025,"EN-SIMLEX-999":0.2503383609476077,"EN-WS-353-REL":0.5763911482008061,"EN-YP-130":0.40401484962916356,"EN-WS-353-ALL":0.6222462579422785,"EN-WS-353-SIM":0.6880709745210787,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_IN-IN"},{"EN-VERB-143":0.23501683536561455,"EN-SimVerb-3500":0.155178603549839,"EN-RG-65":0.6924469032379581,"EN-RW-STANFORD":0.3251233267738106,"EN-MTurk-771":0.5752239870736946,"EN-MEN-TR-3k":0.7059331167783172,"EN-MC-30":0.6762726201193515,"EN-MTurk-287":0.681006300980238,"EN-SIMLEX-999":0.24418399495739598,"EN-WS-353-REL":0.6016077444871313,"EN-YP-130":0.41790984098086836,"EN-WS-353-ALL":0.6424350065734841,"EN-WS-353-SIM":0.7035777424831945,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_IN-OUT"},{"EN-VERB-143":0.2411989501625128,"EN-SimVerb-3500":0.13405800486224162,"EN-RG-65":0.6991905563969207,"EN-RW-STANFORD":0.34562742800632557,"EN-MTurk-771":0.5683129110415912,"EN-MEN-TR-3k":0.7073081241783694,"EN-MC-30":0.7748469709939656,"EN-MTurk-287":0.686461232543265,"EN-SIMLEX-999":0.212155724774273,"EN-WS-353-REL":0.6065138896293149,"EN-YP-130":0.3580221703852564,"EN-WS-353-ALL":0.6438547286508106,"EN-WS-353-SIM":0.7087197740128679,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_OUT-IN"},{"EN-VERB-143":0.2001814236225654,"EN-SimVerb-3500":0.12034858040268838,"EN-RG-65":0.6623447151038436,"EN-RW-STANFORD":0.35719949743016544,"EN-MTurk-771":0.5224939266811585,"EN-MEN-TR-3k":0.6559665706578095,"EN-MC-30":0.7053942520360192,"EN-MTurk-287":0.6630860089204689,"EN-SIMLEX-999":0.2586126724774914,"EN-WS-353-REL":0.4785822534151125,"EN-YP-130":0.2640276380721901,"EN-WS-353-ALL":0.5689648828217478,"EN-WS-353-SIM":0.6521803038725271,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT"}],"rows_bottom":null},"text/plain":"                                                EN-VERB-143  EN-SimVerb-3500  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN       0.348385         0.136466   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT      0.235017         0.155179   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN      0.241199         0.134058   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT     0.200181         0.120349   \n\n                                                EN-RG-65  EN-RW-STANFORD  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN    0.689558        0.375208   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT   0.692447        0.325123   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN   0.699191        0.345627   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT  0.662345        0.357199   \n\n                                                EN-MTurk-771  EN-MEN-TR-3k  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN        0.599916      0.705429   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT       0.575224      0.705933   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN       0.568313      0.707308   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT      0.522494      0.655967   \n\n                                                EN-MC-30  EN-MTurk-287  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN    0.748075      0.697174   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT   0.676273      0.681006   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN   0.774847      0.686461   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT  0.705394      0.663086   \n\n                                                EN-SIMLEX-999  EN-WS-353-REL  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN         0.250338       0.576391   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT        0.244184       0.601608   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN        0.212156       0.606514   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT       0.258613       0.478582   \n\n                                                EN-YP-130  EN-WS-353-ALL  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN     0.404015       0.622246   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT    0.417910       0.642435   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN    0.358022       0.643855   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT   0.264028       0.568965   \n\n                                                EN-WS-353-SIM  \nword2vec_mc=10_size=200_window=50_sg=1_IN-IN         0.688071  \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT        0.703578  \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN        0.708720  \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT       0.652180  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EN-VERB-143</th>\n      <th>EN-SimVerb-3500</th>\n      <th>EN-RG-65</th>\n      <th>EN-RW-STANFORD</th>\n      <th>EN-MTurk-771</th>\n      <th>EN-MEN-TR-3k</th>\n      <th>EN-MC-30</th>\n      <th>EN-MTurk-287</th>\n      <th>EN-SIMLEX-999</th>\n      <th>EN-WS-353-REL</th>\n      <th>EN-YP-130</th>\n      <th>EN-WS-353-ALL</th>\n      <th>EN-WS-353-SIM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_IN-IN</th>\n      <td>0.348385</td>\n      <td>0.136466</td>\n      <td>0.689558</td>\n      <td>0.375208</td>\n      <td>0.599916</td>\n      <td>0.705429</td>\n      <td>0.748075</td>\n      <td>0.697174</td>\n      <td>0.250338</td>\n      <td>0.576391</td>\n      <td>0.404015</td>\n      <td>0.622246</td>\n      <td>0.688071</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_IN-OUT</th>\n      <td>0.235017</td>\n      <td>0.155179</td>\n      <td>0.692447</td>\n      <td>0.325123</td>\n      <td>0.575224</td>\n      <td>0.705933</td>\n      <td>0.676273</td>\n      <td>0.681006</td>\n      <td>0.244184</td>\n      <td>0.601608</td>\n      <td>0.417910</td>\n      <td>0.642435</td>\n      <td>0.703578</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_OUT-IN</th>\n      <td>0.241199</td>\n      <td>0.134058</td>\n      <td>0.699191</td>\n      <td>0.345627</td>\n      <td>0.568313</td>\n      <td>0.707308</td>\n      <td>0.774847</td>\n      <td>0.686461</td>\n      <td>0.212156</td>\n      <td>0.606514</td>\n      <td>0.358022</td>\n      <td>0.643855</td>\n      <td>0.708720</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT</th>\n      <td>0.200181</td>\n      <td>0.120349</td>\n      <td>0.662345</td>\n      <td>0.357199</td>\n      <td>0.522494</td>\n      <td>0.655967</td>\n      <td>0.705394</td>\n      <td>0.663086</td>\n      <td>0.258613</td>\n      <td>0.478582</td>\n      <td>0.264028</td>\n      <td>0.568965</td>\n      <td>0.652180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Appendix\n\n1. Check for the presence of word in dataset and model","metadata":{"tags":[],"cell_id":"00013-505abced-51aa-47ef-a238-cf42f4cb120e"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-58a997c1-2088-453d-87db-a86917ed61bd"},"source":"# missing_words\nlist_of_words = similarity_datasets['EN-VERB-143']['word_1'].values\nprint(f\"Unique words: {len(set(list_of_words))}\")\nprint(f\"Words in model: {sum([lemma(word.lower()) not in model.wv.index2word for word in set(list_of_words) ])}\")","execution_count":null,"outputs":[{"name":"stdout","text":"Unique words: 87\nWords in model: 0\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-e3d5c77e-7b21-4961-9f02-afbe0979c4b5"},"source":"missing_words['EN-VERB-143']\nnltk.download('wordnet')","execution_count":null,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n","output_type":"stream"},{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":true,"cell_id":"00016-4799d3c5-90ab-4f6a-adb6-cc117f486463"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00017-08021ea4-4f86-4b75-97e9-4c436dd71a8d"},"source":"glob.glob(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=50_sg=1/*[!(npy)]\")","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"['../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=50_sg=1/word2vec_wikiEn20171001_millionSentences_mc=10_iter=5_size=200_window=50_sg=1']"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00018-0c99c113-8491-4b9d-b22b-aec61548ecff"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"ee79aacb-fd8f-4052-af8b-c77445857e56","deepnote_execution_queue":[]}}