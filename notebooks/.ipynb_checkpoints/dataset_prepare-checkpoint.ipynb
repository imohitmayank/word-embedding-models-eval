{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-041ba339-031d-426b-8697-9dda6244991a",
    "tags": []
   },
   "source": [
    "# Word2Vec models comparison\n",
    "\n",
    "We compare the different models of word2vec against different intrinsic word embeddings tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-7d1cb22c-84e3-419d-8987-607100f4798d",
    "tags": []
   },
   "source": [
    "### Import and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-3b9bb0a0-e60c-4aee-8287-c11f6e167fc0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/bd/8dbe8a02c7a56b11554fce6da92151d68e508b6c57809693a4c5170b975a/ray-0.8.7-cp37-cp37m-win_amd64.whl (14.2MB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/51/10/19ddf3b6f8bfb2b273dddbcdc8293e79545c55688bdf7c09fc51bab2e4df/msgpack-1.0.0-cp37-cp37m-win_amd64.whl (72kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (0.4.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (3.0.1)\n",
      "Collecting opencensus (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/9c/d40e3408e72d02612acf247d829e3fa9ff15c59f7ad81418ed79962f8681/opencensus-0.7.10-py2.py3-none-any.whl (126kB)\n",
      "Collecting aiohttp (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/b3/744a16bdaba2e4df90f6ff10b9ade9c2dce3f01d94848f3949aa4ce7868d/aiohttp-3.6.2-cp37-cp37m-win_amd64.whl (649kB)\n",
      "Collecting google (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/35/17c9141c4ae21e9a29a43acdfd848e3e468a810517f862cad07977bf8fe9/google-3.0.0-py2.py3-none-any.whl (45kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (5.1.2)\n",
      "Collecting aioredis (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (7.0)\n",
      "Collecting colorful (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (3.0.10)\n",
      "Collecting grpcio>=1.28.1 (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/23/15fe2dff7163f3191d4d74eaddbd3e241dea185e96447b1920685235560c/grpcio-1.31.0-cp37-cp37m-win_amd64.whl (2.4MB)\n",
      "Collecting prometheus-client>=0.7.1 (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/0e/554a265ffdc56e1494ef08e18f765b0cdec78797f510c58c45cf37abb4f4/prometheus_client-0.8.0-py2.py3-none-any.whl (53kB)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (1.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from ray) (2.21.0)\n",
      "Collecting redis<3.5.0,>=3.3.2 (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
      "Collecting gpustat (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
      "Collecting protobuf>=3.8.0 (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/6b/2e/28425c709c26525998be0b7a91c4090c87c38a1a9644fd43fefaea2e16c0/protobuf-3.13.0-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting py-spy>=0.2.0 (from ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/34/52f5898e58a69257afeef18f97701d99942959f5abb9f8b31676055ee6b7/py_spy-0.3.3-py2.py3-none-win_amd64.whl (1.4MB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from jsonschema->ray) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from jsonschema->ray) (0.14.11)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from jsonschema->ray) (40.8.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from jsonschema->ray) (1.12.0)\n",
      "Collecting opencensus-context==0.1.1 (from opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/b7/720d4507e97aa3916ac47054cd75490de6b6148c46d8c2c487638f16ad95/opencensus_context-0.1.1-py2.py3-none-any.whl\n",
      "Collecting google-api-core<2.0.0,>=1.0.0 (from opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/2d/7c6c75013105e1d2b6eaa1bf18a56995be1dbc673c38885aea31136e9918/google_api_core-1.22.1-py2.py3-none-any.whl (91kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from aiohttp->ray) (3.0.4)\n",
      "Collecting async-timeout<4.0,>=3.0 (from aiohttp->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting multidict<5.0,>=4.5 (from aiohttp->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/58/b8/327b0391f14ce7fa001ba5911b4504cf1812617b33a51b837638026f756e/multidict-4.7.6-cp37-cp37m-win_amd64.whl (48kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/31/bf/20538d516ef04497163569027d524dc36cd168752e7b0b6b8a1b0d9ba804/yarl-1.5.1-cp37-cp37m-win_amd64.whl (127kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from google->ray) (4.7.1)\n",
      "Collecting hiredis (from aioredis->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/1e/27a23f8eadf191cfc6a204346d77f922615d5fb7e265872e715e95a118d6/hiredis-1.1.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->ray) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->ray) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->ray) (1.24.1)\n",
      "Collecting nvidia-ml-py3>=7.352.0 (from gpustat->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
      "Requirement already satisfied: psutil in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from gpustat->ray) (5.6.1)\n",
      "Collecting blessings>=1.6 (from gpustat->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core<2.0.0,>=1.0.0->opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/74/3956721ea1eb4bcf7502a311fdaa60b85bd751de4e57d1943afe9b334141/googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100kB)\n",
      "Collecting google-auth<2.0dev,>=1.19.1 (from google-api-core<2.0.0,>=1.0.0->opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/79/4c59796bb02535aee5e5d2e2c5e16008aaf48903c2ec2ff566a2774bb3e0/google_auth-1.20.1-py2.py3-none-any.whl (91kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2018.9)\n",
      "Collecting typing-extensions>=3.7.4; python_version < \"3.8\" (from yarl<2.0,>=1.0->aiohttp->ray)\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/0e/3f026d0645d699e7320b59952146d56ad7c374e9cd72cd16e7c74e657a0f/typing_extensions-3.7.4.2-py3-none-any.whl\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from beautifulsoup4->google->ray) (1.8)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\" (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "Building wheels for collected packages: gpustat, nvidia-ml-py3\n",
      "  Building wheel for gpustat (setup.py): started\n",
      "  Building wheel for gpustat (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Mohit\\AppData\\Local\\pip\\Cache\\wheels\\48\\b4\\d5\\fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): started\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Mohit\\AppData\\Local\\pip\\Cache\\wheels\\e4\\1d\\06\\640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "Successfully built gpustat nvidia-ml-py3\n",
      "Installing collected packages: msgpack, opencensus-context, protobuf, googleapis-common-protos, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-api-core, opencensus, async-timeout, multidict, typing-extensions, yarl, aiohttp, google, hiredis, aioredis, colorful, grpcio, prometheus-client, redis, nvidia-ml-py3, blessings, gpustat, py-spy, ray\n",
      "  Found existing installation: msgpack 0.6.1\n",
      "    Uninstalling msgpack-0.6.1:\n",
      "      Successfully uninstalled msgpack-0.6.1\n",
      "  Found existing installation: prometheus-client 0.6.0\n",
      "    Uninstalling prometheus-client-0.6.0:\n",
      "      Successfully uninstalled prometheus-client-0.6.0\n",
      "Successfully installed aiohttp-3.6.2 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 cachetools-4.1.1 colorful-0.5.4 google-3.0.0 google-api-core-1.22.1 google-auth-1.20.1 googleapis-common-protos-1.52.0 gpustat-0.6.0 grpcio-1.31.0 hiredis-1.1.0 msgpack-1.0.0 multidict-4.7.6 nvidia-ml-py3-7.352.0 opencensus-0.7.10 opencensus-context-0.1.1 prometheus-client-0.8.0 protobuf-3.13.0 py-spy-0.3.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 ray-0.8.7 redis-3.4.1 rsa-4.6 typing-extensions-3.7.4.2 yarl-1.5.1\n",
      "Requirement already satisfied: xlrd in c:\\users\\mohit\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\mohit\\anaconda3\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from nltk) (3.4.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\mohit\\anaconda3\\lib\\site-packages (4.31.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\mohit\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from gensim) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: bz2file in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (1.10.39)\n",
      "Requirement already satisfied: requests in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (2.21.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.39 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim) (1.13.39)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from botocore<1.14.0,>=1.13.39->boto3->smart_open>=1.2.1->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\mohit\\anaconda3\\lib\\site-packages (from botocore<1.14.0,>=1.13.39->boto3->smart_open>=1.2.1->gensim) (0.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohit\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import random\n",
    "!pip install ray\n",
    "import ray\n",
    "import xml.etree.ElementTree as ET\n",
    "# ray.init()\n",
    "!pip install xlrd\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import glob\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "!pip install gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer - noun lemma -- https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\n",
    "def lemma(word): return nltk.stem.WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "# preprocss the word - lowercase and lemma\n",
    "def pre(word): return lemma(word.lower())\n",
    "\n",
    "def check_word(word): return \" \" not in word and \".\" not in word and \"-\" not in word and \"/\" not in word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-31060c96-802e-45cc-a527-ef28db976abe",
    "tags": []
   },
   "source": [
    "## Load similarity/relatedness dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00003-498c0693-1ca7-4c9e-ad7d-b58ca2b2f18e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN-MC-30\n",
      "EN-MEN-TR-3k\n",
      "EN-MTurk-287\n",
      "EN-MTurk-771\n",
      "EN-RG-65\n",
      "EN-RW-STANFORD\n",
      "EN-SIMLEX-999\n",
      "EN-SimVerb-3500\n",
      "EN-VERB-143\n",
      "EN-WS-353-ALL\n",
      "EN-WS-353-REL\n",
      "EN-WS-353-SIM\n",
      "EN-YP-130\n"
     ]
    }
   ],
   "source": [
    "# load the files\n",
    "def load_similarity_datasets():\n",
    "    \"\"\"Load all (13) datasets which can be used to test word interchangeable similarity\n",
    "    \"\"\"\n",
    "    sim_data = {}\n",
    "    for file_path in glob.glob(\"../data/word-sim/*\"):\n",
    "        file_name = file_path[17:].replace(\".txt\", \"\")\n",
    "        print(file_name)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
    "            df.columns = ['word_1', 'word_2', 'similarity_score']\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "            df.columns = ['word_1', 'word_2', 'similarity_score']\n",
    "        sim_data[file_name] = df\n",
    "    return sim_data\n",
    "\n",
    "# load similarity datasets\n",
    "similarity_datasets = load_similarity_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-590b2013-594e-47e2-b9fb-dbe444415ca6",
    "tags": []
   },
   "source": [
    "## Load association datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "cell_id": "00007-4f50110c-4d40-46d0-b8bd-143d0b0d36bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_r123_strength_table(cue_data, cue_name):\n",
    "    # calculate R123 strength\n",
    "    responses = cue_data.loc[:, ['R1', 'R2', 'R3']].values.reshape(1, -1)[0]\n",
    "    responses = [pre(x) for x in responses if str(x) != \"nan\" if \"-\" not in str(x)]\n",
    "    responses = pd.DataFrame.from_dict(Counter(responses), orient='index').reset_index()\n",
    "    responses.columns = ['response', 'R123']\n",
    "    responses.loc[:, 'N'] = responses['R123'].sum()\n",
    "    responses.loc[:, 'R123.Str'] = responses['R123'] / responses['N']\n",
    "    responses.loc[:, 'cue'] = pre(cue_name)\n",
    "    return responses\n",
    "\n",
    "def prepare_swow_8500():\n",
    "    # handle swow-8500\n",
    "    data = pd.read_excel(\"../data/association/swow-8500.xlsx\")\n",
    "    swow_8500 = []\n",
    "    for cue_name, cue_data in tqdm(data.groupby(['cue']), position=0, leave=True, desc=\"Loading SWOW\"):\n",
    "        if \" \" in str(cue_name):\n",
    "            continue\n",
    "        swow_8500.append(prepare_r123_strength_table(cue_data, cue_name))\n",
    "    swow_8500 = pd.concat(swow_8500)\n",
    "    return swow_8500\n",
    "\n",
    "# swow_8500_df = prepare_swow_8500(df)\n",
    "\n",
    "def prepare_eat_dataset():\n",
    "    \"\"\"http://rali.iro.umontreal.ca/rali/?q=en/Textual%20Resources/EAT\n",
    "    \"\"\"\n",
    "    tree = ET.parse('../data/association/eat-stimulus-response.xml')\n",
    "    root = tree.getroot()\n",
    "    eat_table = []\n",
    "    for stimulus in tqdm(root.findall(\"stimulus\"), position=0, leave=True, desc=\"Loading EAT\"):\n",
    "        stimulus_word = stimulus.attrib['word']\n",
    "        if check_word(stimulus_word):\n",
    "            for res in stimulus.findall(\"response\"):\n",
    "                res_word = res.attrib['word']\n",
    "                if check_word(res_word):\n",
    "                    eat_table.append({'cue': pre(stimulus_word), 'response': pre(res_word), \n",
    "                               'occ_count': res.attrib['n'], 'occ_conf': res.attrib['r']})\n",
    "    eat_table = pd.DataFrame.from_dict(eat_table)\n",
    "    return eat_table\n",
    "\n",
    "def load_association_dataset():\n",
    "    return {\"swow8500\": prepare_swow_8500(), \"eat\": prepare_eat_dataset()}\n",
    "\n",
    "association_datasets = load_association_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Analogy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_google_analogy():\n",
    "    google_analogy={}\n",
    "    with open(\"../data/analogy/google_analogy_set.txt\", 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            if \":\" in line: # its a title\n",
    "                title = line[2:]\n",
    "                google_analogy[title] = []\n",
    "            else:\n",
    "                analogy = [pre(x) for x in line.split() if check_word(x)]\n",
    "                if len(analogy) == 4:\n",
    "                    google_analogy[title].append(analogy)\n",
    "    return google_analogy\n",
    "\n",
    "# x = load_google_analogy()\n",
    "\n",
    "\n",
    "def load_bats_analogy():\n",
    "    random.seed(0)\n",
    "    file_analogy = []\n",
    "    for section_path in glob.glob(\"../data/analogy/BATS_3.0/[0-9]*\"):\n",
    "        if \"Inflectional_morphology\" in section_path:\n",
    "            continue\n",
    "        section_name = section_path[10:]\n",
    "        for file_path in glob.glob(section_path+\"/*\"):\n",
    "            file_name = file_path.replace(section_path, \"\")\n",
    "            file_analogy_prefix = []\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    analogy_prefix = [pre(x) for x in line.split() if check_word(x)]\n",
    "                    if len(set(analogy_prefix)) == 2:\n",
    "                        file_analogy_prefix.append(analogy_prefix)\n",
    "            random_choices=63\n",
    "            if len(file_analogy_prefix) > random_choice*1:\n",
    "                for _ in range(random_choices):\n",
    "                    a, b = random.sample(file_analogy_prefix, 2)\n",
    "                    a, b = a.copy(), b.copy()\n",
    "                    a+=b\n",
    "                    file_analogy.append(a)\n",
    "    file_analogy = [x for x in file_analogy if len(set(x)) == 4]\n",
    "    return file_analogy\n",
    "\n",
    "file_analogy = load_bats_analogy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [
   {
    "cellId": "00004-c07a83e9-3fdd-46cf-8ec5-d466f2bd177f",
    "msgId": "e0dc82d5-3a82-4ab4-8e68-bc0132d7221d",
    "sessionId": "af3e297c-ecda-4b4d-9ba5-5193a7bea19d"
   }
  ],
  "deepnote_notebook_id": "3bec70f7-4277-4683-a3e5-692e28462d6a",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
