{"cells":[{"cell_type":"markdown","source":"# Word2Vec models comparison\n\nWe compare the different models of word2vec against different intrinsic word embeddings tasks.","metadata":{"cell_id":"00001-041ba339-031d-426b-8697-9dda6244991a","tags":[]}},{"cell_type":"markdown","source":"### Import and load datasets","metadata":{"cell_id":"00001-7d1cb22c-84e3-419d-8987-607100f4798d","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00002-3b9bb0a0-e60c-4aee-8287-c11f6e167fc0","tags":[]},"source":"# imports\nimport pickle\nimport random\n!pip install ray\nimport ray\nimport xml.etree.ElementTree as ET\n# ray.init()\n!pip install xlrd\n!pip install nltk\nimport nltk\nnltk.download('wordnet')\nimport glob\n!pip install tqdm\nfrom tqdm import tqdm\nimport pandas as pd\n!pip install gensim\nfrom gensim.models import KeyedVectors\nfrom gensim.models.word2vec import Word2Vec\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ray in /opt/venv/lib/python3.7/site-packages (0.8.7)\nRequirement already satisfied: redis<3.5.0,>=3.3.2 in /opt/venv/lib/python3.7/site-packages (from ray) (3.4.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/venv/lib/python3.7/site-packages (from ray) (1.0.0)\nRequirement already satisfied: colorama in /opt/venv/lib/python3.7/site-packages (from ray) (0.4.3)\nRequirement already satisfied: jsonschema in /opt/venv/lib/python3.7/site-packages (from ray) (3.2.0)\nRequirement already satisfied: aioredis in /opt/venv/lib/python3.7/site-packages (from ray) (1.3.1)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from ray) (0.8.0)\nRequirement already satisfied: click>=7.0 in /opt/venv/lib/python3.7/site-packages (from ray) (7.1.2)\nRequirement already satisfied: google in /opt/venv/lib/python3.7/site-packages (from ray) (3.0.0)\nRequirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from ray) (2.24.0)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/venv/lib/python3.7/site-packages (from ray) (0.3.3)\nRequirement already satisfied: protobuf>=3.8.0 in /opt/venv/lib/python3.7/site-packages (from ray) (3.12.4)\nRequirement already satisfied: colorful in /opt/venv/lib/python3.7/site-packages (from ray) (0.5.4)\nRequirement already satisfied: pyyaml in /opt/venv/lib/python3.7/site-packages (from ray) (5.3.1)\nRequirement already satisfied: opencensus in /opt/venv/lib/python3.7/site-packages (from ray) (0.7.10)\nRequirement already satisfied: aiohttp in /opt/venv/lib/python3.7/site-packages (from ray) (3.6.2)\nRequirement already satisfied: numpy>=1.16 in /opt/venv/lib/python3.7/site-packages (from ray) (1.18.5)\nRequirement already satisfied: filelock in /opt/venv/lib/python3.7/site-packages (from ray) (3.0.12)\nRequirement already satisfied: grpcio>=1.28.1 in /opt/venv/lib/python3.7/site-packages (from ray) (1.31.0)\nRequirement already satisfied: gpustat in /opt/venv/lib/python3.7/site-packages (from ray) (0.6.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (1.7.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (0.16.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (19.3.0)\nRequirement already satisfied: six>=1.11.0 in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (1.15.0)\nRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (47.3.1)\nRequirement already satisfied: async-timeout in /opt/venv/lib/python3.7/site-packages (from aioredis->ray) (3.0.1)\nRequirement already satisfied: hiredis in /opt/venv/lib/python3.7/site-packages (from aioredis->ray) (1.1.0)\nRequirement already satisfied: beautifulsoup4 in /opt/venv/lib/python3.7/site-packages (from google->ray) (4.9.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (1.25.9)\nRequirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /opt/venv/lib/python3.7/site-packages (from opencensus->ray) (1.22.1)\nRequirement already satisfied: opencensus-context==0.1.1 in /opt/venv/lib/python3.7/site-packages (from opencensus->ray) (0.1.1)\nRequirement already satisfied: multidict<5.0,>=4.5 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray) (4.7.6)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray) (1.5.1)\nRequirement already satisfied: blessings>=1.6 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray) (1.7)\nRequirement already satisfied: psutil in /opt/venv/lib/python3.7/site-packages (from gpustat->ray) (5.7.2)\nRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray) (7.352.0)\nRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray) (3.1.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/venv/lib/python3.7/site-packages (from beautifulsoup4->google->ray) (2.0.1)\nRequirement already satisfied: google-auth<2.0dev,>=1.19.1 in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.20.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.52.0)\nRequirement already satisfied: pytz in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2020.1)\nRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->ray) (3.7.4.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.1.1)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.6)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: xlrd in /opt/venv/lib/python3.7/site-packages (1.2.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: nltk in /opt/venv/lib/python3.7/site-packages (3.5)\nRequirement already satisfied: click in /opt/venv/lib/python3.7/site-packages (from nltk) (7.1.2)\nRequirement already satisfied: regex in /opt/venv/lib/python3.7/site-packages (from nltk) (2020.7.14)\nRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (from nltk) (4.48.2)\nRequirement already satisfied: joblib in /opt/venv/lib/python3.7/site-packages (from nltk) (0.16.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\nRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (4.48.2)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: gensim in /opt/venv/lib/python3.7/site-packages (3.8.3)\nRequirement already satisfied: scipy>=0.18.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.5.1)\nRequirement already satisfied: numpy>=1.11.3 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.18.5)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (2.1.0)\nRequirement already satisfied: six>=1.5.0 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.15.0)\nRequirement already satisfied: boto in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: boto3 in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.44)\nRequirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\nRequirement already satisfied: botocore<1.18.0,>=1.17.44 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.44)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\nRequirement already satisfied: docutils<0.16,>=0.10 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.44->boto3->smart-open>=1.8.1->gensim) (0.15.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.44->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00003-5bb28d92-0786-44ba-865d-7b3cef2d7bd6"},"source":"# lemmatizer - noun lemma -- https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\ndef lemma(word): return nltk.stem.WordNetLemmatizer().lemmatize(word)\n\n# preprocss the word - lowercase and lemma\ndef pre(word): return lemma(word.lower())\n\ndef check_word(word): return \" \" not in word and \".\" not in word and \"-\" not in word and \"/\" not in word","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load similarity/relatedness dataset","metadata":{"cell_id":"00003-31060c96-802e-45cc-a527-ef28db976abe","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00003-498c0693-1ca7-4c9e-ad7d-b58ca2b2f18e","tags":[]},"source":"# load the files\ndef load_similarity_datasets():\n    \"\"\"Load all (13) datasets which can be used to test word interchangeable similarity\n    \"\"\"\n    sim_data = {}\n    for file_path in glob.glob(\"../data/word-sim/*\"):\n        file_name = file_path[17:].replace(\".txt\", \"\")\n        print(file_name)\n        try:\n            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n            df.columns = ['word_1', 'word_2', 'similarity_score']\n        except:\n            df = pd.read_csv(file_path, sep=\" \", header=None)\n            df.columns = ['word_1', 'word_2', 'similarity_score']\n        sim_data[file_name] = df\n    return sim_data\n\n# load similarity datasets\nsimilarity_datasets = load_similarity_datasets()","execution_count":null,"outputs":[{"name":"stdout","text":"EN-VERB-143\nEN-SimVerb-3500\nEN-RG-65\nEN-RW-STANFORD\nEN-MTurk-771\nEN-MEN-TR-3k\nEN-MC-30\nEN-MTurk-287\nEN-SIMLEX-999\nEN-WS-353-REL\nEN-YP-130\nEN-WS-353-ALL\nEN-WS-353-SIM\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load association datasets","metadata":{"cell_id":"00004-590b2013-594e-47e2-b9fb-dbe444415ca6","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00007-4f50110c-4d40-46d0-b8bd-143d0b0d36bc","tags":[]},"source":"def prepare_r123_strength_table(cue_data, cue_name):\n    # calculate R123 strength\n    responses = cue_data.loc[:, ['R1', 'R2', 'R3']].values.reshape(1, -1)[0]\n    responses = [pre(str(x)) for x in responses if str(x) != \"nan\" if \"-\" not in str(x)]\n    responses = pd.DataFrame.from_dict(Counter(responses), orient='index').reset_index()\n    responses.columns = ['response', 'R123']\n    responses.loc[:, 'N'] = responses['R123'].sum()\n    responses.loc[:, 'R123.Str'] = responses['R123'] / responses['N']\n    responses.loc[:, 'cue'] = pre(str(cue_name))\n    return responses\n\ndef prepare_swow_8500(conf_filter=0.1):\n    \"\"\"Return swow words with r123.str >= conf_filter (default:0.1 leads to 8270 unqiue cues)\n    \"\"\"\n    # handle swow-8500\n    data = pd.read_excel(\"../data/association/swow-8500.xlsx\")\n    swow_8500 = []\n    for cue_name, cue_data in tqdm(data.groupby(['cue']), position=0, leave=True, desc=\"Loading SWOW\"):\n        if \" \" in str(cue_name):\n            continue\n        swow_8500.append(prepare_r123_strength_table(cue_data, cue_name))\n    swow_8500 = pd.concat(swow_8500)\n    swow_8500 = swow_8500.loc[swow_8500['R123.Str']>=conf_filter]\n    return swow_8500\n\n# swow_8500_df = prepare_swow_8500(df)\n\ndef clean_eat_dataset(data, conf_filter=0.1):\n    data.loc[:, 'occ_conf'] = data.loc[:, 'occ_conf'].astype(float)\n    data.loc[:, 'occ_count'] = data.loc[:, 'occ_count'].astype(int)\n    data = data.query(f\"occ_conf >= {conf_filter}\")\n    return data\n\ndef prepare_eat_dataset(conf_filter=0.1):\n    \"\"\"http://rali.iro.umontreal.ca/rali/?q=en/Textual%20Resources/EAT\n    \"\"\"\n    tree = ET.parse('../data/association/eat-stimulus-response.xml')\n    root = tree.getroot()\n    eat_table = []\n    for stimulus in tqdm(root.findall(\"stimulus\"), position=0, leave=True, desc=\"Loading EAT\"):\n        stimulus_word = stimulus.attrib['word']\n        if check_word(stimulus_word):\n            for res in stimulus.findall(\"response\"):\n                res_word = res.attrib['word']\n                if check_word(res_word):\n                    eat_table.append({'cue': pre(stimulus_word), 'response': pre(res_word), \n                               'occ_count': res.attrib['n'], 'occ_conf': res.attrib['r']})\n    eat_table = pd.DataFrame.from_dict(eat_table)\n    return clean_eat_dataset(eat_table, conf_filter=0.1)\n\ndef load_association_dataset():\n    return {\"swow8500\": prepare_swow_8500(), \"eat\": prepare_eat_dataset()}\n\nassociation_datasets = load_association_dataset()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00008-faf0e6eb-76a3-49cf-bab1-f2247ea8c655"},"source":"# # association_datasets['eat']['occ_count'].astype(int)\n# eat_dataset = []\n# for cue_name, cue_data in association_datasets['eat'].groupby(['cue']):\n#     cue_data_copy = cue_data.copy()\n#     cue_data_copy.loc[:, 'occ_conf'] = cue_data_copy.loc[:, 'occ_conf'].astype(float)\n#     cue_data_copy.loc[:, 'occ_count'] = cue_data_copy.loc[:, 'occ_count'].astype(int)\n#     cue_data_copy.loc[:, 'occ_conf'] = cue_data_copy['occ_count']/cue_data_copy['occ_count'].sum()\n#     eat_dataset.append(cue_data_copy)\n# eat_dataset = pd.concat(eat_dataset)\n\nx.query(\"occ_conf >= 0.1\")['cue'].nunique()","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"6673"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00010-41ff796f-ec5d-4b83-8e39-4fcc69652cd9"},"source":"# association_datasets['eat']['occ_conf'].astype(float).describe()\n# x = clean_eat_dataset(association_datasets['eat'].copy())\nassociation_datasets['eat']['cue'].nunique()","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"7182"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load Analogy datasets","metadata":{"cell_id":"00008-40b22d64-e52f-438e-a078-e032dd8565ab"}},{"cell_type":"code","metadata":{"cell_id":"00009-cc482826-3fea-4a95-b456-492ff9236637"},"source":"def load_google_analogy():\n    google_analogy={}\n    with open(\"../data/analogy/google_analogy_set.txt\", 'r') as f:\n        for line in f:\n            line = line.replace(\"\\n\", \"\")\n            if \":\" in line: # its a title\n                title = line[2:]\n                google_analogy[title] = []\n            else:\n                analogy = [pre(x) for x in line.split() if check_word(x)]\n                if len(analogy) == 4:\n                    google_analogy[title].append(analogy)\n    return google_analogy\n\n# x = load_google_analogy()\n\n\ndef load_bats_analogy():\n    random.seed(0)\n    file_analogy = []\n    for section_path in glob.glob(\"../data/analogy/BATS_3.0/[0-9]*\"):\n        if \"Inflectional_morphology\" in section_path:\n            continue\n        section_name = section_path[10:]\n        for file_path in glob.glob(section_path+\"/*\"):\n            file_name = file_path.replace(section_path, \"\")\n            file_analogy_prefix = []\n            with open(file_path, 'r') as f:\n                for line in f:\n                    analogy_prefix = [pre(x) for x in line.split() if check_word(x)]\n                    if len(set(analogy_prefix)) == 2:\n                        file_analogy_prefix.append(analogy_prefix)\n            random_choices=63\n            if len(file_analogy_prefix) > random_choices*1:\n                for _ in range(random_choices):\n                    a, b = random.sample(file_analogy_prefix, 2)\n                    a, b = a.copy(), b.copy()\n                    a+=b\n                    file_analogy.append(a)\n    file_analogy = [x for x in file_analogy if len(set(x)) == 4]\n    return file_analogy\n\nfile_analogy = load_bats_analogy()\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test dataset file","metadata":{"tags":[],"cell_id":"00013-7bb233b0-4b5a-4bc5-b123-d415bcc9c12b"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00014-949b7faa-c2ea-416c-b864-88b87f375f3d"},"source":"import pickle\nwith open(\"../data/all_datasets.pickle\", 'rb') as f:\n    all_dataset = pickle.load(f)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-7d5c48f7-1016-4de9-a670-eff9309355f2"},"source":"all_dataset['association_datasets']['eat']['cue'].nunique()","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"6673"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"00014-21021de1-20f7-40cd-a15a-76a9a4e7e67a"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"3bec70f7-4277-4683-a3e5-692e28462d6a","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}}}