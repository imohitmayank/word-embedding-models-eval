{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-3e5dd85b-a83f-41e3-81ec-63465c987242",
    "tags": []
   },
   "source": [
    "# Word2Vec models comparison\n",
    "\n",
    "We compare the different models of word2vec against different intrinsic word embeddings tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-1d47f6bc-3830-48d3-969f-6f724ac6e2ca",
    "tags": []
   },
   "source": [
    "### Import and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-9e2b57be-6c76-439b-9f0e-24ee9215ace3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray\n",
      "  Downloading ray-0.8.7-cp37-cp37m-manylinux1_x86_64.whl (22.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.0 MB 3.0 MB/s eta 0:00:01    |████▊                           | 3.3 MB 3.0 MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 74.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /opt/venv/lib/python3.7/site-packages (from ray) (1.18.5)\n",
      "Collecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 61.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (275 kB)\n",
      "\u001b[K     |████████████████████████████████| 275 kB 59.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting redis<3.5.0,>=3.3.2\n",
      "  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Collecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 55.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gpustat\n",
      "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/venv/lib/python3.7/site-packages (from ray) (3.12.4)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from ray) (0.8.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.6.2-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 56.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.7.10-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 75.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from ray) (2.24.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /opt/venv/lib/python3.7/site-packages (from ray) (1.31.0)\n",
      "Requirement already satisfied: jsonschema in /opt/venv/lib/python3.7/site-packages (from ray) (3.2.0)\n",
      "Collecting click>=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting aioredis\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.7 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray) (1.15.0)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.7.2.tar.gz (460 kB)\n",
      "\u001b[K     |████████████████████████████████| 460 kB 45.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blessings>=1.6\n",
      "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from protobuf>=3.8.0->ray) (47.3.1)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (258 kB)\n",
      "\u001b[K     |████████████████████████████████| 258 kB 48.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<5.0,>=4.5\n",
      "  Downloading multidict-4.7.6-cp37-cp37m-manylinux1_x86_64.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 62.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray) (19.3.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray) (3.0.4)\n",
      "Collecting google-api-core<2.0.0,>=1.0.0\n",
      "  Downloading google_api_core-1.22.1-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencensus-context==0.1.1\n",
      "  Downloading opencensus_context-0.1.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->ray) (2020.6.20)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (1.7.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray) (0.16.0)\n",
      "Collecting hiredis\n",
      "  Downloading hiredis-1.1.0-cp37-cp37m-manylinux2010_x86_64.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting typing-extensions>=3.7.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.2-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.19.1 in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.20.1)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 13.7 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2020.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.19.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n",
      "Building wheels for collected packages: pyyaml, gpustat, nvidia-ml-py3, psutil\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=74d988c94ece68240a3ab9bb264750ffa4c0651aa08753ca8b166c736934424f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=d29c6ee221f7e2d7e73eab0d86ea6b7303c5bc84eb9517df78f555effa392d36\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e6/67/af/f1ad15974b8fd95f59a63dbf854483ebe5c7a46a93930798b8\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19189 sha256=31ea7aad31eabfbce9bfdbca525c18d8e2fdf47a0195b42b2f465b29ab64ad03\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/df/99/da/c34f202dc8fd1dffd35e0ecf1a7d7f8374ca05fbcbaf974b83\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.2-cp37-cp37m-linux_x86_64.whl size=282599 sha256=c5bc0ff2400f2f5458f1aea33a86ba2aaaba90eabd703884094a603cf14278c2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2d/43/97/00701864a7bee6d9e1a52dd682537dcbf1d013d0e2e6f0c1f1\n",
      "Successfully built pyyaml gpustat nvidia-ml-py3 psutil\n",
      "Installing collected packages: pyyaml, colorful, msgpack, redis, colorama, py-spy, nvidia-ml-py3, psutil, blessings, gpustat, soupsieve, beautifulsoup4, google, async-timeout, typing-extensions, multidict, yarl, aiohttp, googleapis-common-protos, google-api-core, opencensus-context, opencensus, filelock, click, hiredis, aioredis, ray\n",
      "Successfully installed aiohttp-3.6.2 aioredis-1.3.1 async-timeout-3.0.1 beautifulsoup4-4.9.1 blessings-1.7 click-7.1.2 colorama-0.4.3 colorful-0.5.4 filelock-3.0.12 google-3.0.0 google-api-core-1.22.1 googleapis-common-protos-1.52.0 gpustat-0.6.0 hiredis-1.1.0 msgpack-1.0.0 multidict-4.7.6 nvidia-ml-py3-7.352.0 opencensus-0.7.10 opencensus-context-0.1.1 psutil-5.7.2 py-spy-0.3.3 pyyaml-5.3.1 ray-0.8.7 redis-3.4.1 soupsieve-2.0.1 typing-extensions-3.7.4.2 yarl-1.5.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "2020-08-18 14:57:58,174\tINFO resource_spec.py:231 -- Starting Ray with 12.94 GiB memory available for workers and up to 6.47 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-08-18 14:57:58,676\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "2020-08-18 14:57:58,681\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-08-18 14:57:58,696\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-08-18 14:57:59,839\tWARNING worker.py:1134 -- The dashboard on node p-302a6336-d27e-43af-93d1-276242f3b519 failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/venv/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 961, in <module>\n",
      "    dashboard.run()\n",
      "  File \"/opt/venv/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 576, in run\n",
      "    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n",
      "  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web.py\", line 433, in run_app\n",
      "    reuse_port=reuse_port))\n",
      "  File \"/usr/local/lib/python3.7/asyncio/base_events.py\", line 584, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web.py\", line 359, in _run_app\n",
      "    await site.start()\n",
      "  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web_runner.py\", line 104, in start\n",
      "    reuse_port=self._reuse_port)\n",
      "  File \"/usr/local/lib/python3.7/asyncio/base_events.py\", line 1378, in create_server\n",
      "    % (sa, err.strerror.lower())) from None\n",
      "OSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n",
      "\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/venv/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/venv/lib/python3.7/site-packages (from nltk) (0.16.0)\n",
      "Collecting regex\n",
      "  Downloading regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (from nltk) (4.48.2)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434676 sha256=3f778d5ff421c14d0458ded89f2e78f1232e84ff8170bda385409be645900447\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
      "Successfully built nltk\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.5 regex-2020.7.14\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "Requirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (4.48.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gensim in /opt/venv/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.5.1)\n",
      "Requirement already satisfied: boto in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: boto3 in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.44)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.44 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.44)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.44->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.44->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "EN-VERB-143\n",
      "EN-SimVerb-3500\n",
      "EN-RG-65\n",
      "EN-RW-STANFORD\n",
      "EN-MTurk-771\n",
      "EN-MEN-TR-3k\n",
      "EN-MC-30\n",
      "EN-MTurk-287\n",
      "EN-SIMLEX-999\n",
      "EN-WS-353-REL\n",
      "EN-YP-130\n",
      "EN-WS-353-ALL\n",
      "EN-WS-353-SIM\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "!pip install ray\n",
    "import ray\n",
    "ray.init()\n",
    "\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import glob\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "!pip install gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# load the files\n",
    "def load_similarity_datasets():\n",
    "    \"\"\"Load all (13) datasets which can be used to test word interchangeable similarity\n",
    "    \"\"\"\n",
    "    sim_data = {}\n",
    "    for file_path in glob.glob(\"../data/word-sim/*\"):\n",
    "        file_name = file_path[17:].replace(\".txt\", \"\")\n",
    "        print(file_name)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
    "            df.columns = ['word_1', 'word_2', 'similarity_score']\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "            df.columns = ['word_1', 'word_2', 'similarity_score']\n",
    "        sim_data[file_name] = df\n",
    "    return sim_data\n",
    "\n",
    "# load similarity datasets\n",
    "similarity_datasets = load_similarity_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-7aa5267f-439e-4e0e-bce0-1c113f44ced3",
    "tags": []
   },
   "source": [
    "### Load word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-b38d3970-71ec-445e-8d56-ee126cda621c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = Word2Vec.load(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0/word2vec_wikiEn20171001_millionSentences_mc=10_iter=5_size=100_window=5_sg=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-0d59b9b7-fd9e-4264-b365-928853de76d4",
    "tags": []
   },
   "source": [
    "### Create Word2vec similarity computing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-53360c62-c699-4129-99da-de30347538ce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word2vec_get_index_by_word(model, word):\n",
    "    \"\"\"Return the index of the word in the model\n",
    "    \"\"\"\n",
    "    return model.wv.index2word.index(word)\n",
    "\n",
    "def word2vec_get_word_by_index(model, index):\n",
    "    \"\"\"Return the word by the provided index\n",
    "    \"\"\"\n",
    "    return model.wv.index2word[index]\n",
    "\n",
    "def word2vec_find_top_similar_words(model, source_word, method='IN-IN', top_n=5, no_self_similarity=True):\n",
    "    \"\"\"\n",
    "    Provided a word, find the top_n most similar from the model following the method\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    input_weights = model.wv.vectors\n",
    "    output_weights = model.trainables.syn1neg\n",
    "    source_word_index = word2vec_get_index_by_word(model, source_word)\n",
    "    if method==\"IN-IN\":\n",
    "        weights1, weights2 = input_weights, input_weights\n",
    "    elif method==\"IN-OUT\":\n",
    "        weights1, weights2 = input_weights, output_weights\n",
    "    elif method==\"OUT-IN\":\n",
    "        weights1, weights2 = output_weights, input_weights\n",
    "    elif method==\"OUT-OUT\":\n",
    "        weights1, weights2 = output_weights, output_weights\n",
    "    score = cosine_similarity(weights1[source_word_index].reshape(1, -1), weights2)[0]\n",
    "    if no_self_similarity:\n",
    "        score[source_word_index] = -1 # negate self-similarity\n",
    "    top_n_similar_words = np.argpartition(-score, top_n)[:top_n]\n",
    "    return sorted([(word2vec_get_word_by_index(model, index), score[index]) for index in top_n_similar_words], \n",
    "                key=lambda x: x[1], \n",
    "                reverse=True)\n",
    "\n",
    "def word2vec_find_similarity(model, source_word, target_word, method=\"IN-IN\"):\n",
    "    \"\"\"Return the cosine similarity between two words based on the suggested method\n",
    "    \"\"\"\n",
    "    input_weights = model.wv.vectors\n",
    "    output_weights = model.trainables.syn1neg\n",
    "    source_word_index = word2vec_get_index_by_word(model, source_word)\n",
    "    target_word_index = word2vec_get_index_by_word(model, target_word)\n",
    "    if method==\"IN-IN\":\n",
    "        weights1, weights2 = input_weights, input_weights\n",
    "    elif method==\"IN-OUT\":\n",
    "        weights1, weights2 = input_weights, output_weights\n",
    "    elif method==\"OUT-IN\":\n",
    "        weights1, weights2 = output_weights, input_weights\n",
    "    elif method==\"OUT-OUT\":\n",
    "        weights1, weights2 = output_weights, output_weights\n",
    "    score = cosine_similarity(weights1[source_word_index].reshape(1, -1), \n",
    "                              weights2[target_word_index].reshape(1, -1))[0]\n",
    "    return score\n",
    "# word2vec_find_similarity(model, \"car\", \"truck\", \"IN-OUT\")\n",
    "# word2vec_find_top_similar_words(model, \"car\", \"IN-IN\")\n",
    "# word2vec_find_top_similar_words(model, \"car\", \"IN-OUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-d3aa3594-05aa-4e59-81cc-bc78b820a6e1",
    "tags": []
   },
   "source": [
    "### Generate stats for one similarity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-80a352e0-31e8-49d8-aa79-e3b9cb2d4f2d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = similarity_datasets['EN-SIMLEX-999'].copy()\n",
    "score_table = []\n",
    "dimension = model.trainables.syn1neg.shape[1]\n",
    "for row in df.to_dict(orient=\"records\"):\n",
    "    methods = [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]\n",
    "    for method in methods:\n",
    "        try:\n",
    "            sim_score = word2vec_find_similarity(model, row['word_1'], row['word_2'], method)[0]\n",
    "        except:\n",
    "            sim_score = None\n",
    "        row[f'word2vec_{dimension}_{method}_sim_score'] = sim_score\n",
    "    score_table.append(row)\n",
    "score_table = pd.DataFrame.from_dict(score_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-338dc9c3-5d82-453c-bc7f-66de541b50f9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "column_count": 5,
       "columns": [
        {
         "dtype": "float64",
         "name": "similarity_score",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.3409898424692416,
            "bin_start": 0.26776649163249067,
            "count": 3
           },
           {
            "bin_end": 0.41421319330599254,
            "bin_start": 0.3409898424692416,
            "count": 1
           },
           {
            "bin_end": 0.4874365441427435,
            "bin_start": 0.41421319330599254,
            "count": 0
           },
           {
            "bin_end": 0.5606598949794944,
            "bin_start": 0.4874365441427435,
            "count": 0
           },
           {
            "bin_end": 0.6338832458162453,
            "bin_start": 0.5606598949794944,
            "count": 0
           },
           {
            "bin_end": 0.7071065966529964,
            "bin_start": 0.6338832458162453,
            "count": 0
           },
           {
            "bin_end": 0.7803299474897473,
            "bin_start": 0.7071065966529964,
            "count": 0
           },
           {
            "bin_end": 0.8535532983264982,
            "bin_start": 0.7803299474897473,
            "count": 0
           },
           {
            "bin_end": 0.9267766491632491,
            "bin_start": 0.8535532983264982,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9267766491632491,
            "count": 1
           }
          ],
          "max": 1,
          "min": 0.26776649163249067,
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "float64",
         "name": "word2vec_100_IN-IN_sim_score",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.4404693645057322,
            "bin_start": 0.378299293895258,
            "count": 1
           },
           {
            "bin_end": 0.5026394351162065,
            "bin_start": 0.4404693645057322,
            "count": 0
           },
           {
            "bin_end": 0.5648095057266806,
            "bin_start": 0.5026394351162065,
            "count": 0
           },
           {
            "bin_end": 0.6269795763371548,
            "bin_start": 0.5648095057266806,
            "count": 0
           },
           {
            "bin_end": 0.689149646947629,
            "bin_start": 0.6269795763371548,
            "count": 2
           },
           {
            "bin_end": 0.7513197175581032,
            "bin_start": 0.689149646947629,
            "count": 0
           },
           {
            "bin_end": 0.8134897881685774,
            "bin_start": 0.7513197175581032,
            "count": 1
           },
           {
            "bin_end": 0.8756598587790516,
            "bin_start": 0.8134897881685774,
            "count": 0
           },
           {
            "bin_end": 0.9378299293895258,
            "bin_start": 0.8756598587790516,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9378299293895258,
            "count": 1
           }
          ],
          "max": 1,
          "min": 0.378299293895258,
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "float64",
         "name": "word2vec_100_IN-OUT_sim_score",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.35590176047779665,
            "bin_start": 0.28433528941977404,
            "count": 1
           },
           {
            "bin_end": 0.42746823153581925,
            "bin_start": 0.35590176047779665,
            "count": 0
           },
           {
            "bin_end": 0.4990347025938418,
            "bin_start": 0.42746823153581925,
            "count": 1
           },
           {
            "bin_end": 0.5706011736518644,
            "bin_start": 0.4990347025938418,
            "count": 0
           },
           {
            "bin_end": 0.642167644709887,
            "bin_start": 0.5706011736518644,
            "count": 1
           },
           {
            "bin_end": 0.7137341157679096,
            "bin_start": 0.642167644709887,
            "count": 0
           },
           {
            "bin_end": 0.7853005868259322,
            "bin_start": 0.7137341157679096,
            "count": 0
           },
           {
            "bin_end": 0.8568670578839548,
            "bin_start": 0.7853005868259322,
            "count": 0
           },
           {
            "bin_end": 0.9284335289419774,
            "bin_start": 0.8568670578839548,
            "count": 1
           },
           {
            "bin_end": 1,
            "bin_start": 0.9284335289419774,
            "count": 1
           }
          ],
          "max": 1,
          "min": 0.28433528941977404,
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "float64",
         "name": "word2vec_100_OUT-IN_sim_score",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.3409898424692416,
            "bin_start": 0.26776649163249067,
            "count": 1
           },
           {
            "bin_end": 0.41421319330599254,
            "bin_start": 0.3409898424692416,
            "count": 0
           },
           {
            "bin_end": 0.4874365441427435,
            "bin_start": 0.41421319330599254,
            "count": 1
           },
           {
            "bin_end": 0.5606598949794944,
            "bin_start": 0.4874365441427435,
            "count": 0
           },
           {
            "bin_end": 0.6338832458162453,
            "bin_start": 0.5606598949794944,
            "count": 0
           },
           {
            "bin_end": 0.7071065966529964,
            "bin_start": 0.6338832458162453,
            "count": 1
           },
           {
            "bin_end": 0.7803299474897473,
            "bin_start": 0.7071065966529964,
            "count": 0
           },
           {
            "bin_end": 0.8535532983264982,
            "bin_start": 0.7803299474897473,
            "count": 0
           },
           {
            "bin_end": 0.9267766491632491,
            "bin_start": 0.8535532983264982,
            "count": 1
           },
           {
            "bin_end": 1,
            "bin_start": 0.9267766491632491,
            "count": 1
           }
          ],
          "max": 1,
          "min": 0.26776649163249067,
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "float64",
         "name": "word2vec_100_OUT-OUT_sim_score",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.39415230661256667,
            "bin_start": 0.3268358962361852,
            "count": 1
           },
           {
            "bin_end": 0.46146871698894815,
            "bin_start": 0.39415230661256667,
            "count": 0
           },
           {
            "bin_end": 0.5287851273653297,
            "bin_start": 0.46146871698894815,
            "count": 2
           },
           {
            "bin_end": 0.5961015377417112,
            "bin_start": 0.5287851273653297,
            "count": 0
           },
           {
            "bin_end": 0.6634179481180926,
            "bin_start": 0.5961015377417112,
            "count": 0
           },
           {
            "bin_end": 0.7307343584944741,
            "bin_start": 0.6634179481180926,
            "count": 0
           },
           {
            "bin_end": 0.7980507688708556,
            "bin_start": 0.7307343584944741,
            "count": 1
           },
           {
            "bin_end": 0.865367179247237,
            "bin_start": 0.7980507688708556,
            "count": 0
           },
           {
            "bin_end": 0.9326835896236185,
            "bin_start": 0.865367179247237,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9326835896236185,
            "count": 1
           }
          ],
          "max": 1,
          "min": 0.3268358962361852,
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "_deepnote_index_column"
        }
       ],
       "row_count": 5,
       "rows_bottom": null,
       "rows_top": [
        {
         "_deepnote_index_column": "similarity_score",
         "similarity_score": 1,
         "word2vec_100_IN-IN_sim_score": 0.378299293895258,
         "word2vec_100_IN-OUT_sim_score": 0.28433528941977404,
         "word2vec_100_OUT-IN_sim_score": 0.26776649163249067,
         "word2vec_100_OUT-OUT_sim_score": 0.3268358962361852
        },
        {
         "_deepnote_index_column": "word2vec_100_IN-IN_sim_score",
         "similarity_score": 0.378299293895258,
         "word2vec_100_IN-IN_sim_score": 1,
         "word2vec_100_IN-OUT_sim_score": 0.6290711764425195,
         "word2vec_100_OUT-IN_sim_score": 0.64211004201536,
         "word2vec_100_OUT-OUT_sim_score": 0.7906238382155103
        },
        {
         "_deepnote_index_column": "word2vec_100_IN-OUT_sim_score",
         "similarity_score": 0.28433528941977404,
         "word2vec_100_IN-IN_sim_score": 0.6290711764425195,
         "word2vec_100_IN-OUT_sim_score": 1,
         "word2vec_100_OUT-IN_sim_score": 0.9209477013494461,
         "word2vec_100_OUT-OUT_sim_score": 0.4752112857861825
        },
        {
         "_deepnote_index_column": "word2vec_100_OUT-IN_sim_score",
         "similarity_score": 0.26776649163249067,
         "word2vec_100_IN-IN_sim_score": 0.64211004201536,
         "word2vec_100_IN-OUT_sim_score": 0.9209477013494461,
         "word2vec_100_OUT-IN_sim_score": 1,
         "word2vec_100_OUT-OUT_sim_score": 0.4751503500242323
        },
        {
         "_deepnote_index_column": "word2vec_100_OUT-OUT_sim_score",
         "similarity_score": 0.3268358962361852,
         "word2vec_100_IN-IN_sim_score": 0.7906238382155103,
         "word2vec_100_IN-OUT_sim_score": 0.4752112857861825,
         "word2vec_100_OUT-IN_sim_score": 0.4751503500242323,
         "word2vec_100_OUT-OUT_sim_score": 1
        }
       ]
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>word2vec_100_IN-IN_sim_score</th>\n",
       "      <th>word2vec_100_IN-OUT_sim_score</th>\n",
       "      <th>word2vec_100_OUT-IN_sim_score</th>\n",
       "      <th>word2vec_100_OUT-OUT_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>similarity_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378299</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.267766</td>\n",
       "      <td>0.326836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_100_IN-IN_sim_score</th>\n",
       "      <td>0.378299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629071</td>\n",
       "      <td>0.642110</td>\n",
       "      <td>0.790624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_100_IN-OUT_sim_score</th>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.629071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920948</td>\n",
       "      <td>0.475211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_100_OUT-IN_sim_score</th>\n",
       "      <td>0.267766</td>\n",
       "      <td>0.642110</td>\n",
       "      <td>0.920948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_100_OUT-OUT_sim_score</th>\n",
       "      <td>0.326836</td>\n",
       "      <td>0.790624</td>\n",
       "      <td>0.475211</td>\n",
       "      <td>0.475150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                similarity_score  \\\n",
       "similarity_score                        1.000000   \n",
       "word2vec_100_IN-IN_sim_score            0.378299   \n",
       "word2vec_100_IN-OUT_sim_score           0.284335   \n",
       "word2vec_100_OUT-IN_sim_score           0.267766   \n",
       "word2vec_100_OUT-OUT_sim_score          0.326836   \n",
       "\n",
       "                                word2vec_100_IN-IN_sim_score  \\\n",
       "similarity_score                                    0.378299   \n",
       "word2vec_100_IN-IN_sim_score                        1.000000   \n",
       "word2vec_100_IN-OUT_sim_score                       0.629071   \n",
       "word2vec_100_OUT-IN_sim_score                       0.642110   \n",
       "word2vec_100_OUT-OUT_sim_score                      0.790624   \n",
       "\n",
       "                                word2vec_100_IN-OUT_sim_score  \\\n",
       "similarity_score                                     0.284335   \n",
       "word2vec_100_IN-IN_sim_score                         0.629071   \n",
       "word2vec_100_IN-OUT_sim_score                        1.000000   \n",
       "word2vec_100_OUT-IN_sim_score                        0.920948   \n",
       "word2vec_100_OUT-OUT_sim_score                       0.475211   \n",
       "\n",
       "                                word2vec_100_OUT-IN_sim_score  \\\n",
       "similarity_score                                     0.267766   \n",
       "word2vec_100_IN-IN_sim_score                         0.642110   \n",
       "word2vec_100_IN-OUT_sim_score                        0.920948   \n",
       "word2vec_100_OUT-IN_sim_score                        1.000000   \n",
       "word2vec_100_OUT-OUT_sim_score                       0.475150   \n",
       "\n",
       "                                word2vec_100_OUT-OUT_sim_score  \n",
       "similarity_score                                      0.326836  \n",
       "word2vec_100_IN-IN_sim_score                          0.790624  \n",
       "word2vec_100_IN-OUT_sim_score                         0.475211  \n",
       "word2vec_100_OUT-IN_sim_score                         0.475150  \n",
       "word2vec_100_OUT-OUT_sim_score                        1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table.dropna().corr(\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-0ee6049a-6cce-4f29-b41d-db37bcd57547",
    "tags": []
   },
   "source": [
    "## Generate similarity score for each similarity datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-8f52192d-aa1f-495d-89ad-5b52b2a358df",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ],
   "source": [
    "# lemmatizer - noun lemma -- https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\n",
    "def lemma(word): return nltk.stem.WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "# preprocss the word - lowercase and lemma\n",
    "def pre(word): return lemma(word.lower())\n",
    "\n",
    "all_df_res = []\n",
    "all_missing_words = []\n",
    "\n",
    "@ray.remote\n",
    "def compare_word2vec_model_with_dataset(model, model_name, dataset_name, dataset):\n",
    "    missing_words = 0\n",
    "    score_table = []\n",
    "    for row in dataset.to_dict(orient=\"records\"):\n",
    "        methods = [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]\n",
    "        for method in methods:\n",
    "            try:\n",
    "                sim_score = word2vec_find_similarity(model, pre(row['word_1']), pre(row['word_2']), method)[0]\n",
    "            except:\n",
    "                sim_score = None\n",
    "                missing_words += 1\n",
    "            row[f\"{model_name}_{method}\"] = sim_score\n",
    "        score_table.append(row)\n",
    "    score_table = pd.DataFrame.from_dict(score_table)\n",
    "    score_table = score_table.dropna().corr(\"pearson\")[['similarity_score']].tail(4)\n",
    "    score_table.columns = [dataset_name]\n",
    "    missing_words = missing_words/len(methods)\n",
    "    return score_table, dataset_name, missing_words\n",
    "\n",
    "for model_dir in tqdm(glob.glob(\"../../../embeddings_lemma/word2vec_*\")[3:]):\n",
    "    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n",
    "    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n",
    "    model = Word2Vec.load(model_path)\n",
    "    # print(\"Running analysis on each dataset\")\n",
    "    futures = [compare_word2vec_model_with_dataset.remote(model, model_name, dataset_name, dataset) \\\n",
    "                    for dataset_name, dataset in similarity_datasets.items()]\n",
    "    res = ray.get(futures)    \n",
    "    # print(\"Post processing and Saving results\")\n",
    "    # pd.concat(res, axis=1)\n",
    "    df_res = pd.concat([df_res for df_res, _, _ in res], axis=1)\n",
    "    missing_words = {key:val for _, key, val in res}\n",
    "    all_df_res.append(df_res)\n",
    "    all_missing_words.append(missing_words)\n",
    "    with open(\"word2vec_results1.pickle\", \"wb\") as f:\n",
    "        pickle.dump({\"score_matrix\": all_df_res, 'missing_words': all_missing_words}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "allow_embed": false,
    "cell_id": "00012-1bf4c181-882e-4c11-8704-ec97b5fa2b31",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "column_count": 13,
       "columns": [
        {
         "dtype": "float64",
         "name": "EN-VERB-143",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.21500174295258992,
            "bin_start": 0.2001814236225654,
            "count": 1
           },
           {
            "bin_end": 0.2298220622826144,
            "bin_start": 0.21500174295258992,
            "count": 0
           },
           {
            "bin_end": 0.2446423816126389,
            "bin_start": 0.2298220622826144,
            "count": 2
           },
           {
            "bin_end": 0.2594627009426634,
            "bin_start": 0.2446423816126389,
            "count": 0
           },
           {
            "bin_end": 0.2742830202726879,
            "bin_start": 0.2594627009426634,
            "count": 0
           },
           {
            "bin_end": 0.2891033396027124,
            "bin_start": 0.2742830202726879,
            "count": 0
           },
           {
            "bin_end": 0.3039236589327369,
            "bin_start": 0.2891033396027124,
            "count": 0
           },
           {
            "bin_end": 0.31874397826276135,
            "bin_start": 0.3039236589327369,
            "count": 0
           },
           {
            "bin_end": 0.3335642975927859,
            "bin_start": 0.31874397826276135,
            "count": 0
           },
           {
            "bin_end": 0.34838461692281036,
            "bin_start": 0.3335642975927859,
            "count": 1
           }
          ],
          "max": 0.34838461692281036,
          "min": 0.2001814236225654,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-SimVerb-3500",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.12383158271740344,
            "bin_start": 0.12034858040268838,
            "count": 1
           },
           {
            "bin_end": 0.1273145850321185,
            "bin_start": 0.12383158271740344,
            "count": 0
           },
           {
            "bin_end": 0.13079758734683355,
            "bin_start": 0.1273145850321185,
            "count": 0
           },
           {
            "bin_end": 0.13428058966154863,
            "bin_start": 0.13079758734683355,
            "count": 1
           },
           {
            "bin_end": 0.1377635919762637,
            "bin_start": 0.13428058966154863,
            "count": 1
           },
           {
            "bin_end": 0.14124659429097874,
            "bin_start": 0.1377635919762637,
            "count": 0
           },
           {
            "bin_end": 0.14472959660569382,
            "bin_start": 0.14124659429097874,
            "count": 0
           },
           {
            "bin_end": 0.1482125989204089,
            "bin_start": 0.14472959660569382,
            "count": 0
           },
           {
            "bin_end": 0.15169560123512393,
            "bin_start": 0.1482125989204089,
            "count": 0
           },
           {
            "bin_end": 0.155178603549839,
            "bin_start": 0.15169560123512393,
            "count": 1
           }
          ],
          "max": 0.155178603549839,
          "min": 0.12034858040268838,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-RG-65",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6660292992331514,
            "bin_start": 0.6623447151038436,
            "count": 1
           },
           {
            "bin_end": 0.6697138833624591,
            "bin_start": 0.6660292992331514,
            "count": 0
           },
           {
            "bin_end": 0.6733984674917668,
            "bin_start": 0.6697138833624591,
            "count": 0
           },
           {
            "bin_end": 0.6770830516210745,
            "bin_start": 0.6733984674917668,
            "count": 0
           },
           {
            "bin_end": 0.6807676357503822,
            "bin_start": 0.6770830516210745,
            "count": 0
           },
           {
            "bin_end": 0.6844522198796898,
            "bin_start": 0.6807676357503822,
            "count": 0
           },
           {
            "bin_end": 0.6881368040089976,
            "bin_start": 0.6844522198796898,
            "count": 0
           },
           {
            "bin_end": 0.6918213881383053,
            "bin_start": 0.6881368040089976,
            "count": 1
           },
           {
            "bin_end": 0.695505972267613,
            "bin_start": 0.6918213881383053,
            "count": 1
           },
           {
            "bin_end": 0.6991905563969207,
            "bin_start": 0.695505972267613,
            "count": 1
           }
          ],
          "max": 0.6991905563969207,
          "min": 0.6623447151038436,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-RW-STANFORD",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.3301317691918348,
            "bin_start": 0.3251233267738106,
            "count": 1
           },
           {
            "bin_end": 0.33514021160985896,
            "bin_start": 0.3301317691918348,
            "count": 0
           },
           {
            "bin_end": 0.34014865402788313,
            "bin_start": 0.33514021160985896,
            "count": 0
           },
           {
            "bin_end": 0.3451570964459073,
            "bin_start": 0.34014865402788313,
            "count": 0
           },
           {
            "bin_end": 0.35016553886393154,
            "bin_start": 0.3451570964459073,
            "count": 1
           },
           {
            "bin_end": 0.3551739812819557,
            "bin_start": 0.35016553886393154,
            "count": 0
           },
           {
            "bin_end": 0.3601824236999799,
            "bin_start": 0.3551739812819557,
            "count": 1
           },
           {
            "bin_end": 0.36519086611800405,
            "bin_start": 0.3601824236999799,
            "count": 0
           },
           {
            "bin_end": 0.3701993085360282,
            "bin_start": 0.36519086611800405,
            "count": 0
           },
           {
            "bin_end": 0.3752077509540524,
            "bin_start": 0.3701993085360282,
            "count": 1
           }
          ],
          "max": 0.3752077509540524,
          "min": 0.3251233267738106,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-MTurk-771",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.5302360941898684,
            "bin_start": 0.5224939266811585,
            "count": 1
           },
           {
            "bin_end": 0.5379782616985783,
            "bin_start": 0.5302360941898684,
            "count": 0
           },
           {
            "bin_end": 0.5457204292072884,
            "bin_start": 0.5379782616985783,
            "count": 0
           },
           {
            "bin_end": 0.5534625967159983,
            "bin_start": 0.5457204292072884,
            "count": 0
           },
           {
            "bin_end": 0.5612047642247082,
            "bin_start": 0.5534625967159983,
            "count": 0
           },
           {
            "bin_end": 0.5689469317334181,
            "bin_start": 0.5612047642247082,
            "count": 1
           },
           {
            "bin_end": 0.5766890992421281,
            "bin_start": 0.5689469317334181,
            "count": 1
           },
           {
            "bin_end": 0.5844312667508381,
            "bin_start": 0.5766890992421281,
            "count": 0
           },
           {
            "bin_end": 0.592173434259548,
            "bin_start": 0.5844312667508381,
            "count": 0
           },
           {
            "bin_end": 0.599915601768258,
            "bin_start": 0.592173434259548,
            "count": 1
           }
          ],
          "max": 0.599915601768258,
          "min": 0.5224939266811585,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-MEN-TR-3k",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6611007260098655,
            "bin_start": 0.6559665706578095,
            "count": 1
           },
           {
            "bin_end": 0.6662348813619214,
            "bin_start": 0.6611007260098655,
            "count": 0
           },
           {
            "bin_end": 0.6713690367139775,
            "bin_start": 0.6662348813619214,
            "count": 0
           },
           {
            "bin_end": 0.6765031920660335,
            "bin_start": 0.6713690367139775,
            "count": 0
           },
           {
            "bin_end": 0.6816373474180895,
            "bin_start": 0.6765031920660335,
            "count": 0
           },
           {
            "bin_end": 0.6867715027701454,
            "bin_start": 0.6816373474180895,
            "count": 0
           },
           {
            "bin_end": 0.6919056581222014,
            "bin_start": 0.6867715027701454,
            "count": 0
           },
           {
            "bin_end": 0.6970398134742575,
            "bin_start": 0.6919056581222014,
            "count": 0
           },
           {
            "bin_end": 0.7021739688263134,
            "bin_start": 0.6970398134742575,
            "count": 0
           },
           {
            "bin_end": 0.7073081241783694,
            "bin_start": 0.7021739688263134,
            "count": 3
           }
          ],
          "max": 0.7073081241783694,
          "min": 0.6559665706578095,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-MC-30",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6861300552068129,
            "bin_start": 0.6762726201193515,
            "count": 1
           },
           {
            "bin_end": 0.6959874902942743,
            "bin_start": 0.6861300552068129,
            "count": 0
           },
           {
            "bin_end": 0.7058449253817357,
            "bin_start": 0.6959874902942743,
            "count": 1
           },
           {
            "bin_end": 0.7157023604691971,
            "bin_start": 0.7058449253817357,
            "count": 0
           },
           {
            "bin_end": 0.7255597955566586,
            "bin_start": 0.7157023604691971,
            "count": 0
           },
           {
            "bin_end": 0.73541723064412,
            "bin_start": 0.7255597955566586,
            "count": 0
           },
           {
            "bin_end": 0.7452746657315814,
            "bin_start": 0.73541723064412,
            "count": 0
           },
           {
            "bin_end": 0.7551321008190428,
            "bin_start": 0.7452746657315814,
            "count": 1
           },
           {
            "bin_end": 0.7649895359065042,
            "bin_start": 0.7551321008190428,
            "count": 0
           },
           {
            "bin_end": 0.7748469709939656,
            "bin_start": 0.7649895359065042,
            "count": 1
           }
          ],
          "max": 0.7748469709939656,
          "min": 0.6762726201193515,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-MTurk-287",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6664948402530922,
            "bin_start": 0.6630860089204689,
            "count": 1
           },
           {
            "bin_end": 0.6699036715857156,
            "bin_start": 0.6664948402530922,
            "count": 0
           },
           {
            "bin_end": 0.673312502918339,
            "bin_start": 0.6699036715857156,
            "count": 0
           },
           {
            "bin_end": 0.6767213342509624,
            "bin_start": 0.673312502918339,
            "count": 0
           },
           {
            "bin_end": 0.6801301655835856,
            "bin_start": 0.6767213342509624,
            "count": 0
           },
           {
            "bin_end": 0.683538996916209,
            "bin_start": 0.6801301655835856,
            "count": 1
           },
           {
            "bin_end": 0.6869478282488324,
            "bin_start": 0.683538996916209,
            "count": 1
           },
           {
            "bin_end": 0.6903566595814558,
            "bin_start": 0.6869478282488324,
            "count": 0
           },
           {
            "bin_end": 0.6937654909140791,
            "bin_start": 0.6903566595814558,
            "count": 0
           },
           {
            "bin_end": 0.6971743222467025,
            "bin_start": 0.6937654909140791,
            "count": 1
           }
          ],
          "max": 0.6971743222467025,
          "min": 0.6630860089204689,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-SIMLEX-999",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.21680141954459484,
            "bin_start": 0.212155724774273,
            "count": 1
           },
           {
            "bin_end": 0.22144711431491668,
            "bin_start": 0.21680141954459484,
            "count": 0
           },
           {
            "bin_end": 0.22609280908523852,
            "bin_start": 0.22144711431491668,
            "count": 0
           },
           {
            "bin_end": 0.23073850385556036,
            "bin_start": 0.22609280908523852,
            "count": 0
           },
           {
            "bin_end": 0.23538419862588222,
            "bin_start": 0.23073850385556036,
            "count": 0
           },
           {
            "bin_end": 0.24002989339620406,
            "bin_start": 0.23538419862588222,
            "count": 0
           },
           {
            "bin_end": 0.2446755881665259,
            "bin_start": 0.24002989339620406,
            "count": 1
           },
           {
            "bin_end": 0.24932128293684774,
            "bin_start": 0.2446755881665259,
            "count": 0
           },
           {
            "bin_end": 0.2539669777071696,
            "bin_start": 0.24932128293684774,
            "count": 1
           },
           {
            "bin_end": 0.2586126724774914,
            "bin_start": 0.2539669777071696,
            "count": 1
           }
          ],
          "max": 0.2586126724774914,
          "min": 0.212155724774273,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-WS-353-REL",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.49137541703653276,
            "bin_start": 0.4785822534151125,
            "count": 1
           },
           {
            "bin_end": 0.504168580657953,
            "bin_start": 0.49137541703653276,
            "count": 0
           },
           {
            "bin_end": 0.5169617442793732,
            "bin_start": 0.504168580657953,
            "count": 0
           },
           {
            "bin_end": 0.5297549079007935,
            "bin_start": 0.5169617442793732,
            "count": 0
           },
           {
            "bin_end": 0.5425480715222137,
            "bin_start": 0.5297549079007935,
            "count": 0
           },
           {
            "bin_end": 0.555341235143634,
            "bin_start": 0.5425480715222137,
            "count": 0
           },
           {
            "bin_end": 0.5681343987650541,
            "bin_start": 0.555341235143634,
            "count": 0
           },
           {
            "bin_end": 0.5809275623864744,
            "bin_start": 0.5681343987650541,
            "count": 1
           },
           {
            "bin_end": 0.5937207260078946,
            "bin_start": 0.5809275623864744,
            "count": 0
           },
           {
            "bin_end": 0.6065138896293149,
            "bin_start": 0.5937207260078946,
            "count": 2
           }
          ],
          "max": 0.6065138896293149,
          "min": 0.4785822534151125,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-YP-130",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.27941585836305793,
            "bin_start": 0.2640276380721901,
            "count": 1
           },
           {
            "bin_end": 0.29480407865392577,
            "bin_start": 0.27941585836305793,
            "count": 0
           },
           {
            "bin_end": 0.3101922989447936,
            "bin_start": 0.29480407865392577,
            "count": 0
           },
           {
            "bin_end": 0.3255805192356614,
            "bin_start": 0.3101922989447936,
            "count": 0
           },
           {
            "bin_end": 0.34096873952652923,
            "bin_start": 0.3255805192356614,
            "count": 0
           },
           {
            "bin_end": 0.35635695981739707,
            "bin_start": 0.34096873952652923,
            "count": 0
           },
           {
            "bin_end": 0.3717451801082649,
            "bin_start": 0.35635695981739707,
            "count": 1
           },
           {
            "bin_end": 0.3871334003991327,
            "bin_start": 0.3717451801082649,
            "count": 0
           },
           {
            "bin_end": 0.4025216206900005,
            "bin_start": 0.3871334003991327,
            "count": 0
           },
           {
            "bin_end": 0.41790984098086836,
            "bin_start": 0.4025216206900005,
            "count": 2
           }
          ],
          "max": 0.41790984098086836,
          "min": 0.2640276380721901,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-WS-353-ALL",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.5764538674046541,
            "bin_start": 0.5689648828217478,
            "count": 1
           },
           {
            "bin_end": 0.5839428519875604,
            "bin_start": 0.5764538674046541,
            "count": 0
           },
           {
            "bin_end": 0.5914318365704667,
            "bin_start": 0.5839428519875604,
            "count": 0
           },
           {
            "bin_end": 0.598920821153373,
            "bin_start": 0.5914318365704667,
            "count": 0
           },
           {
            "bin_end": 0.6064098057362792,
            "bin_start": 0.598920821153373,
            "count": 0
           },
           {
            "bin_end": 0.6138987903191855,
            "bin_start": 0.6064098057362792,
            "count": 0
           },
           {
            "bin_end": 0.6213877749020917,
            "bin_start": 0.6138987903191855,
            "count": 0
           },
           {
            "bin_end": 0.6288767594849981,
            "bin_start": 0.6213877749020917,
            "count": 1
           },
           {
            "bin_end": 0.6363657440679044,
            "bin_start": 0.6288767594849981,
            "count": 0
           },
           {
            "bin_end": 0.6438547286508106,
            "bin_start": 0.6363657440679044,
            "count": 2
           }
          ],
          "max": 0.6438547286508106,
          "min": 0.5689648828217478,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "float64",
         "name": "EN-WS-353-SIM",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6578342508865612,
            "bin_start": 0.6521803038725271,
            "count": 1
           },
           {
            "bin_end": 0.6634881979005953,
            "bin_start": 0.6578342508865612,
            "count": 0
           },
           {
            "bin_end": 0.6691421449146293,
            "bin_start": 0.6634881979005953,
            "count": 0
           },
           {
            "bin_end": 0.6747960919286634,
            "bin_start": 0.6691421449146293,
            "count": 0
           },
           {
            "bin_end": 0.6804500389426975,
            "bin_start": 0.6747960919286634,
            "count": 0
           },
           {
            "bin_end": 0.6861039859567316,
            "bin_start": 0.6804500389426975,
            "count": 0
           },
           {
            "bin_end": 0.6917579329707657,
            "bin_start": 0.6861039859567316,
            "count": 1
           },
           {
            "bin_end": 0.6974118799847997,
            "bin_start": 0.6917579329707657,
            "count": 0
           },
           {
            "bin_end": 0.7030658269988338,
            "bin_start": 0.6974118799847997,
            "count": 0
           },
           {
            "bin_end": 0.7087197740128679,
            "bin_start": 0.7030658269988338,
            "count": 2
           }
          ],
          "max": 0.7087197740128679,
          "min": 0.6521803038725271,
          "nan_count": 0,
          "unique_count": 4
         }
        },
        {
         "dtype": "object",
         "name": "_deepnote_index_column"
        }
       ],
       "row_count": 4,
       "rows_bottom": null,
       "rows_top": [
        {
         "EN-MC-30": 0.7480747755671264,
         "EN-MEN-TR-3k": 0.7054288643887612,
         "EN-MTurk-287": 0.6971743222467025,
         "EN-MTurk-771": 0.599915601768258,
         "EN-RG-65": 0.6895579203091267,
         "EN-RW-STANFORD": 0.3752077509540524,
         "EN-SIMLEX-999": 0.2503383609476077,
         "EN-SimVerb-3500": 0.1364659926036458,
         "EN-VERB-143": 0.34838461692281036,
         "EN-WS-353-ALL": 0.6222462579422785,
         "EN-WS-353-REL": 0.5763911482008061,
         "EN-WS-353-SIM": 0.6880709745210787,
         "EN-YP-130": 0.40401484962916356,
         "_deepnote_index_column": "word2vec_mc=10_size=200_window=50_sg=1_IN-IN"
        },
        {
         "EN-MC-30": 0.6762726201193515,
         "EN-MEN-TR-3k": 0.7059331167783172,
         "EN-MTurk-287": 0.681006300980238,
         "EN-MTurk-771": 0.5752239870736946,
         "EN-RG-65": 0.6924469032379581,
         "EN-RW-STANFORD": 0.3251233267738106,
         "EN-SIMLEX-999": 0.24418399495739598,
         "EN-SimVerb-3500": 0.155178603549839,
         "EN-VERB-143": 0.23501683536561455,
         "EN-WS-353-ALL": 0.6424350065734841,
         "EN-WS-353-REL": 0.6016077444871313,
         "EN-WS-353-SIM": 0.7035777424831945,
         "EN-YP-130": 0.41790984098086836,
         "_deepnote_index_column": "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT"
        },
        {
         "EN-MC-30": 0.7748469709939656,
         "EN-MEN-TR-3k": 0.7073081241783694,
         "EN-MTurk-287": 0.686461232543265,
         "EN-MTurk-771": 0.5683129110415912,
         "EN-RG-65": 0.6991905563969207,
         "EN-RW-STANFORD": 0.34562742800632557,
         "EN-SIMLEX-999": 0.212155724774273,
         "EN-SimVerb-3500": 0.13405800486224162,
         "EN-VERB-143": 0.2411989501625128,
         "EN-WS-353-ALL": 0.6438547286508106,
         "EN-WS-353-REL": 0.6065138896293149,
         "EN-WS-353-SIM": 0.7087197740128679,
         "EN-YP-130": 0.3580221703852564,
         "_deepnote_index_column": "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN"
        },
        {
         "EN-MC-30": 0.7053942520360192,
         "EN-MEN-TR-3k": 0.6559665706578095,
         "EN-MTurk-287": 0.6630860089204689,
         "EN-MTurk-771": 0.5224939266811585,
         "EN-RG-65": 0.6623447151038436,
         "EN-RW-STANFORD": 0.35719949743016544,
         "EN-SIMLEX-999": 0.2586126724774914,
         "EN-SimVerb-3500": 0.12034858040268838,
         "EN-VERB-143": 0.2001814236225654,
         "EN-WS-353-ALL": 0.5689648828217478,
         "EN-WS-353-REL": 0.4785822534151125,
         "EN-WS-353-SIM": 0.6521803038725271,
         "EN-YP-130": 0.2640276380721901,
         "_deepnote_index_column": "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT"
        }
       ]
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN-VERB-143</th>\n",
       "      <th>EN-SimVerb-3500</th>\n",
       "      <th>EN-RG-65</th>\n",
       "      <th>EN-RW-STANFORD</th>\n",
       "      <th>EN-MTurk-771</th>\n",
       "      <th>EN-MEN-TR-3k</th>\n",
       "      <th>EN-MC-30</th>\n",
       "      <th>EN-MTurk-287</th>\n",
       "      <th>EN-SIMLEX-999</th>\n",
       "      <th>EN-WS-353-REL</th>\n",
       "      <th>EN-YP-130</th>\n",
       "      <th>EN-WS-353-ALL</th>\n",
       "      <th>EN-WS-353-SIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word2vec_mc=10_size=200_window=50_sg=1_IN-IN</th>\n",
       "      <td>0.348385</td>\n",
       "      <td>0.136466</td>\n",
       "      <td>0.689558</td>\n",
       "      <td>0.375208</td>\n",
       "      <td>0.599916</td>\n",
       "      <td>0.705429</td>\n",
       "      <td>0.748075</td>\n",
       "      <td>0.697174</td>\n",
       "      <td>0.250338</td>\n",
       "      <td>0.576391</td>\n",
       "      <td>0.404015</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.688071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_mc=10_size=200_window=50_sg=1_IN-OUT</th>\n",
       "      <td>0.235017</td>\n",
       "      <td>0.155179</td>\n",
       "      <td>0.692447</td>\n",
       "      <td>0.325123</td>\n",
       "      <td>0.575224</td>\n",
       "      <td>0.705933</td>\n",
       "      <td>0.676273</td>\n",
       "      <td>0.681006</td>\n",
       "      <td>0.244184</td>\n",
       "      <td>0.601608</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.642435</td>\n",
       "      <td>0.703578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_mc=10_size=200_window=50_sg=1_OUT-IN</th>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.134058</td>\n",
       "      <td>0.699191</td>\n",
       "      <td>0.345627</td>\n",
       "      <td>0.568313</td>\n",
       "      <td>0.707308</td>\n",
       "      <td>0.774847</td>\n",
       "      <td>0.686461</td>\n",
       "      <td>0.212156</td>\n",
       "      <td>0.606514</td>\n",
       "      <td>0.358022</td>\n",
       "      <td>0.643855</td>\n",
       "      <td>0.708720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT</th>\n",
       "      <td>0.200181</td>\n",
       "      <td>0.120349</td>\n",
       "      <td>0.662345</td>\n",
       "      <td>0.357199</td>\n",
       "      <td>0.522494</td>\n",
       "      <td>0.655967</td>\n",
       "      <td>0.705394</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>0.258613</td>\n",
       "      <td>0.478582</td>\n",
       "      <td>0.264028</td>\n",
       "      <td>0.568965</td>\n",
       "      <td>0.652180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                EN-VERB-143  EN-SimVerb-3500  \\\n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN       0.348385         0.136466   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT      0.235017         0.155179   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN      0.241199         0.134058   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT     0.200181         0.120349   \n",
       "\n",
       "                                                EN-RG-65  EN-RW-STANFORD  \\\n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN    0.689558        0.375208   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT   0.692447        0.325123   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN   0.699191        0.345627   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT  0.662345        0.357199   \n",
       "\n",
       "                                                EN-MTurk-771  EN-MEN-TR-3k  \\\n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN        0.599916      0.705429   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT       0.575224      0.705933   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN       0.568313      0.707308   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT      0.522494      0.655967   \n",
       "\n",
       "                                                EN-MC-30  EN-MTurk-287  \\\n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN    0.748075      0.697174   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT   0.676273      0.681006   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN   0.774847      0.686461   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT  0.705394      0.663086   \n",
       "\n",
       "                                                EN-SIMLEX-999  EN-WS-353-REL  \\\n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN         0.250338       0.576391   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT        0.244184       0.601608   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN        0.212156       0.606514   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT       0.258613       0.478582   \n",
       "\n",
       "                                                EN-YP-130  EN-WS-353-ALL  \\\n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN     0.404015       0.622246   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT    0.417910       0.642435   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN    0.358022       0.643855   \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT   0.264028       0.568965   \n",
       "\n",
       "                                                EN-WS-353-SIM  \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-IN         0.688071  \n",
       "word2vec_mc=10_size=200_window=50_sg=1_IN-OUT        0.703578  \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-IN        0.708720  \n",
       "word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT       0.652180  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob.glob(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0/*\")\n",
    "import pickle\n",
    "with open(\"word2vec_results1.pickle\", \"rb\") as f:\n",
    "    _ = pickle.load(f)\n",
    "_['score_matrix'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-505abced-51aa-47ef-a238-cf42f4cb120e",
    "tags": []
   },
   "source": [
    "## Appendix\n",
    "\n",
    "1. Check for the presence of word in dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-58a997c1-2088-453d-87db-a86917ed61bd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 87\n",
      "Words in model: 0\n"
     ]
    }
   ],
   "source": [
    "# missing_words\n",
    "list_of_words = similarity_datasets['EN-VERB-143']['word_1'].values\n",
    "print(f\"Unique words: {len(set(list_of_words))}\")\n",
    "print(f\"Words in model: {sum([lemma(word.lower()) not in model.wv.index2word for word in set(list_of_words) ])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-e3d5c77e-7b21-4961-9f02-afbe0979c4b5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_words['EN-VERB-143']\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-4799d3c5-90ab-4f6a-adb6-cc117f486463",
    "output_cleared": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-08021ea4-4f86-4b75-97e9-4c436dd71a8d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=50_sg=1/word2vec_wikiEn20171001_millionSentences_mc=10_iter=5_size=200_window=50_sg=1']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=50_sg=1/*[!(npy)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-0c99c113-8491-4b9d-b22b-aec61548ecff",
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ee79aacb-fd8f-4052-af8b-c77445857e56",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
