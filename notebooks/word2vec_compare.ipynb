{"cells":[{"cell_type":"markdown","source":"# Word2Vec models comparison\n\nWe compare the different models of word2vec against different intrinsic word embeddings tasks.\n\n**BLUNDER: all 200 and 300 D models are not trained on leema text**","metadata":{"cell_id":"00000-3e5dd85b-a83f-41e3-81ec-63465c987242","tags":[]}},{"cell_type":"markdown","source":"### Import and load datasets","metadata":{"cell_id":"00001-1d47f6bc-3830-48d3-969f-6f724ac6e2ca","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00002-9e2b57be-6c76-439b-9f0e-24ee9215ace3","tags":[],"output_cleared":false},"source":"# imports\n!pip install ray[tune]\nimport ray\nfrom ray.tune.utils import pin_in_object_store, get_pinned_object\nray.init(ignore_reinit_error=True)\nimport pickle\nimport time\nfrom numpy.linalg import norm\nfrom scipy.spatial.distance import cosine, cdist\nimport base64\n!pip install telepot\nimport telepot\n\n!pip install nltk\nimport nltk\nnltk.download('wordnet')\nimport glob\n!pip install tqdm\nfrom tqdm import tqdm\nimport pandas as pd\n!pip install gensim\nfrom gensim.models import KeyedVectors\nfrom gensim.models.word2vec import Word2Vec\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity","execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ray[tune] in /opt/venv/lib/python3.7/site-packages (0.8.7)\nRequirement already satisfied: numpy>=1.16 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (1.19.0)\nRequirement already satisfied: aiohttp in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (3.6.2)\nRequirement already satisfied: opencensus in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (0.7.10)\nRequirement already satisfied: colorama in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (0.4.3)\nRequirement already satisfied: gpustat in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (0.6.0)\nRequirement already satisfied: filelock in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (3.0.12)\nRequirement already satisfied: aioredis in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (1.3.1)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (0.8.0)\nRequirement already satisfied: redis<3.5.0,>=3.3.2 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (3.4.1)\nRequirement already satisfied: colorful in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (0.5.4)\nRequirement already satisfied: protobuf>=3.8.0 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (3.13.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (1.0.0)\nRequirement already satisfied: click>=7.0 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (7.1.2)\nRequirement already satisfied: grpcio>=1.28.1 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (1.32.0)\nRequirement already satisfied: jsonschema in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (3.2.0)\nRequirement already satisfied: google in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (3.0.0)\nRequirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (2.24.0)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (0.3.3)\nRequirement already satisfied: pyyaml in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (5.3.1)\nCollecting tabulate; extra == \"tune\"\n  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\nCollecting tensorboardX; extra == \"tune\"\n  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n\u001b[K     |████████████████████████████████| 308 kB 6.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pandas; extra == \"tune\" in /opt/venv/lib/python3.7/site-packages (from ray[tune]) (1.0.5)\nRequirement already satisfied: multidict<5.0,>=4.5 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray[tune]) (4.7.6)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray[tune]) (1.5.1)\nRequirement already satisfied: chardet<4.0,>=2.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray[tune]) (3.0.4)\nRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray[tune]) (3.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp->ray[tune]) (19.3.0)\nRequirement already satisfied: opencensus-context==0.1.1 in /opt/venv/lib/python3.7/site-packages (from opencensus->ray[tune]) (0.1.1)\nRequirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /opt/venv/lib/python3.7/site-packages (from opencensus->ray[tune]) (1.22.2)\nRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray[tune]) (7.352.0)\nRequirement already satisfied: six>=1.7 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray[tune]) (1.15.0)\nRequirement already satisfied: psutil in /opt/venv/lib/python3.7/site-packages (from gpustat->ray[tune]) (5.7.2)\nRequirement already satisfied: blessings>=1.6 in /opt/venv/lib/python3.7/site-packages (from gpustat->ray[tune]) (1.7)\nRequirement already satisfied: hiredis in /opt/venv/lib/python3.7/site-packages (from aioredis->ray[tune]) (1.1.0)\nRequirement already satisfied: setuptools in /opt/venv/lib/python3.7/site-packages (from protobuf>=3.8.0->ray[tune]) (47.3.1)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray[tune]) (0.16.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from jsonschema->ray[tune]) (1.7.0)\nRequirement already satisfied: beautifulsoup4 in /opt/venv/lib/python3.7/site-packages (from google->ray[tune]) (4.9.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->ray[tune]) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->ray[tune]) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->ray[tune]) (2020.6.20)\nRequirement already satisfied: pytz>=2017.2 in /opt/venv/lib/python3.7/site-packages (from pandas; extra == \"tune\"->ray[tune]) (2020.1)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/venv/lib/python3.7/site-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\nRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->ray[tune]) (3.7.4.3)\nRequirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.21.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/venv/lib/python3.7/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\nRequirement already satisfied: zipp>=0.5 in /opt/venv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray[tune]) (3.1.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/venv/lib/python3.7/site-packages (from beautifulsoup4->google->ray[tune]) (2.0.1)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/venv/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/venv/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\nInstalling collected packages: tabulate, tensorboardX\nSuccessfully installed tabulate-0.8.7 tensorboardX-2.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n2020-09-12 17:20:39,921\tINFO resource_spec.py:231 -- Starting Ray with 3.91 GiB memory available for workers and up to 1.95 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n2020-09-12 17:20:40,896\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n2020-09-12 17:20:40,907\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n2020-09-12 17:20:40,948\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n2020-09-12 17:20:44,634\tWARNING worker.py:1134 -- The dashboard on node p-302a6336-d27e-43af-93d1-276242f3b519 failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/venv/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 961, in <module>\n    dashboard.run()\n  File \"/opt/venv/lib/python3.7/site-packages/ray/dashboard/dashboard.py\", line 576, in run\n    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web.py\", line 433, in run_app\n    reuse_port=reuse_port))\n  File \"/usr/local/lib/python3.7/asyncio/base_events.py\", line 584, in run_until_complete\n    return future.result()\n  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web.py\", line 359, in _run_app\n    await site.start()\n  File \"/opt/venv/lib/python3.7/site-packages/aiohttp/web_runner.py\", line 104, in start\n    reuse_port=self._reuse_port)\n  File \"/usr/local/lib/python3.7/asyncio/base_events.py\", line 1378, in create_server\n    % (sa, err.strerror.lower())) from None\nOSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n\nCollecting telepot\n  Downloading telepot-12.7.tar.gz (73 kB)\n\u001b[K     |████████████████████████████████| 73 kB 1.1 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: urllib3>=1.9.1 in /opt/venv/lib/python3.7/site-packages (from telepot) (1.25.9)\nRequirement already satisfied: aiohttp>=3.0.0 in /opt/venv/lib/python3.7/site-packages (from telepot) (3.6.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp>=3.0.0->telepot) (1.5.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp>=3.0.0->telepot) (19.3.0)\nRequirement already satisfied: chardet<4.0,>=2.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp>=3.0.0->telepot) (3.0.4)\nRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/venv/lib/python3.7/site-packages (from aiohttp>=3.0.0->telepot) (3.0.1)\nRequirement already satisfied: multidict<5.0,>=4.5 in /opt/venv/lib/python3.7/site-packages (from aiohttp>=3.0.0->telepot) (4.7.6)\nRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/venv/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.0.0->telepot) (3.7.4.3)\nRequirement already satisfied: idna>=2.0 in /opt/venv/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.0.0->telepot) (2.10)\nBuilding wheels for collected packages: telepot\n  Building wheel for telepot (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for telepot: filename=telepot-12.7-py3-none-any.whl size=57962 sha256=a2b5f00303cc2fc775cbfc636a14159f9692b22b4e4db018a61a08b4b42153da\n  Stored in directory: /home/jovyan/.cache/pip/wheels/59/4d/ea/8781198a69408b6c37d47d902d7bbe5541969eddf5290e6b2e\nSuccessfully built telepot\nInstalling collected packages: telepot\nSuccessfully installed telepot-12.7\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: nltk in /opt/venv/lib/python3.7/site-packages (3.5)\nRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (from nltk) (4.48.2)\nRequirement already satisfied: click in /opt/venv/lib/python3.7/site-packages (from nltk) (7.1.2)\nRequirement already satisfied: regex in /opt/venv/lib/python3.7/site-packages (from nltk) (2020.7.14)\nRequirement already satisfied: joblib in /opt/venv/lib/python3.7/site-packages (from nltk) (0.16.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nRequirement already satisfied: tqdm in /opt/venv/lib/python3.7/site-packages (4.48.2)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: gensim in /opt/venv/lib/python3.7/site-packages (3.8.3)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (2.1.1)\nRequirement already satisfied: scipy>=0.18.1 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.5.1)\nRequirement already satisfied: numpy>=1.11.3 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.19.0)\nRequirement already satisfied: six>=1.5.0 in /opt/venv/lib/python3.7/site-packages (from gensim) (1.15.0)\nRequirement already satisfied: boto in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\nRequirement already satisfied: boto3 in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.60)\nRequirement already satisfied: requests in /opt/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\nRequirement already satisfied: botocore<1.18.0,>=1.17.60 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.60)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/venv/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.60->boto3->smart-open>=1.8.1->gensim) (2.8.1)\nRequirement already satisfied: docutils<0.16,>=0.10 in /opt/venv/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.60->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-2f225dfe-99d1-438d-a35f-5ff619480095"},"source":"## Load telepot\ndef send_telegram_message(message):\n    token = '1361671158:AAF9jfW_fT0aF0zHwHtpOaUEB9CPYhmyew8'\n    TelegramBot = telepot.Bot(token)\n    TelegramBot.sendMessage(934022573, str(message))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-d7473357-957f-4110-a0b9-b58274497464"},"source":"# send_telegram_message(\"test from deepnotes\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-2a8bf924-33fd-402a-b346-8a3fd2e34a3f"},"source":"with open (\"../data/all_datasets.pickle\", 'rb') as f:\n    all_datasets = pickle.load(f)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-86a66fbc-424b-492b-a79a-b01e1dee6926"},"source":"# all([len(set(x))==4 for x in all_datasets['analogy_datasets']['bats_analogy']])\n# all_datasets['analogy_datasets']['bats_analogy'][:10]\n# for x , y in all_datasets['relatedness_datasets'].items():\n#     print(x, len(y))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load word2vec models","metadata":{"cell_id":"00003-7aa5267f-439e-4e0e-bce0-1c113f44ced3","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00004-b38d3970-71ec-445e-8d56-ee126cda621c","tags":[]},"source":"def nnorm(matrix):\n    \"norm each vector in the matrix\"\n    return (matrix.T/norm(matrix, axis=1)).T\n    \nmodel = Word2Vec.load(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=5_sg=0/word2vec_wikiEn20171001_millionSentences_mc=10_iter=5_size=200_window=5_sg=0\")\nmodel.wv.vectors = nnorm(model.wv.vectors) \nmodel.trainables.syn1neg = nnorm(model.trainables.syn1neg)\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00009-b18e346e-3d4e-4b23-83bc-34c3253ba308"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Word2vec similarity computing method","metadata":{"cell_id":"00005-0d59b9b7-fd9e-4264-b365-928853de76d4","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00006-53360c62-c699-4129-99da-de30347538ce","tags":[]},"source":"def word2vec_get_index_by_word(word2vec_model, word):\n    \"\"\"Return the index of the word in the model\n    \"\"\"\n    return word2vec_model.wv.index2word.index(word)\n\ndef word2vec_get_word_by_index(word2vec_model, index):\n    \"\"\"Return the word by the provided index\n    \"\"\"\n    return word2vec_model.wv.index2word[index]\n\ndef word2vec_get_model_matrix_by_method(word2vec_model, method):\n    \"\"\"Return the source and compare matrix based on model and method selection\n    \"\"\"\n    input_weights = word2vec_model.wv.vectors\n    output_weights = word2vec_model.trainables.syn1neg\n    weights1, weights2 = None, None\n    if method==\"IN-IN\":\n        weights1, weights2 = input_weights, input_weights \n    elif method==\"IN-OUT\":\n        weights1, weights2 = input_weights, output_weights\n    elif method==\"OUT-IN\":\n        weights1, weights2 = output_weights, input_weights\n    elif method==\"OUT-OUT\":\n        weights1, weights2 = output_weights, output_weights\n    return weights1, weights2\n\ndef word2vec_find_top_similar_vectors_bw_matrix(vector, compare_matrix, source_word_index, index2word, top_n=5, no_self_similarity=True):\n    \"\"\"Find top n similar vectors in the compare matrix\n    \"\"\"\n    score = np.dot(vector, compare_matrix)[0]\n    if no_self_similarity:\n        score[source_word_index] = -1 # negate self-similarity\n    top_n_similar_words = np.argpartition(-score, top_n)[:top_n]\n    sorted_result = sorted([(index2word[index], score[index]) for index in top_n_similar_words], \n                key=lambda x: x[1], \n                reverse=True)\n    return sorted_result\n\ndef word2vec_find_top_similar_words(word2vec_model, source_word, method='IN-IN', top_n=5, no_self_similarity=True):\n    \"\"\"\n    Provided a word, find the top_n most similar from the model following the method\n    \"\"\"\n    score = []\n    source_word_index = word2vec_get_index_by_word(word2vec_model, source_word)\n    source_matrix, compare_matrix = word2vec_get_model_matrix_by_method(word2vec_model, method)\n    sorted_result = word2vec_find_top_similar_vectors_bw_matrix(\n            vector=source_matrix[source_word_index].reshape(1, -1),\n            compare_matrix=compare_matrix.T, \n            source_word_index = source_word_index,\n            index2word=word2vec_model.wv.index2word,\n            top_n=top_n, \n            no_self_similarity=no_self_similarity)\n    return sorted_result\n\ndef word2vec_find_similarity(word2vec_model, source_word, target_word, method=\"IN-IN\"):\n    \"\"\"Return the cosine similarity between two words based on the suggested method\n    \"\"\"\n    source_word_index = word2vec_get_index_by_word(word2vec_model, source_word)\n    target_word_index = word2vec_get_index_by_word(word2vec_model, target_word)\n    source_matrix, compare_matrix = word2vec_get_model_matrix_by_method(word2vec_model, method)\n    score = cosine_similarity(source_matrix[source_word_index].reshape(1, -1), \n                              compare_matrix[target_word_index].reshape(1, -1))[0]\n    return score\n\n# word2vec_find_similarity(model, \"car\", \"truck\", \"IN-OUT\")\n# word2vec_find_top_similar_words(model, \"car\", \"IN-IN\")\n# word2vec_find_top_similar_words(model, \"car\", \"IN-OUT\")\n\n# lemmatizer - noun lemma -- https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word\ndef lemma(word): return nltk.stem.WordNetLemmatizer().lemmatize(word)\n\n# preprocss the word - lowercase and lemma\ndef pre(word): return lemma(word.lower())","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00008-428591ef-cbf0-4dfd-842b-985a97e70458"},"source":"# word2vec_find_top_similar_words(get_pinned_object(model), 'car', method='IN-IN', top_n=10, no_self_similarity=True)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test functions","metadata":{"cell_id":"00010-0ee6049a-6cce-4f29-b41d-db37bcd57547","tags":[]}},{"cell_type":"code","metadata":{"cell_id":"00011-8f52192d-aa1f-495d-89ad-5b52b2a358df","tags":[]},"source":"glob_w2v_models = ['../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=1',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=50_sg=0',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=50_sg=1',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=5_sg=0',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=5_sg=1',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=50_sg=0',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=200_window=50_sg=1',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=300_window=5_sg=0',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=300_window=5_sg=1',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=300_window=50_sg=0',\n                    '../../../embeddings_lemma/word2vec_mc=10_iter=5_size=300_window=50_sg=1']\n\n# @ray.remote\ndef compare_word2vec_model_with_relatedness_dataset(model, model_name, dataset_name, dataset):\n    missing_words = 0\n    score_table = []\n    for row in dataset.to_dict(orient=\"records\"):\n        methods = [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]\n        for method in methods:\n            try:\n                sim_score = word2vec_find_similarity(model, pre(row['word_1']), pre(row['word_2']), method)[0]\n            except:\n                sim_score = None\n                missing_words += 1\n            row[f\"{model_name}_{method}\"] = sim_score\n        score_table.append(row)\n    score_table = pd.DataFrame.from_dict(score_table)\n    score_table = score_table.dropna().corr(\"pearson\")[['similarity_score']].tail(4)\n    score_table.columns = [dataset_name]\n    missing_words = missing_words/len(methods)\n    return score_table, dataset_name, missing_words\n\ndef calculate_tp_score(y_pred, y_true):\n    y_pred, y_true = set(y_pred), set(y_true)\n    tp = y_pred & y_true\n    # fp = y_pred - tp\n    # tn = 0.001\n    # fn = y_true - y_pred\n    # precision = len(tp) / (len(tp) + len(fp))\n    # recall = len(tp) / (len(tp) + len(fn))\n    # try:\n    #     f1_score = 2*(precision * recall)/(precision + recall)\n    # except ZeroDivisionError:\n    #     f1_score = 0\n    return len(tp)/len(y_true)\n\ndef word2vec_check_all_word_in_model(words, index2word):\n    return all([word in index2word for word in words])\n\n@ray.remote\ndef word2vec_test_association_dataset(model, model_name, dataset_name, dataset):\n    # word2vec_model = get_pinned_object(model)\n    word2vec_model = model\n    possible_top_n = [10]\n    methods = [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]\n    max_possible_top_n = max(possible_top_n)\n    all_cue_test_result= []\n    for cue_name, cue_data in dataset.groupby(['cue']):\n        expected_responses = cue_data['response'].values\n        if not word2vec_check_all_word_in_model([cue_name] + list(expected_responses), word2vec_model.wv.index2word):\n            continue\n        cue_test_result = {'cue': cue_name, 'expected_responses': expected_responses}\n        for method in methods:\n            model_response = word2vec_find_top_similar_words(word2vec_model, cue_name, method, top_n=max_possible_top_n)\n            for top_n in possible_top_n:\n                subset_model_response = [x[0] for x in model_response[:top_n]]\n                tp_score = calculate_tp_score(subset_model_response, expected_responses)\n                model_method_topn_name = f'{model_name}_{method}_{top_n}'\n                cue_test_result[f'{model_method_topn_name}_model_response'] = subset_model_response\n                cue_test_result[f'{model_method_topn_name}_tp_score'] = tp_score\n        all_cue_test_result.append(cue_test_result)\n    return dataset_name, all_cue_test_result\n\n## \n# ANALGOY\n##\ndef cos3mul(compare_matrix, word_index, a, a_s, b,  b_s, top_n, e=0.0000001):\n    \"\"\"From: https://www.aclweb.org/anthology/W14-1618.pdf; Page 175\n    \"\"\"\n    c = np.stack([b, a_s, a], axis=1)\n    all_scores = np.dot(compare_matrix, c)\n    all_scores = (all_scores + 1)/2 # normalize bw 0 to 1\n    all_scores[:, 2] += e\n    all_scores = ((all_scores[:, 0] * all_scores[:, 1]) / all_scores[:, 2])\n    top_n_similar_words = np.argpartition(-all_scores, top_n)[:top_n]\n    sorted_result = sorted([(word_index[index], all_scores[index]) for index in top_n_similar_words], \n                key=lambda x: x[1], \n                reverse=True)\n    sorted_result = [x[0] for x in sorted_result]\n    return sorted_result, 1 if b_s in sorted_result else 0\n\ndef cos3add(compare_matrix, a, a_s, b, b_s, top_n, index2word):\n    \"\"\"Find the most similar vector with (b-a+a_)\n    \"\"\"\n    b_ = b.reshape(1, -1)-a.reshape(1, -1)+a_s.reshape(1, -1)\n    res = word2vec_find_top_similar_vectors_bw_matrix(\n            b_, compare_matrix, None, index2word, top_n=top_n, no_self_similarity=False)\n    res = [x[0] for x in res]\n    return res, 1 if b_s in res else 0\n\n# for dataset_name, dataset in all_datasets['analogy_datasets'].items():\n    # dataset_result = []\n@ray.remote\ndef word2vec_test_analogy_dataset(model, model_name, dataset_name, dataset):\n    dataset_result = []\n    # word2vec_model = get_pinned_object(model)\n    word2vec_model = model\n    for row in dataset:\n        a, a_s, b, b_s = row\n        try:\n            a_index = word2vec_get_index_by_word(word2vec_model, a)\n            a_s_index = word2vec_get_index_by_word(word2vec_model, a_s)\n            b_index = word2vec_get_index_by_word(word2vec_model, b)\n            b_s_index = word2vec_get_index_by_word(word2vec_model, b_s)\n        except:\n            continue\n        for method in [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]:\n            source_matrix, compare_matrix = word2vec_get_model_matrix_by_method(word2vec_model, method)\n            a_vector = source_matrix[a_index]\n            a_s_vector = source_matrix[a_s_index]\n            b_vector = source_matrix[b_index]\n            cos3add_response, cos3add_score = \\\n                cos3add(compare_matrix.T, a_vector, a_s_vector, b_vector, b_s, 3, word2vec_model.wv.index2word)\n            cos3mul_response, cos3mul_score = \\\n                cos3mul(compare_matrix, word2vec_model.wv.index2word, a_vector, a_s_vector, b_vector, b_s, top_n=3)\n            dataset_result.append({\n                'analogy': row,\n                'method': method, \n                'model': model_name,\n                'cos3add_response': cos3add_response,\n                'cos3add_score': cos3add_score,\n                'cos3mul_response': cos3mul_response,\n                'cos3mul_score': cos3mul_score\n            })\n    return dataset_name, pd.DataFrame(dataset_result)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-d2ac0af6-f8a9-4ee2-a089-e9d4462d6e83"},"source":"# ['car', 'truck'] not in get_pinned_object(model).wv.index2word\n# all([True, False, True])\n# [5] + [1,2,3]","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run Analogy","metadata":{"tags":[],"cell_id":"00014-42247abb-1785-4e0b-9082-f1acadffd62a"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-23b99a82-7711-4d83-8d15-2ec6ee97ac91"},"source":"# perform this for each model\nfor model_dir in tqdm(glob_w2v_models[3:]):\n    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n    model = Word2Vec.load(model_path)\n    model.wv.vectors = nnorm(model.wv.vectors) \n    model.trainables.syn1neg = nnorm(model.trainables.syn1neg)\n    # model = pin_in_object_store(model)\n    # print(\"Running analysis on each dataset\")\n    # Step 1: Handle relatedness dataset\n    futures = [word2vec_test_analogy_dataset.remote(model, model_name, dataset_name, dataset) \\\n                    for dataset_name, dataset in all_datasets['analogy_datasets'].items()]\n    res = ray.get(futures)    \n    # print(\"Post processing and Saving results\")\n    # pd.concat(res, axis=1)\n    df_res = {dname:df_res for dname, df_res in res}\n    with open(f\"../output/word2vec/analogy/word2vec_results_{model_name}_analogy.pickle\", \"wb\") as f:\n        pickle.dump({\"score_matrix\": df_res}, f)\n    # clean ray object store\n    # ray.internal.free(model)\n    # message from telegram\n    try:\n        send_telegram_message(model_name)\n        send_telegram_message(str(df_res['google_analogy'].groupby('method').mean()))\n        send_telegram_message(str(df_res['bats_analogy'].groupby('method').mean()))\n    except:\n        pass\n                ","execution_count":null,"outputs":[{"name":"stderr","text":" 67%|██████▋   | 6/9 [2:47:33<1:28:26, 1768.90s/it]","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9/9 [4:46:47<00:00, 1911.90s/it]  \n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00016-32ac2072-d32b-4aeb-bc03-6d4eec673a12"},"source":"# glob.glob(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0/*\")\nimport pickle\nwith open(\"../output/word2vec/analogy/word2vec_results_word2vec_mc=10_size=100_window=5_sg=0_analogy.pickle\", \"rb\") as f:\n    _ = pickle.load(f)\n# _['score_matrix'][0]\n(_['score_matrix']['bats_analogy'].groupby('method').mean())\n# _['score_matrix']['google_analogy'].query('method==\"IN-OUT\"')","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":4,"column_count":2,"columns":[{"name":"cos3add_score","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0,"max":0.27209302325581397,"histogram":[{"bin_start":0,"bin_end":0.027209302325581396,"count":1},{"bin_start":0.027209302325581396,"bin_end":0.05441860465116279,"count":0},{"bin_start":0.05441860465116279,"bin_end":0.08162790697674419,"count":0},{"bin_start":0.08162790697674419,"bin_end":0.10883720930232559,"count":0},{"bin_start":0.10883720930232559,"bin_end":0.13604651162790699,"count":0},{"bin_start":0.13604651162790699,"bin_end":0.16325581395348837,"count":1},{"bin_start":0.16325581395348837,"bin_end":0.19046511627906978,"count":0},{"bin_start":0.19046511627906978,"bin_end":0.21767441860465117,"count":1},{"bin_start":0.21767441860465117,"bin_end":0.24488372093023256,"count":0},{"bin_start":0.24488372093023256,"bin_end":0.27209302325581397,"count":1}]}},{"name":"cos3mul_score","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0,"max":0.2302325581395349,"histogram":[{"bin_start":0,"bin_end":0.023023255813953487,"count":1},{"bin_start":0.023023255813953487,"bin_end":0.046046511627906975,"count":0},{"bin_start":0.046046511627906975,"bin_end":0.06906976744186047,"count":0},{"bin_start":0.06906976744186047,"bin_end":0.09209302325581395,"count":0},{"bin_start":0.09209302325581395,"bin_end":0.11511627906976743,"count":0},{"bin_start":0.11511627906976743,"bin_end":0.13813953488372094,"count":0},{"bin_start":0.13813953488372094,"bin_end":0.16116279069767442,"count":1},{"bin_start":0.16116279069767442,"bin_end":0.1841860465116279,"count":0},{"bin_start":0.1841860465116279,"bin_end":0.20720930232558138,"count":1},{"bin_start":0.20720930232558138,"bin_end":0.2302325581395349,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"cos3add_score":0.27209302325581397,"cos3mul_score":0.2302325581395349,"_deepnote_index_column":"IN-IN"},{"cos3add_score":0.15348837209302327,"cos3mul_score":0.1511627906976744,"_deepnote_index_column":"IN-OUT"},{"cos3add_score":0,"cos3mul_score":0,"_deepnote_index_column":"OUT-IN"},{"cos3add_score":0.2069767441860465,"cos3mul_score":0.20465116279069767,"_deepnote_index_column":"OUT-OUT"}],"rows_bottom":null},"text/plain":"         cos3add_score  cos3mul_score\nmethod                               \nIN-IN         0.272093       0.230233\nIN-OUT        0.153488       0.151163\nOUT-IN        0.000000       0.000000\nOUT-OUT       0.206977       0.204651","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cos3add_score</th>\n      <th>cos3mul_score</th>\n    </tr>\n    <tr>\n      <th>method</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>IN-IN</th>\n      <td>0.272093</td>\n      <td>0.230233</td>\n    </tr>\n    <tr>\n      <th>IN-OUT</th>\n      <td>0.153488</td>\n      <td>0.151163</td>\n    </tr>\n    <tr>\n      <th>OUT-IN</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>OUT-OUT</th>\n      <td>0.206977</td>\n      <td>0.204651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00017-2df67f67-35a1-4951-bd8c-93266efbdec0"},"source":"","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"'listens'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Run Relatedness tests","metadata":{"tags":[],"cell_id":"00016-a624bffc-10ff-4feb-959a-457ee38599db"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00016-ff3acfd2-7377-4bad-85fa-dbc0dbe8b3f5"},"source":"# all_df_res = []\n# all_missing_words = []\n\n# perform this for each model\n# for model_dir in tqdm(glob.glob(\"../../../embeddings_lemma/word2vec_*\")[3:]):\nfor model_dir in tqdm(glob_w2v_models):\n    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n    model = Word2Vec.load(model_path)\n    model.wv.vectors = nnorm(model.wv.vectors) \n    model.trainables.syn1neg = nnorm(model.trainables.syn1neg)\n    # print(\"Running analysis on each dataset\")\n    # Step 1: Handle relatedness dataset\n    futures = [compare_word2vec_model_with_relatedness_dataset.remote(model, model_name, dataset_name, dataset) \\\n                    for dataset_name, dataset in all_datasets['relatedness_datasets'].items()]\n    res = ray.get(futures)    \n    # print(\"Post processing and Saving results\")\n    # pd.concat(res, axis=1)\n    df_res = pd.concat([df_res for df_res, _, _ in res], axis=1)\n    missing_words = {key:val for _, key, val in res}\n    # all_df_res.append(df_res)\n    # all_missing_words.append(missing_words)\n    with open(f\"../output/word2vec/relatedness/word2vec_results_{model_name}_relatedness.pickle\", \"wb\") as f:\n        pickle.dump({\"score_matrix\": df_res, 'missing_words': missing_words}, f)\n    try:\n        send_telegram_message(model_name)\n        send_telegram_message(str(df_res.iloc[:, [0]]))\n    except:\n        pass","execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/12 [00:00<?, ?it/s]\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:15.305629   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008004000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n2020-09-01 19:52:19,004\tINFO (unknown file):0 -- gc.collect() freed 16 refs in 3.551877399906516 seconds\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:16.324450   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008004000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[36m(pid=249)\u001b[0m 2020-09-01 19:52:16,983\tINFO (unknown file):0 -- gc.collect() freed 7 refs in 1.5036049876362085 seconds\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:18.325723   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008004000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:22.326722   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008004000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:49.424046   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008005000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:50.425778   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008005000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[36m(pid=247)\u001b[0m 2020-09-01 19:52:51,213\tINFO (unknown file):0 -- gc.collect() freed 7 refs in 1.1586590576916933 seconds\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:52.426862   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008005000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:52:56.431663   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008005000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:53:21.806563   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008006000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:53:22.813490   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008006000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:53:24.817822   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008006000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:53:28.819188   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008006000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:53:36.826557   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008006000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E0901 19:53:52.827723   218   233 store.cc:252] Not enough memory to create the object ffffffffffffffffffffffff0100008006000000, data_size=769881459, metadata_size=6, will send a reply of PlasmaError::OutOfMemory\n  0%|          | 0/12 [03:28<?, ?it/s]\n","output_type":"stream"},{"output_type":"error","ename":"ObjectStoreFullError","evalue":"Failed to put object ffffffffffffffffffffffff0100008006000000 in object store because it is full. Object size is 769881459 bytes.\nThe local object store is full of objects that are still in scope and cannot be evicted. Try increasing the object store memory available with ray.init(object_store_memory=<bytes>). You can also try setting an option to fallback to LRU eviction when the object store is full by calling ray.init(lru_evict=True). See also: https://docs.ray.io/en/latest/memory-management.html.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mObjectStoreFullError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-155-b6b34bfe9298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Step 1: Handle relatedness dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     futures = [compare_word2vec_model_with_relatedness_dataset.remote(model, model_name, dataset_name, dataset) \\\n\u001b[0;32m---> 15\u001b[0;31m                     for dataset_name, dataset in all_datasets['relatedness_datasets'].items()]\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# print(\"Post processing and Saving results\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-155-b6b34bfe9298>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Step 1: Handle relatedness dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     futures = [compare_word2vec_model_with_relatedness_dataset.remote(model, model_name, dataset_name, dataset) \\\n\u001b[0;32m---> 15\u001b[0;31m                     for dataset_name, dataset in all_datasets['relatedness_datasets'].items()]\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# print(\"Post processing and Saving results\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/ray/remote_function.py\u001b[0m in \u001b[0;36m_remote_proxy\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_remote_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remote_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/ray/remote_function.py\u001b[0m in \u001b[0;36m_remote\u001b[0;34m(self, args, kwargs, num_return_vals, is_direct_call, num_cpus, num_gpus, memory, object_store_memory, resources, max_retries)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0minvocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minvocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/ray/remote_function.py\u001b[0m in \u001b[0;36minvocation\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m             object_refs = worker.core_worker.submit_task(\n\u001b[1;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 num_return_vals, resources, max_retries)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.prepare_args\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.put_serialized_object\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker._create_put_buffer\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mObjectStoreFullError\u001b[0m: Failed to put object ffffffffffffffffffffffff0100008006000000 in object store because it is full. Object size is 769881459 bytes.\nThe local object store is full of objects that are still in scope and cannot be evicted. Try increasing the object store memory available with ray.init(object_store_memory=<bytes>). You can also try setting an option to fallback to LRU eviction when the object store is full by calling ray.init(lru_evict=True). See also: https://docs.ray.io/en/latest/memory-management.html."]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00021-d2d51152-fe26-4a66-8e51-8ce8c479de9f"},"source":"## NO RAY version\n\n# perform this for each model\n# for model_dir in tqdm(glob.glob(\"../../../embeddings_lemma/word2vec_*\")[3:]):\nfor model_dir in tqdm(glob_w2v_models):\n    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n    model = Word2Vec.load(model_path)\n    model.wv.vectors = nnorm(model.wv.vectors) \n    model.trainables.syn1neg = nnorm(model.trainables.syn1neg)\n    # print(\"Running analysis on each dataset\")\n    # Step 1: Handle relatedness dataset\n    all_df_res = []\n    for dataset_name, dataset in all_datasets['relatedness_datasets'].items():\n        df_res = compare_word2vec_model_with_relatedness_dataset(model, model_name, dataset_name, dataset)\n        all_df_res.append(df_res)\n    with open(f\"../output/word2vec/relatedness/word2vec_results_{model_name}_relatedness.pickle\", \"wb\") as f:\n        pickle.dump({\"score_matrix\": all_df_res}, f)\n    try:\n        send_telegram_message(model_name)\n        send_telegram_message(str(df_res.iloc[:, [0]]))\n    except:\n        pass","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 12/12 [3:16:39<00:00, 983.28s/it]  \n","output_type":"stream"}]},{"cell_type":"code","metadata":{"allow_embed":false,"cell_id":"00012-1bf4c181-882e-4c11-8704-ec97b5fa2b31","tags":[]},"source":"# glob.glob(\"../../../embeddings_lemma/word2vec_mc=10_iter=5_size=100_window=5_sg=0/*\")\nimport pickle\nwith open(\"../output/word2vec/word2vec_results_word2vec_mc=10_size=100_window=5_sg=0_relatedness.pickle\", \"rb\") as f:\n    _ = pickle.load(f)\n_['score_matrix'][0]","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":4,"column_count":13,"columns":[{"name":"EN-VERB-143","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.2045174598297288,"max":0.39746927488993555,"histogram":[{"bin_start":0.2045174598297288,"bin_end":0.22381264133574946,"count":1},{"bin_start":0.22381264133574946,"bin_end":0.24310782284177015,"count":0},{"bin_start":0.24310782284177015,"bin_end":0.26240300434779085,"count":1},{"bin_start":0.26240300434779085,"bin_end":0.2816981858538115,"count":1},{"bin_start":0.2816981858538115,"bin_end":0.3009933673598322,"count":0},{"bin_start":0.3009933673598322,"bin_end":0.32028854886585284,"count":0},{"bin_start":0.32028854886585284,"bin_end":0.3395837303718735,"count":0},{"bin_start":0.3395837303718735,"bin_end":0.3588789118778942,"count":0},{"bin_start":0.3588789118778942,"bin_end":0.37817409338391483,"count":0},{"bin_start":0.37817409338391483,"bin_end":0.39746927488993555,"count":1}]}},{"name":"EN-SimVerb-3500","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.14138012756419324,"max":0.21731962411121528,"histogram":[{"bin_start":0.14138012756419324,"bin_end":0.14897407721889544,"count":2},{"bin_start":0.14897407721889544,"bin_end":0.15656802687359764,"count":0},{"bin_start":0.15656802687359764,"bin_end":0.16416197652829984,"count":0},{"bin_start":0.16416197652829984,"bin_end":0.17175592618300206,"count":0},{"bin_start":0.17175592618300206,"bin_end":0.17934987583770426,"count":0},{"bin_start":0.17934987583770426,"bin_end":0.18694382549240646,"count":0},{"bin_start":0.18694382549240646,"bin_end":0.19453777514710865,"count":0},{"bin_start":0.19453777514710865,"bin_end":0.20213172480181085,"count":1},{"bin_start":0.20213172480181085,"bin_end":0.20972567445651308,"count":0},{"bin_start":0.20972567445651308,"bin_end":0.21731962411121528,"count":1}]}},{"name":"EN-RG-65","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6055483366333668,"max":0.8019565031250883,"histogram":[{"bin_start":0.6055483366333668,"bin_end":0.625189153282539,"count":1},{"bin_start":0.625189153282539,"bin_end":0.6448299699317112,"count":0},{"bin_start":0.6448299699317112,"bin_end":0.6644707865808832,"count":0},{"bin_start":0.6644707865808832,"bin_end":0.6841116032300554,"count":0},{"bin_start":0.6841116032300554,"bin_end":0.7037524198792275,"count":0},{"bin_start":0.7037524198792275,"bin_end":0.7233932365283997,"count":0},{"bin_start":0.7233932365283997,"bin_end":0.7430340531775719,"count":1},{"bin_start":0.7430340531775719,"bin_end":0.762674869826744,"count":0},{"bin_start":0.762674869826744,"bin_end":0.7823156864759161,"count":0},{"bin_start":0.7823156864759161,"bin_end":0.8019565031250883,"count":2}]}},{"name":"EN-RW-STANFORD","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.15552612236157692,"max":0.414003281667331,"histogram":[{"bin_start":0.15552612236157692,"bin_end":0.18137383829215234,"count":1},{"bin_start":0.18137383829215234,"bin_end":0.20722155422272776,"count":0},{"bin_start":0.20722155422272776,"bin_end":0.23306927015330314,"count":0},{"bin_start":0.23306927015330314,"bin_end":0.2589169860838786,"count":1},{"bin_start":0.2589169860838786,"bin_end":0.284764702014454,"count":0},{"bin_start":0.284764702014454,"bin_end":0.31061241794502936,"count":0},{"bin_start":0.31061241794502936,"bin_end":0.3364601338756048,"count":0},{"bin_start":0.3364601338756048,"bin_end":0.3623078498061802,"count":0},{"bin_start":0.3623078498061802,"bin_end":0.3881555657367556,"count":0},{"bin_start":0.3881555657367556,"bin_end":0.414003281667331,"count":2}]}},{"name":"EN-MTurk-771","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.4977091531872367,"max":0.6587903550055381,"histogram":[{"bin_start":0.4977091531872367,"bin_end":0.5138172733690668,"count":1},{"bin_start":0.5138172733690668,"bin_end":0.529925393550897,"count":0},{"bin_start":0.529925393550897,"bin_end":0.5460335137327271,"count":0},{"bin_start":0.5460335137327271,"bin_end":0.5621416339145573,"count":0},{"bin_start":0.5621416339145573,"bin_end":0.5782497540963873,"count":0},{"bin_start":0.5782497540963873,"bin_end":0.5943578742782175,"count":0},{"bin_start":0.5943578742782175,"bin_end":0.6104659944600477,"count":0},{"bin_start":0.6104659944600477,"bin_end":0.6265741146418777,"count":0},{"bin_start":0.6265741146418777,"bin_end":0.6426822348237079,"count":0},{"bin_start":0.6426822348237079,"bin_end":0.6587903550055381,"count":3}]}},{"name":"EN-MEN-TR-3k","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.5902626534276089,"max":0.7667695758642483,"histogram":[{"bin_start":0.5902626534276089,"bin_end":0.6079133456712729,"count":1},{"bin_start":0.6079133456712729,"bin_end":0.6255640379149368,"count":0},{"bin_start":0.6255640379149368,"bin_end":0.6432147301586006,"count":0},{"bin_start":0.6432147301586006,"bin_end":0.6608654224022646,"count":0},{"bin_start":0.6608654224022646,"bin_end":0.6785161146459286,"count":0},{"bin_start":0.6785161146459286,"bin_end":0.6961668068895925,"count":0},{"bin_start":0.6961668068895925,"bin_end":0.7138174991332564,"count":0},{"bin_start":0.7138174991332564,"bin_end":0.7314681913769204,"count":1},{"bin_start":0.7314681913769204,"bin_end":0.7491188836205844,"count":0},{"bin_start":0.7491188836205844,"bin_end":0.7667695758642483,"count":2}]}},{"name":"EN-MC-30","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6881511709607714,"max":0.8323022512021407,"histogram":[{"bin_start":0.6881511709607714,"bin_end":0.7025662789849083,"count":1},{"bin_start":0.7025662789849083,"bin_end":0.7169813870090452,"count":0},{"bin_start":0.7169813870090452,"bin_end":0.7313964950331822,"count":0},{"bin_start":0.7313964950331822,"bin_end":0.7458116030573191,"count":0},{"bin_start":0.7458116030573191,"bin_end":0.760226711081456,"count":0},{"bin_start":0.760226711081456,"bin_end":0.774641819105593,"count":0},{"bin_start":0.774641819105593,"bin_end":0.78905692712973,"count":1},{"bin_start":0.78905692712973,"bin_end":0.8034720351538669,"count":0},{"bin_start":0.8034720351538669,"bin_end":0.8178871431780038,"count":0},{"bin_start":0.8178871431780038,"bin_end":0.8323022512021407,"count":2}]}},{"name":"EN-MTurk-287","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.529686774390123,"max":0.7144052798698126,"histogram":[{"bin_start":0.529686774390123,"bin_end":0.548158624938092,"count":1},{"bin_start":0.548158624938092,"bin_end":0.5666304754860609,"count":0},{"bin_start":0.5666304754860609,"bin_end":0.5851023260340299,"count":0},{"bin_start":0.5851023260340299,"bin_end":0.6035741765819989,"count":0},{"bin_start":0.6035741765819989,"bin_end":0.6220460271299678,"count":0},{"bin_start":0.6220460271299678,"bin_end":0.6405178776779368,"count":0},{"bin_start":0.6405178776779368,"bin_end":0.6589897282259057,"count":1},{"bin_start":0.6589897282259057,"bin_end":0.6774615787738747,"count":0},{"bin_start":0.6774615787738747,"bin_end":0.6959334293218437,"count":1},{"bin_start":0.6959334293218437,"bin_end":0.7144052798698126,"count":1}]}},{"name":"EN-SIMLEX-999","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.26235457814126206,"max":0.3774817412189316,"histogram":[{"bin_start":0.26235457814126206,"bin_end":0.273867294449029,"count":1},{"bin_start":0.273867294449029,"bin_end":0.285380010756796,"count":1},{"bin_start":0.285380010756796,"bin_end":0.29689272706456293,"count":0},{"bin_start":0.29689272706456293,"bin_end":0.3084054433723299,"count":0},{"bin_start":0.3084054433723299,"bin_end":0.31991815968009685,"count":0},{"bin_start":0.31991815968009685,"bin_end":0.3314308759878638,"count":1},{"bin_start":0.3314308759878638,"bin_end":0.3429435922956307,"count":0},{"bin_start":0.3429435922956307,"bin_end":0.35445630860339766,"count":0},{"bin_start":0.35445630860339766,"bin_end":0.3659690249111646,"count":0},{"bin_start":0.3659690249111646,"bin_end":0.3774817412189316,"count":1}]}},{"name":"EN-WS-353-REL","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.4758090741994607,"max":0.6367034822341671,"histogram":[{"bin_start":0.4758090741994607,"bin_end":0.49189851500293136,"count":1},{"bin_start":0.49189851500293136,"bin_end":0.507987955806402,"count":0},{"bin_start":0.507987955806402,"bin_end":0.5240773966098726,"count":0},{"bin_start":0.5240773966098726,"bin_end":0.5401668374133433,"count":0},{"bin_start":0.5401668374133433,"bin_end":0.5562562782168139,"count":1},{"bin_start":0.5562562782168139,"bin_end":0.5723457190202845,"count":0},{"bin_start":0.5723457190202845,"bin_end":0.5884351598237552,"count":0},{"bin_start":0.5884351598237552,"bin_end":0.6045246006272258,"count":0},{"bin_start":0.6045246006272258,"bin_end":0.6206140414306964,"count":0},{"bin_start":0.6206140414306964,"bin_end":0.6367034822341671,"count":2}]}},{"name":"EN-YP-130","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.30044356848489134,"max":0.4632022954239011,"histogram":[{"bin_start":0.30044356848489134,"bin_end":0.3167194411787923,"count":1},{"bin_start":0.3167194411787923,"bin_end":0.3329953138726933,"count":0},{"bin_start":0.3329953138726933,"bin_end":0.3492711865665943,"count":0},{"bin_start":0.3492711865665943,"bin_end":0.36554705926049524,"count":0},{"bin_start":0.36554705926049524,"bin_end":0.3818229319543962,"count":0},{"bin_start":0.3818229319543962,"bin_end":0.3980988046482972,"count":1},{"bin_start":0.3980988046482972,"bin_end":0.4143746773421982,"count":0},{"bin_start":0.4143746773421982,"bin_end":0.4306505500360992,"count":0},{"bin_start":0.4306505500360992,"bin_end":0.44692642273000016,"count":1},{"bin_start":0.44692642273000016,"bin_end":0.4632022954239011,"count":1}]}},{"name":"EN-WS-353-ALL","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.5516145103621383,"max":0.6704490061266352,"histogram":[{"bin_start":0.5516145103621383,"bin_end":0.563497959938588,"count":1},{"bin_start":0.563497959938588,"bin_end":0.5753814095150377,"count":0},{"bin_start":0.5753814095150377,"bin_end":0.5872648590914873,"count":0},{"bin_start":0.5872648590914873,"bin_end":0.599148308667937,"count":0},{"bin_start":0.599148308667937,"bin_end":0.6110317582443867,"count":0},{"bin_start":0.6110317582443867,"bin_end":0.6229152078208364,"count":0},{"bin_start":0.6229152078208364,"bin_end":0.6347986573972861,"count":1},{"bin_start":0.6347986573972861,"bin_end":0.6466821069737357,"count":0},{"bin_start":0.6466821069737357,"bin_end":0.6585655565501854,"count":0},{"bin_start":0.6585655565501854,"bin_end":0.6704490061266352,"count":2}]}},{"name":"EN-WS-353-SIM","dtype":"float64","stats":{"unique_count":4,"nan_count":0,"min":0.6045634941309105,"max":0.7297362268043539,"histogram":[{"bin_start":0.6045634941309105,"bin_end":0.6170807673982548,"count":1},{"bin_start":0.6170807673982548,"bin_end":0.6295980406655992,"count":0},{"bin_start":0.6295980406655992,"bin_end":0.6421153139329435,"count":0},{"bin_start":0.6421153139329435,"bin_end":0.6546325872002878,"count":0},{"bin_start":0.6546325872002878,"bin_end":0.6671498604676322,"count":0},{"bin_start":0.6671498604676322,"bin_end":0.6796671337349766,"count":0},{"bin_start":0.6796671337349766,"bin_end":0.6921844070023209,"count":0},{"bin_start":0.6921844070023209,"bin_end":0.7047016802696652,"count":0},{"bin_start":0.7047016802696652,"bin_end":0.7172189535370096,"count":0},{"bin_start":0.7172189535370096,"bin_end":0.7297362268043539,"count":3}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"EN-VERB-143":0.39746927488993555,"EN-SimVerb-3500":0.21731962411121528,"EN-RG-65":0.7339761489480742,"EN-RW-STANFORD":0.39923584983394395,"EN-MTurk-771":0.6587903550055381,"EN-MEN-TR-3k":0.7205426693458772,"EN-MC-30":0.7881115853499098,"EN-MTurk-287":0.7144052798698126,"EN-SIMLEX-999":0.3774817412189316,"EN-WS-353-REL":0.5544344817337636,"EN-YP-130":0.396154225645398,"EN-WS-353-ALL":0.6293832518117112,"EN-WS-353-SIM":0.7208313695189691,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_IN-IN"},{"EN-VERB-143":0.2045174598297288,"EN-SimVerb-3500":0.14138012756419324,"EN-RG-65":0.8019565031250883,"EN-RW-STANFORD":0.15552612236157692,"EN-MTurk-771":0.6560076486521655,"EN-MEN-TR-3k":0.7649573922625617,"EN-MC-30":0.8323022512021407,"EN-MTurk-287":0.6577932250425418,"EN-SIMLEX-999":0.28006676307827794,"EN-WS-353-REL":0.6367034822341671,"EN-YP-130":0.44303416827663616,"EN-WS-353-ALL":0.6704490061266352,"EN-WS-353-SIM":0.7297362268043539,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_IN-OUT"},{"EN-VERB-143":0.27155124547580356,"EN-SimVerb-3500":0.14498121166398756,"EN-RG-65":0.7986096159098365,"EN-RW-STANFORD":0.23524667907506983,"EN-MTurk-771":0.6474495518240032,"EN-MEN-TR-3k":0.7667695758642483,"EN-MC-30":0.8230561715516306,"EN-MTurk-287":0.679872611505997,"EN-SIMLEX-999":0.26235457814126206,"EN-WS-353-REL":0.6316461276242601,"EN-YP-130":0.4632022954239011,"EN-WS-353-ALL":0.6633233613157942,"EN-WS-353-SIM":0.7257652560000988,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_OUT-IN"},{"EN-VERB-143":0.2602141346223455,"EN-SimVerb-3500":0.19665309300094058,"EN-RG-65":0.6055483366333668,"EN-RW-STANFORD":0.414003281667331,"EN-MTurk-771":0.4977091531872367,"EN-MEN-TR-3k":0.5902626534276089,"EN-MC-30":0.6881511709607714,"EN-MTurk-287":0.529686774390123,"EN-SIMLEX-999":0.3249865487373889,"EN-WS-353-REL":0.4758090741994607,"EN-YP-130":0.30044356848489134,"EN-WS-353-ALL":0.5516145103621383,"EN-WS-353-SIM":0.6045634941309105,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_OUT-OUT"}],"rows_bottom":null},"text/plain":"                                               EN-VERB-143  EN-SimVerb-3500  \\\nword2vec_mc=10_size=100_window=5_sg=0_IN-IN       0.397469         0.217320   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT      0.204517         0.141380   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN      0.271551         0.144981   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT     0.260214         0.196653   \n\n                                               EN-RG-65  EN-RW-STANFORD  \\\nword2vec_mc=10_size=100_window=5_sg=0_IN-IN    0.733976        0.399236   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT   0.801957        0.155526   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN   0.798610        0.235247   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT  0.605548        0.414003   \n\n                                               EN-MTurk-771  EN-MEN-TR-3k  \\\nword2vec_mc=10_size=100_window=5_sg=0_IN-IN        0.658790      0.720543   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT       0.656008      0.764957   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN       0.647450      0.766770   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT      0.497709      0.590263   \n\n                                               EN-MC-30  EN-MTurk-287  \\\nword2vec_mc=10_size=100_window=5_sg=0_IN-IN    0.788112      0.714405   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT   0.832302      0.657793   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN   0.823056      0.679873   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT  0.688151      0.529687   \n\n                                               EN-SIMLEX-999  EN-WS-353-REL  \\\nword2vec_mc=10_size=100_window=5_sg=0_IN-IN         0.377482       0.554434   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT        0.280067       0.636703   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN        0.262355       0.631646   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT       0.324987       0.475809   \n\n                                               EN-YP-130  EN-WS-353-ALL  \\\nword2vec_mc=10_size=100_window=5_sg=0_IN-IN     0.396154       0.629383   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT    0.443034       0.670449   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN    0.463202       0.663323   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT   0.300444       0.551615   \n\n                                               EN-WS-353-SIM  \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN         0.720831  \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT        0.729736  \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN        0.725765  \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT       0.604563  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EN-VERB-143</th>\n      <th>EN-SimVerb-3500</th>\n      <th>EN-RG-65</th>\n      <th>EN-RW-STANFORD</th>\n      <th>EN-MTurk-771</th>\n      <th>EN-MEN-TR-3k</th>\n      <th>EN-MC-30</th>\n      <th>EN-MTurk-287</th>\n      <th>EN-SIMLEX-999</th>\n      <th>EN-WS-353-REL</th>\n      <th>EN-YP-130</th>\n      <th>EN-WS-353-ALL</th>\n      <th>EN-WS-353-SIM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_IN-IN</th>\n      <td>0.397469</td>\n      <td>0.217320</td>\n      <td>0.733976</td>\n      <td>0.399236</td>\n      <td>0.658790</td>\n      <td>0.720543</td>\n      <td>0.788112</td>\n      <td>0.714405</td>\n      <td>0.377482</td>\n      <td>0.554434</td>\n      <td>0.396154</td>\n      <td>0.629383</td>\n      <td>0.720831</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_IN-OUT</th>\n      <td>0.204517</td>\n      <td>0.141380</td>\n      <td>0.801957</td>\n      <td>0.155526</td>\n      <td>0.656008</td>\n      <td>0.764957</td>\n      <td>0.832302</td>\n      <td>0.657793</td>\n      <td>0.280067</td>\n      <td>0.636703</td>\n      <td>0.443034</td>\n      <td>0.670449</td>\n      <td>0.729736</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_OUT-IN</th>\n      <td>0.271551</td>\n      <td>0.144981</td>\n      <td>0.798610</td>\n      <td>0.235247</td>\n      <td>0.647450</td>\n      <td>0.766770</td>\n      <td>0.823056</td>\n      <td>0.679873</td>\n      <td>0.262355</td>\n      <td>0.631646</td>\n      <td>0.463202</td>\n      <td>0.663323</td>\n      <td>0.725765</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_OUT-OUT</th>\n      <td>0.260214</td>\n      <td>0.196653</td>\n      <td>0.605548</td>\n      <td>0.414003</td>\n      <td>0.497709</td>\n      <td>0.590263</td>\n      <td>0.688151</td>\n      <td>0.529687</td>\n      <td>0.324987</td>\n      <td>0.475809</td>\n      <td>0.300444</td>\n      <td>0.551615</td>\n      <td>0.604563</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Run association test","metadata":{"tags":[],"cell_id":"00019-b253e8bb-1190-4447-a8c3-403f98b26655"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00020-488a8409-12ab-4206-85db-f1f34aa1982f"},"source":"all_datasets['association_datasets'].keys()","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"dict_keys(['swow8500', 'eat'])"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00020-2d2f9320-fa87-41e3-9345-3e9e9bcc8941"},"source":"\n# perform this for each model\n# for model_dir in tqdm(glob.glob(\"../../../embeddings_lemma/word2vec_*\")[3:]):\nfor model_dir in tqdm(glob_w2v_models):\n    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n    model = Word2Vec.load(model_path)\n    model.wv.vectors = nnorm(model.wv.vectors) \n    model.trainables.syn1neg = nnorm(model.trainables.syn1neg)\n    # model = pin_in_object_store(model)\n    # print(\"Running analysis on each dataset\")\n    # Step 1: Handle relatedness dataset\n    futures = [word2vec_test_association_dataset.remote(model, model_name, dataset_name, dataset) \\\n                    for dataset_name, dataset in all_datasets['association_datasets'].items()]\n    res = ray.get(futures)    \n    # print(\"Post processing and Saving results\")\n    # pd.concat(res, axis=1)\n    df_res = {dname:df_res for dname, df_res in res}\n    with open(f\"../output/word2vec/association/word2vec_results_{model_name}_association.pickle\", \"wb\") as f:\n        pickle.dump({\"score_matrix\": df_res}, f)\n    try:\n        send_telegram_message(model_name)\n    except:\n        pass","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 12/12 [11:05:23<00:00, 3326.95s/it] \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test Analogy","metadata":{"tags":[],"cell_id":"00022-6bf910b8-a94f-49cb-8bcc-7fdbe73c0393"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00023-a3bc850d-95d1-4a23-b86c-05db42e5c44f","output_cleared":false},"source":"# all_datasets['analogy_datasets']['google_analogy'][:]\ndef cos3mul(compare_matrix, word_index, a, a_s, b,  b_s, top_n, e=0.0000001):\n    c = np.stack([b, a_s, a], axis=1)\n    all_scores = np.dot(compare_matrix, c)\n    all_scores = (all_scores + 1)/2 # normalize bw 0 to 1\n    all_scores[:, 2] += e\n    all_scores = ((all_scores[:, 0] * all_scores[:, 1]) / all_scores[:, 2])\n    top_n_similar_words = np.argpartition(-all_scores, top_n)[:top_n]\n    sorted_result = sorted([(word_index[index], all_scores[index]) for index in top_n_similar_words], \n                key=lambda x: x[1], \n                reverse=True)\n    sorted_result = [x[0] for x in sorted_result]\n    return sorted_result, 1 if b_s in sorted_result else 0\n\ndef cos3add(compare_matrix, a, a_s, b, b_s, top_n, index2word):\n    \"\"\"Find the most similar vector with (b-a+a_)\n    \"\"\"\n    b_ = b.reshape(1, -1)-a.reshape(1, -1)+a_s.reshape(1, -1)\n    res = word2vec_find_top_similar_vectors_bw_matrix(\n            b_, compare_matrix, None, index2word, top_n=top_n, no_self_similarity=False)\n    res = [x[0] for x in res]\n    return res, 1 if b_s in res else 0\n\n# for dataset_name, dataset in all_datasets['analogy_datasets'].items():\n    # dataset_result = []\n@ray.remote\ndef word2vec_test_analogy_dataset(model_name, dataset, dataset_name):\n    word2vec_model = get_pinned_object(model)\n    for row in tqdm(dataset):\n        a, a_s, b, b_s = row\n        try:\n            a_index = word2vec_get_index_by_word(word2vec_model, a)\n            a_s_index = word2vec_get_index_by_word(word2vec_model, a_s)\n            b_index = word2vec_get_index_by_word(word2vec_model, b)\n            b_s_index = word2vec_get_index_by_word(word2vec_model, b_s)\n        except:\n            continue\n        for method in [\"IN-IN\", \"IN-OUT\", \"OUT-IN\", \"OUT-OUT\"]:\n            source_matrix, compare_matrix = word2vec_get_model_matrix_by_method(word2vec_model, method)\n            a_vector = source_matrix[a_index]\n            a_s_vector = source_matrix[a_s_index]\n            b_vector = source_matrix[b_index]\n            cos3add_response, cos3add_score = \\\n                cos3add(compare_matrix.T, a_vector, a_s_vector, b_vector, b_s, 3, word2vec_model.wv.index2word)\n            cos3mul_response, cos3mul_score = \\\n                cos3mul(compare_matrix, word2vec_model.wv.index2word, a_vector, a_s_vector, b_vector, b_s, top_n=3)\n            dataset_result.append({\n                'analogy': row,\n                'method': method, \n                'cos3add_response': cos3add_response,\n                'cos3add_score': cos3add_score,\n                'cos3mul_response': cos3mul_response,\n                'cos3mul_score': cos3mul_score\n            })\n    return dataset_name, pd.DataFrame(dataset_result)\n\n# perform this for each model\nfor model_dir in tqdm(glob_w2v_models):\n    model_name = model_dir.replace(\"../../../embeddings_lemma/\", \"\").replace(\"iter=5_\", \"\")\n    model_path = glob.glob(model_dir + \"/*[!(npy)]\")[0]\n    model = Word2Vec.load(model_path)\n    model.wv.vectors = nnorm(model.wv.vectors) \n    model.trainables.syn1neg = nnorm(model.trainables.syn1neg)\n    model = pin_in_object_store(model)\n    # print(\"Running analysis on each dataset\")\n    # Step 1: Handle relatedness dataset\n    futures = [word2vec_test_association_dataset.remote(model_name, dataset_name, dataset) \\\n                    for dataset_name, dataset in all_datasets['analogy_datasets'].items()]\n    res = ray.get(futures)    \n    # print(\"Post processing and Saving results\")\n    # pd.concat(res, axis=1)\n    df_res = {dname:df_res for dname, df_res in res}\n    with open(f\"../output/word2vec_results_{model_name}_analogy.pickle\", \"wb\") as f:\n        pickle.dump({\"score_matrix\": df_res}, f)\n                ","execution_count":null,"outputs":[{"name":"stderr","text":"  3%|▎         | 27/994 [00:15<09:04,  1.78it/s]\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-5022405dacad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mcos3add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_s_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mcos3mul_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos3mul_score\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mcos3mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_s_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             dataset_result.append({\n\u001b[1;32m     46\u001b[0m                 \u001b[0;34m'analogy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-86-5022405dacad>\u001b[0m in \u001b[0;36mcos3mul\u001b[0;34m(compare_matrix, word_index, a, a_s, b, b_s, top_n, e)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcos3mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompare_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;31m# normalize bw 0 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mall_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00022-06d4b811-1708-4c52-83f6-50782ebd09e5"},"source":"pd.DataFrame(dataset_result)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":90,"data":{"application/vnd.deepnote.dataframe.v2+json":{"error":"Traceback (most recent call last):\n  File \"/home/jovyan/.deepnote/variable_explorer.py\", line 270, in dataframe_formatter\n    return { MIME_TYPE: describe_pd_dataframe(df) }\n  File \"/home/jovyan/.deepnote/variable_explorer_helpers.py\", line 97, in describe_pd_dataframe\n    'unique_count': column.dropna().nunique(),\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1284, in nunique\n    uniqs = self.unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/series.py\", line 1816, in unique\n    result = super().unique()\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/base.py\", line 1246, in unique\n    result = unique1d(values)\n  File \"/opt/venv/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 382, in unique\n    uniques = table.unique(values)\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1784, in pandas._libs.hashtable.PyObjectHashTable.unique\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1731, in pandas._libs.hashtable.PyObjectHashTable._unique\nTypeError: unhashable type: 'list'\n"},"text/plain":"                                      analogy   method  \\\n0          [rome, italy, islamabad, pakistan]    IN-IN   \n1          [rome, italy, islamabad, pakistan]   IN-OUT   \n2          [rome, italy, islamabad, pakistan]   OUT-IN   \n3          [rome, italy, islamabad, pakistan]  OUT-OUT   \n4       [hanoi, vietnam, canberra, australia]    IN-IN   \n..                                        ...      ...   \n105  [bangkok, thailand, canberra, australia]   IN-OUT   \n106  [bangkok, thailand, canberra, australia]   OUT-IN   \n107  [bangkok, thailand, canberra, australia]  OUT-OUT   \n108           [madrid, spain, athens, greece]    IN-IN   \n109           [madrid, spain, athens, greece]   IN-OUT   \n\n                           cos3add_response  cos3add_score  \\\n0     [islamabad, malaysia, ===pakistan===]              0   \n1                [pakistan, malaysia, iran]              1   \n2       [aa/semitic, petrochimi, tejan-sie]              0   \n3           [islamabad, pakistan, sargodha]              1   \n4        [canberra, queensland, australian]              0   \n..                                      ...            ...   \n105  [australia, canberra, ===australia===]              1   \n106           [aa/semitic, hmts, forceably]              0   \n107        [canberra, queensland, tasmania]              0   \n108          [greece, athens, peloponnesus]              1   \n109             [greece, athens, macedonia]              1   \n\n                                 cos3mul_response  cos3mul_score  \n0    [===pakistan===, ====pakistan====, malaysia]              0  \n1                [pakistan, malaysia, bangladesh]              1  \n2             [aa/semitic, petrochimi, tejan-sie]              0  \n3         [pakistan, islamabad, gilgit-baltistan]              1  \n4                   [queensland, australian, nsw]              0  \n..                                            ...            ...  \n105        [australia, ===australia===, canberra]              1  \n106                 [aa/semitic, hmts, forceably]              0  \n107              [canberra, queensland, tasmania]              0  \n108                     [greece, colchis, athens]              1  \n109                   [greece, athens, macedonia]              1  \n\n[110 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>analogy</th>\n      <th>method</th>\n      <th>cos3add_response</th>\n      <th>cos3add_score</th>\n      <th>cos3mul_response</th>\n      <th>cos3mul_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[rome, italy, islamabad, pakistan]</td>\n      <td>IN-IN</td>\n      <td>[islamabad, malaysia, ===pakistan===]</td>\n      <td>0</td>\n      <td>[===pakistan===, ====pakistan====, malaysia]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[rome, italy, islamabad, pakistan]</td>\n      <td>IN-OUT</td>\n      <td>[pakistan, malaysia, iran]</td>\n      <td>1</td>\n      <td>[pakistan, malaysia, bangladesh]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[rome, italy, islamabad, pakistan]</td>\n      <td>OUT-IN</td>\n      <td>[aa/semitic, petrochimi, tejan-sie]</td>\n      <td>0</td>\n      <td>[aa/semitic, petrochimi, tejan-sie]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[rome, italy, islamabad, pakistan]</td>\n      <td>OUT-OUT</td>\n      <td>[islamabad, pakistan, sargodha]</td>\n      <td>1</td>\n      <td>[pakistan, islamabad, gilgit-baltistan]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[hanoi, vietnam, canberra, australia]</td>\n      <td>IN-IN</td>\n      <td>[canberra, queensland, australian]</td>\n      <td>0</td>\n      <td>[queensland, australian, nsw]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>[bangkok, thailand, canberra, australia]</td>\n      <td>IN-OUT</td>\n      <td>[australia, canberra, ===australia===]</td>\n      <td>1</td>\n      <td>[australia, ===australia===, canberra]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>[bangkok, thailand, canberra, australia]</td>\n      <td>OUT-IN</td>\n      <td>[aa/semitic, hmts, forceably]</td>\n      <td>0</td>\n      <td>[aa/semitic, hmts, forceably]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>[bangkok, thailand, canberra, australia]</td>\n      <td>OUT-OUT</td>\n      <td>[canberra, queensland, tasmania]</td>\n      <td>0</td>\n      <td>[canberra, queensland, tasmania]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>[madrid, spain, athens, greece]</td>\n      <td>IN-IN</td>\n      <td>[greece, athens, peloponnesus]</td>\n      <td>1</td>\n      <td>[greece, colchis, athens]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>[madrid, spain, athens, greece]</td>\n      <td>IN-OUT</td>\n      <td>[greece, athens, macedonia]</td>\n      <td>1</td>\n      <td>[greece, athens, macedonia]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>110 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00021-ec290a1b-0c60-48c4-a75c-c40ce883b152"},"source":"# # all_datasets['analogy_datasets']['google_analogy']['gram8-plural'][:10]\n# # all_datasets['analogy_datasets']['bats_analogy'][:10]\n# # pd.DataFrame(dataset_result)\n# def cos3mul(compare_matrix, word_index, c,  b_s, top_n, e=0.0000001):\n#     all_scores = np.dot(compare_matrix, c)\n#     all_scores = (all_scores + 1)/2 # normalize bw 0 to 1\n#     all_scores[:, 2] += e\n#     all_scores = ((all_scores[:, 0] * all_scores[:, 1]) / all_scores[:, 2])\n#     top_n_similar_words = np.argpartition(-all_scores, top_n)[:top_n]\n#     sorted_result = sorted([(word_index[index], all_scores[index]) for index in top_n_similar_words], \n#                 key=lambda x: x[1], \n#                 reverse=True)\n#     sorted_result = [x[0] for x in sorted_result]\n#     return sorted_result, 1 if b_s in sorted_result else 0\n# # test\n# # source_matrix, compare_matrix = word2vec_get_model_matrix_by_method(model, \"IN-IN\")\n# # c = np.stack(\n# #     [source_matrix[word2vec_get_index_by_word(model, 'tehran')],\n# #     source_matrix[word2vec_get_index_by_word(model, 'italy')],\n# #     source_matrix[word2vec_get_index_by_word(model, 'rome')]]\n# #         , axis=1)\n# # cos3mul(compare_matrix, model.wv.index2word, c,  'pakistan', 10, e=0.0001)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":80,"data":{"text/plain":"(['iran',\n  'tehran',\n  '===iran===',\n  'azerbaijan',\n  'khodro',\n  'utc+03:30',\n  'kuwait',\n  'abadan',\n  'uae',\n  'bahrain'],\n 0)"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00023-9e2b03d5-cef1-4d3e-8cf6-c895c5fdf383"},"source":"# np.stack([[1, 0], [1, 1], [0, 1]], axis=1)\n# all_dataset\n# model.wv.most_similar(positive=['italy', 'islamabad'], negative=['rome'])\n# ais = np.dot(compare_matrix, c)\n# max(((ais[:, 0] * ais[:, 1])/(ais[:, 2]+0.001)))#[1951]\nais.min()","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"-0.4604089"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00024-b12b018f-19da-4818-839a-88fe668e041f"},"source":"# print(model.wv.index2word.index('pakistan'))\nall_datasets['analogy_datasets']['google_analogy'][:10]","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"[['rome', 'italy', 'islamabad', 'pakistan'],\n ['hanoi', 'vietnam', 'canberra', 'australia'],\n ['ottawa', 'canada', 'havana', 'cuba'],\n ['stockholm', 'sweden', 'london', 'england'],\n ['havana', 'cuba', 'berlin', 'germany'],\n ['athens', 'greece', 'tehran', 'iran'],\n ['cairo', 'egypt', 'canberra', 'australia'],\n ['tokyo', 'japan', 'helsinki', 'finland'],\n ['islamabad', 'pakistan', 'hanoi', 'vietnam'],\n ['islamabad', 'pakistan', 'paris', 'france']]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Combine all results","metadata":{"tags":[],"cell_id":"00013-224f56bd-8280-4ed9-ab56-c489d06e58e1"}},{"cell_type":"markdown","source":"### Relatedness","metadata":{"tags":[],"cell_id":"00032-57696227-b762-49f2-8207-d99eb9d5781a"}},{"cell_type":"code","metadata":{"cell_id":"00018-0c99c113-8491-4b9d-b22b-aec61548ecff","tags":[]},"source":"# Load all relatedness results\nall_relatedness_table = []\nfor result_file in glob.glob(\"../output/word2vec/relatedness/*\"):\n    with open (result_file, \"rb\") as f:\n        data = pickle.load(f)\n        table = pd.concat([x[0] for x in data['score_matrix']], axis=1)\n        all_relatedness_table.append(table)    \n        # print(result_file)\nall_relatedness_table = pd.concat(all_relatedness_table)\nall_relatedness_table.to_csv(\"../output/all_relatedness_table_v2.csv\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00033-16e5564e-fe45-46ea-a2d1-fafbb629dcad"},"source":"# all_relatedness_table.index\n# np.allclose(all_relatedness_table[3].values, all_relatedness_table[10].values)\n# pd.concat(all_relatedness_table)\n# all_relatedness_table[10].index\n# with open (glob.glob(\"../output/word2vec/relatedness/*\")[0], \"rb\") as f:\n#     data = pickle.load(f)\n# pd.concat([x[0] for x in data['score_matrix']], axis=1)\nall_relatedness_table\n","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":48,"column_count":13,"columns":[{"name":"EN-VERB-143","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.0954869101232928,"max":0.5179281413606942,"histogram":[{"bin_start":0.0954869101232928,"bin_end":0.13773103324703295,"count":3},{"bin_start":0.13773103324703295,"bin_end":0.17997515637077308,"count":4},{"bin_start":0.17997515637077308,"bin_end":0.2222192794945132,"count":4},{"bin_start":0.2222192794945132,"bin_end":0.26446340261825335,"count":7},{"bin_start":0.26446340261825335,"bin_end":0.3067075257419935,"count":7},{"bin_start":0.3067075257419935,"bin_end":0.3489516488657336,"count":6},{"bin_start":0.3489516488657336,"bin_end":0.39119577198947375,"count":5},{"bin_start":0.39119577198947375,"bin_end":0.4334398951132139,"count":8},{"bin_start":0.4334398951132139,"bin_end":0.47568401823695405,"count":2},{"bin_start":0.47568401823695405,"bin_end":0.5179281413606942,"count":2}]}},{"name":"EN-SimVerb-3500","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.11339584519742406,"max":0.25336211773918604,"histogram":[{"bin_start":0.11339584519742406,"bin_end":0.12739247245160026,"count":4},{"bin_start":0.12739247245160026,"bin_end":0.14138909970577646,"count":6},{"bin_start":0.14138909970577646,"bin_end":0.15538572695995265,"count":6},{"bin_start":0.15538572695995265,"bin_end":0.16938235421412884,"count":3},{"bin_start":0.16938235421412884,"bin_end":0.18337898146830506,"count":3},{"bin_start":0.18337898146830506,"bin_end":0.19737560872248122,"count":7},{"bin_start":0.19737560872248122,"bin_end":0.21137223597665744,"count":2},{"bin_start":0.21137223597665744,"bin_end":0.22536886323083363,"count":7},{"bin_start":0.22536886323083363,"bin_end":0.23936549048500982,"count":7},{"bin_start":0.23936549048500982,"bin_end":0.25336211773918604,"count":3}]}},{"name":"EN-RG-65","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.5497542000633383,"max":0.8103394567935266,"histogram":[{"bin_start":0.5497542000633383,"bin_end":0.5758127257363571,"count":1},{"bin_start":0.5758127257363571,"bin_end":0.6018712514093759,"count":0},{"bin_start":0.6018712514093759,"bin_end":0.6279297770823948,"count":5},{"bin_start":0.6279297770823948,"bin_end":0.6539883027554136,"count":3},{"bin_start":0.6539883027554136,"bin_end":0.6800468284284324,"count":3},{"bin_start":0.6800468284284324,"bin_end":0.7061053541014513,"count":5},{"bin_start":0.7061053541014513,"bin_end":0.7321638797744701,"count":3},{"bin_start":0.7321638797744701,"bin_end":0.7582224054474889,"count":4},{"bin_start":0.7582224054474889,"bin_end":0.7842809311205078,"count":3},{"bin_start":0.7842809311205078,"bin_end":0.8103394567935266,"count":21}]}},{"name":"EN-RW-STANFORD","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.13594572608097097,"max":0.44518229307827706,"histogram":[{"bin_start":0.13594572608097097,"bin_end":0.16686938278070157,"count":2},{"bin_start":0.16686938278070157,"bin_end":0.1977930394804322,"count":3},{"bin_start":0.1977930394804322,"bin_end":0.2287166961801628,"count":1},{"bin_start":0.2287166961801628,"bin_end":0.2596403528798934,"count":1},{"bin_start":0.2596403528798934,"bin_end":0.290564009579624,"count":4},{"bin_start":0.290564009579624,"bin_end":0.32148766627935466,"count":3},{"bin_start":0.32148766627935466,"bin_end":0.35241132297908523,"count":9},{"bin_start":0.35241132297908523,"bin_end":0.3833349796788158,"count":10},{"bin_start":0.3833349796788158,"bin_end":0.41425863637854643,"count":8},{"bin_start":0.41425863637854643,"bin_end":0.44518229307827706,"count":7}]}},{"name":"EN-MTurk-771","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.4208104815293742,"max":0.6857498490288588,"histogram":[{"bin_start":0.4208104815293742,"bin_end":0.44730441827932266,"count":2},{"bin_start":0.44730441827932266,"bin_end":0.47379835502927115,"count":3},{"bin_start":0.47379835502927115,"bin_end":0.5002922917792196,"count":1},{"bin_start":0.5002922917792196,"bin_end":0.526786228529168,"count":2},{"bin_start":0.526786228529168,"bin_end":0.5532801652791165,"count":1},{"bin_start":0.5532801652791165,"bin_end":0.579774102029065,"count":4},{"bin_start":0.579774102029065,"bin_end":0.6062680387790135,"count":6},{"bin_start":0.6062680387790135,"bin_end":0.632761975528962,"count":7},{"bin_start":0.632761975528962,"bin_end":0.6592559122789103,"count":13},{"bin_start":0.6592559122789103,"bin_end":0.6857498490288588,"count":9}]}},{"name":"EN-MEN-TR-3k","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.5145919562281084,"max":0.7808016200215596,"histogram":[{"bin_start":0.5145919562281084,"bin_end":0.5412129226074535,"count":3},{"bin_start":0.5412129226074535,"bin_end":0.5678338889867987,"count":2},{"bin_start":0.5678338889867987,"bin_end":0.5944548553661437,"count":1},{"bin_start":0.5944548553661437,"bin_end":0.6210758217454889,"count":0},{"bin_start":0.6210758217454889,"bin_end":0.647696788124834,"count":0},{"bin_start":0.647696788124834,"bin_end":0.6743177545041792,"count":3},{"bin_start":0.6743177545041792,"bin_end":0.7009387208835243,"count":3},{"bin_start":0.7009387208835243,"bin_end":0.7275596872628693,"count":12},{"bin_start":0.7275596872628693,"bin_end":0.7541806536422145,"count":13},{"bin_start":0.7541806536422145,"bin_end":0.7808016200215596,"count":11}]}},{"name":"EN-MC-30","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.6669604593219693,"max":0.896772486053877,"histogram":[{"bin_start":0.6669604593219693,"bin_end":0.6899416619951602,"count":7},{"bin_start":0.6899416619951602,"bin_end":0.7129228646683509,"count":5},{"bin_start":0.7129228646683509,"bin_end":0.7359040673415417,"count":1},{"bin_start":0.7359040673415417,"bin_end":0.7588852700147324,"count":3},{"bin_start":0.7588852700147324,"bin_end":0.7818664726879232,"count":11},{"bin_start":0.7818664726879232,"bin_end":0.804847675361114,"count":3},{"bin_start":0.804847675361114,"bin_end":0.8278288780343047,"count":7},{"bin_start":0.8278288780343047,"bin_end":0.8508100807074955,"count":7},{"bin_start":0.8508100807074955,"bin_end":0.8737912833806862,"count":2},{"bin_start":0.8737912833806862,"bin_end":0.896772486053877,"count":2}]}},{"name":"EN-MTurk-287","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.4296714101393483,"max":0.7367000674901923,"histogram":[{"bin_start":0.4296714101393483,"bin_end":0.4603742758744327,"count":2},{"bin_start":0.4603742758744327,"bin_end":0.4910771416095171,"count":2},{"bin_start":0.4910771416095171,"bin_end":0.5217800073446015,"count":1},{"bin_start":0.5217800073446015,"bin_end":0.5524828730796859,"count":1},{"bin_start":0.5524828730796859,"bin_end":0.5831857388147703,"count":0},{"bin_start":0.5831857388147703,"bin_end":0.6138886045498547,"count":0},{"bin_start":0.6138886045498547,"bin_end":0.6445914702849391,"count":2},{"bin_start":0.6445914702849391,"bin_end":0.6752943360200235,"count":7},{"bin_start":0.6752943360200235,"bin_end":0.7059972017551079,"count":21},{"bin_start":0.7059972017551079,"bin_end":0.7367000674901923,"count":12}]}},{"name":"EN-SIMLEX-999","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.20951308328084037,"max":0.39368308286572873,"histogram":[{"bin_start":0.20951308328084037,"bin_end":0.2279300832393292,"count":3},{"bin_start":0.2279300832393292,"bin_end":0.24634708319781803,"count":2},{"bin_start":0.24634708319781803,"bin_end":0.2647640831563069,"count":7},{"bin_start":0.2647640831563069,"bin_end":0.28318108311479573,"count":6},{"bin_start":0.28318108311479573,"bin_end":0.30159808307328456,"count":3},{"bin_start":0.30159808307328456,"bin_end":0.3200150830317734,"count":5},{"bin_start":0.3200150830317734,"bin_end":0.33843208299026223,"count":8},{"bin_start":0.33843208299026223,"bin_end":0.35684908294875106,"count":8},{"bin_start":0.35684908294875106,"bin_end":0.3752660829072399,"count":1},{"bin_start":0.3752660829072399,"bin_end":0.39368308286572873,"count":5}]}},{"name":"EN-WS-353-REL","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.41091195326241553,"max":0.6860349243555525,"histogram":[{"bin_start":0.41091195326241553,"bin_end":0.4384242503717292,"count":4},{"bin_start":0.4384242503717292,"bin_end":0.4659365474810429,"count":1},{"bin_start":0.4659365474810429,"bin_end":0.49344884459035665,"count":4},{"bin_start":0.49344884459035665,"bin_end":0.5209611416996703,"count":0},{"bin_start":0.5209611416996703,"bin_end":0.548473438808984,"count":2},{"bin_start":0.548473438808984,"bin_end":0.5759857359182977,"count":3},{"bin_start":0.5759857359182977,"bin_end":0.6034980330276114,"count":11},{"bin_start":0.6034980330276114,"bin_end":0.6310103301369251,"count":11},{"bin_start":0.6310103301369251,"bin_end":0.6585226272462388,"count":8},{"bin_start":0.6585226272462388,"bin_end":0.6860349243555525,"count":4}]}},{"name":"EN-YP-130","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.22300426304563162,"max":0.6587569388276342,"histogram":[{"bin_start":0.22300426304563162,"bin_end":0.2665795306238319,"count":4},{"bin_start":0.2665795306238319,"bin_end":0.3101547982020321,"count":3},{"bin_start":0.3101547982020321,"bin_end":0.35373006578023236,"count":3},{"bin_start":0.35373006578023236,"bin_end":0.39730533335843266,"count":5},{"bin_start":0.39730533335843266,"bin_end":0.44088060093663295,"count":8},{"bin_start":0.44088060093663295,"bin_end":0.48445586851483313,"count":6},{"bin_start":0.48445586851483313,"bin_end":0.5280311360930334,"count":2},{"bin_start":0.5280311360930334,"bin_end":0.5716064036712337,"count":8},{"bin_start":0.5716064036712337,"bin_end":0.6151816712494339,"count":5},{"bin_start":0.6151816712494339,"bin_end":0.6587569388276342,"count":4}]}},{"name":"EN-WS-353-ALL","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.47583206526030186,"max":0.7239156167743513,"histogram":[{"bin_start":0.47583206526030186,"bin_end":0.5006404204117068,"count":4},{"bin_start":0.5006404204117068,"bin_end":0.5254487755631118,"count":1},{"bin_start":0.5254487755631118,"bin_end":0.5502571307145168,"count":2},{"bin_start":0.5502571307145168,"bin_end":0.5750654858659217,"count":2},{"bin_start":0.5750654858659217,"bin_end":0.5998738410173265,"count":0},{"bin_start":0.5998738410173265,"bin_end":0.6246821961687316,"count":8},{"bin_start":0.6246821961687316,"bin_end":0.6494905513201366,"count":11},{"bin_start":0.6494905513201366,"bin_end":0.6742989064715414,"count":8},{"bin_start":0.6742989064715414,"bin_end":0.6991072616229463,"count":6},{"bin_start":0.6991072616229463,"bin_end":0.7239156167743513,"count":6}]}},{"name":"EN-WS-353-SIM","dtype":"float64","stats":{"unique_count":48,"nan_count":0,"min":0.5211439542983681,"max":0.809128439999733,"histogram":[{"bin_start":0.5211439542983681,"bin_end":0.5499424028685046,"count":3},{"bin_start":0.5499424028685046,"bin_end":0.5787408514386411,"count":1},{"bin_start":0.5787408514386411,"bin_end":0.6075393000087776,"count":3},{"bin_start":0.6075393000087776,"bin_end":0.6363377485789141,"count":0},{"bin_start":0.6363377485789141,"bin_end":0.6651361971490506,"count":3},{"bin_start":0.6651361971490506,"bin_end":0.6939346457191871,"count":5},{"bin_start":0.6939346457191871,"bin_end":0.7227330942893235,"count":7},{"bin_start":0.7227330942893235,"bin_end":0.75153154285946,"count":13},{"bin_start":0.75153154285946,"bin_end":0.7803299914295965,"count":9},{"bin_start":0.7803299914295965,"bin_end":0.809128439999733,"count":4}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"EN-VERB-143":0.3483845541043698,"EN-SimVerb-3500":0.13644234940438846,"EN-RG-65":0.6895579250232022,"EN-RW-STANFORD":0.37199157052673026,"EN-MTurk-771":0.6002733713431263,"EN-MEN-TR-3k":0.7054288706232369,"EN-MC-30":0.7480747602362963,"EN-MTurk-287":0.6971743192782789,"EN-SIMLEX-999":0.25033837296406003,"EN-WS-353-REL":0.5763911447169188,"EN-YP-130":0.40401484815739674,"EN-WS-353-ALL":0.6171251370162997,"EN-WS-353-SIM":0.6808315086211604,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_IN-IN"},{"EN-VERB-143":0.23501681605795452,"EN-SimVerb-3500":0.15515006332725573,"EN-RG-65":0.6924469132913864,"EN-RW-STANFORD":0.3213789496220688,"EN-MTurk-771":0.5767951434082011,"EN-MEN-TR-3k":0.7059331175508449,"EN-MC-30":0.67627262220062,"EN-MTurk-287":0.6810062998241381,"EN-SIMLEX-999":0.24418399403227822,"EN-WS-353-REL":0.6016077425270705,"EN-YP-130":0.41790983916618285,"EN-WS-353-ALL":0.6376856312877957,"EN-WS-353-SIM":0.6966938770754557,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_IN-OUT"},{"EN-VERB-143":0.24119895949933182,"EN-SimVerb-3500":0.1340265574626941,"EN-RG-65":0.6991905619505165,"EN-RW-STANFORD":0.3420248298119056,"EN-MTurk-771":0.5707436013624054,"EN-MEN-TR-3k":0.7073081241428386,"EN-MC-30":0.7748469832125546,"EN-MTurk-287":0.6864612419045938,"EN-SIMLEX-999":0.21215572043824443,"EN-WS-353-REL":0.6065138890467805,"EN-YP-130":0.3580221628207538,"EN-WS-353-ALL":0.6391677577063133,"EN-WS-353-SIM":0.7019672750449458,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_OUT-IN"},{"EN-VERB-143":0.20018142545661288,"EN-SimVerb-3500":0.12034438551781948,"EN-RG-65":0.6623446975810436,"EN-RW-STANFORD":0.353782450272268,"EN-MTurk-771":0.5216713664757826,"EN-MEN-TR-3k":0.6559665726193267,"EN-MC-30":0.7053942324367198,"EN-MTurk-287":0.6630860013239852,"EN-SIMLEX-999":0.2586126794907765,"EN-WS-353-REL":0.4785822595372036,"EN-YP-130":0.26402763454687317,"EN-WS-353-ALL":0.5628230003268594,"EN-WS-353-SIM":0.6437247905601852,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT"},{"EN-VERB-143":0.5179281413606942,"EN-SimVerb-3500":0.2270861185033452,"EN-RG-65":0.7884070138162002,"EN-RW-STANFORD":0.4349116805638258,"EN-MTurk-771":0.6480540133940521,"EN-MEN-TR-3k":0.7440612136186001,"EN-MC-30":0.8346287370943649,"EN-MTurk-287":0.7037332281804249,"EN-SIMLEX-999":0.345374152650793,"EN-WS-353-REL":0.613785975424749,"EN-YP-130":0.49673603176308306,"EN-WS-353-ALL":0.6650413058222956,"EN-WS-353-SIM":0.7608090191408263,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=1_IN-IN"},{"EN-VERB-143":0.2990965606187669,"EN-SimVerb-3500":0.19923317409153993,"EN-RG-65":0.8076741741449536,"EN-RW-STANFORD":0.34934802133947646,"EN-MTurk-771":0.6467084850524814,"EN-MEN-TR-3k":0.7544564597018597,"EN-MC-30":0.7807563260705347,"EN-MTurk-287":0.6912100083273301,"EN-SIMLEX-999":0.3169013054553781,"EN-WS-353-REL":0.6333878765353914,"EN-YP-130":0.5956049531420714,"EN-WS-353-ALL":0.6810775807749575,"EN-WS-353-SIM":0.7563842703357584,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=1_IN-OUT"},{"EN-VERB-143":0.2922604105042459,"EN-SimVerb-3500":0.19587231087635695,"EN-RG-65":0.7947746368375042,"EN-RW-STANFORD":0.3768852716733387,"EN-MTurk-771":0.6352403895448774,"EN-MEN-TR-3k":0.75614858115997,"EN-MC-30":0.8252038460604263,"EN-MTurk-287":0.690761346844739,"EN-SIMLEX-999":0.3075509083943274,"EN-WS-353-REL":0.6381888894331745,"EN-YP-130":0.5679461949306086,"EN-WS-353-ALL":0.6843789119441256,"EN-WS-353-SIM":0.7624460948246901,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=1_OUT-IN"},{"EN-VERB-143":0.39353099474315223,"EN-SimVerb-3500":0.2277427922922384,"EN-RG-65":0.7913278408231158,"EN-RW-STANFORD":0.44518229307827706,"EN-MTurk-771":0.6097843789286608,"EN-MEN-TR-3k":0.7078304292473152,"EN-MC-30":0.8283339384356361,"EN-MTurk-287":0.6856836383614284,"EN-SIMLEX-999":0.35264789003485925,"EN-WS-353-REL":0.5850097677877201,"EN-YP-130":0.4075974537497744,"EN-WS-353-ALL":0.6427066652382403,"EN-WS-353-SIM":0.731489184595455,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=1_OUT-OUT"},{"EN-VERB-143":0.3944301605509328,"EN-SimVerb-3500":0.2422948208359546,"EN-RG-65":0.8101941797702787,"EN-RW-STANFORD":0.4161761369705298,"EN-MTurk-771":0.6730469848620825,"EN-MEN-TR-3k":0.7483567568232959,"EN-MC-30":0.8274923948116515,"EN-MTurk-287":0.7295984912252257,"EN-SIMLEX-999":0.38412988555625244,"EN-WS-353-REL":0.6175953469954323,"EN-YP-130":0.5491069202970454,"EN-WS-353-ALL":0.6824057716779323,"EN-WS-353-SIM":0.7703618445704641,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=0_IN-IN"},{"EN-VERB-143":0.36449105048257663,"EN-SimVerb-3500":0.21774627742773014,"EN-RG-65":0.8063249444293163,"EN-RW-STANFORD":0.17492875838139385,"EN-MTurk-771":0.6754579749736443,"EN-MEN-TR-3k":0.7674823117875978,"EN-MC-30":0.8502397340371602,"EN-MTurk-287":0.6882543094556126,"EN-SIMLEX-999":0.32827540874607536,"EN-WS-353-REL":0.6791616959926157,"EN-YP-130":0.6286061944316427,"EN-WS-353-ALL":0.7220368221916579,"EN-WS-353-SIM":0.797994673419687,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=0_IN-OUT"},{"EN-VERB-143":0.4191482472300205,"EN-SimVerb-3500":0.21985685863453672,"EN-RG-65":0.785515307341526,"EN-RW-STANFORD":0.3052984047838469,"EN-MTurk-771":0.6669540006583575,"EN-MEN-TR-3k":0.7669007421641473,"EN-MC-30":0.8468253220425791,"EN-MTurk-287":0.6957862660539775,"EN-SIMLEX-999":0.329116494203784,"EN-WS-353-REL":0.6524482127329934,"EN-YP-130":0.6044001179052783,"EN-WS-353-ALL":0.7022974550261915,"EN-WS-353-SIM":0.7907535401692377,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=0_OUT-IN"},{"EN-VERB-143":0.102490631643689,"EN-SimVerb-3500":0.18218617197387993,"EN-RG-65":0.6094767539319432,"EN-RW-STANFORD":0.3719394173974368,"EN-MTurk-771":0.4208104815293742,"EN-MEN-TR-3k":0.5324721276596861,"EN-MC-30":0.6872553812039823,"EN-MTurk-287":0.45189548271952573,"EN-SIMLEX-999":0.31014536515262675,"EN-WS-353-REL":0.41091195326241553,"EN-YP-130":0.22300426304563162,"EN-WS-353-ALL":0.47583206526030186,"EN-WS-353-SIM":0.5299642443591125,"_deepnote_index_column":"word2vec_mc=10_size=200_window=50_sg=0_OUT-OUT"},{"EN-VERB-143":0.41654407252833453,"EN-SimVerb-3500":0.24713599976734815,"EN-RG-65":0.7996087333047989,"EN-RW-STANFORD":0.40424820607069606,"EN-MTurk-771":0.6829644237253656,"EN-MEN-TR-3k":0.7507124955294459,"EN-MC-30":0.8369523517399844,"EN-MTurk-287":0.7352288693821486,"EN-SIMLEX-999":0.39368308286572873,"EN-WS-353-REL":0.6315855955438064,"EN-YP-130":0.5368763839640883,"EN-WS-353-ALL":0.6881465750671522,"EN-WS-353-SIM":0.7744929588053133,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=0_IN-IN"},{"EN-VERB-143":0.40980976070187247,"EN-SimVerb-3500":0.22547400772508364,"EN-RG-65":0.8005638641634102,"EN-RW-STANFORD":0.20323613453859873,"EN-MTurk-771":0.681842028552244,"EN-MEN-TR-3k":0.7710247523374255,"EN-MC-30":0.8559558211554552,"EN-MTurk-287":0.6757409462977242,"EN-SIMLEX-999":0.3340826046632236,"EN-WS-353-REL":0.6763601260027348,"EN-YP-130":0.6587569388276342,"EN-WS-353-ALL":0.7239156167743513,"EN-WS-353-SIM":0.809128439999733,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=0_IN-OUT"},{"EN-VERB-143":0.4066003304532156,"EN-SimVerb-3500":0.22310264507023198,"EN-RG-65":0.7954718391036523,"EN-RW-STANFORD":0.32176135017011365,"EN-MTurk-771":0.6831318877723477,"EN-MEN-TR-3k":0.7706523291470092,"EN-MC-30":0.837707847150875,"EN-MTurk-287":0.6904334120105857,"EN-SIMLEX-999":0.3369925057167011,"EN-WS-353-REL":0.6602403881318202,"EN-YP-130":0.6297364296592068,"EN-WS-353-ALL":0.7028977203465553,"EN-WS-353-SIM":0.7884465907474286,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=0_OUT-IN"},{"EN-VERB-143":0.0954869101232928,"EN-SimVerb-3500":0.18582142954670502,"EN-RG-65":0.6147046740030908,"EN-RW-STANFORD":0.35576473691872734,"EN-MTurk-771":0.4209627470790356,"EN-MEN-TR-3k":0.5145919562281084,"EN-MC-30":0.6816782605529988,"EN-MTurk-287":0.4296714101393483,"EN-SIMLEX-999":0.3158759974463528,"EN-WS-353-REL":0.4411688561731159,"EN-YP-130":0.26503459626712567,"EN-WS-353-ALL":0.4823488431635488,"EN-WS-353-SIM":0.5275523547184584,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=0_OUT-OUT"},{"EN-VERB-143":0.482816637188152,"EN-SimVerb-3500":0.2178461071171003,"EN-RG-65":0.7896570111144667,"EN-RW-STANFORD":0.43236947371017637,"EN-MTurk-771":0.6461493497905229,"EN-MEN-TR-3k":0.7386514220927302,"EN-MC-30":0.8273767457045097,"EN-MTurk-287":0.715968864375474,"EN-SIMLEX-999":0.33895594947754076,"EN-WS-353-REL":0.6093303165497975,"EN-YP-130":0.47014786563540156,"EN-WS-353-ALL":0.6647075889654637,"EN-WS-353-SIM":0.7616162686068462,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=1_IN-IN"},{"EN-VERB-143":0.2968350332242956,"EN-SimVerb-3500":0.19433637118322775,"EN-RG-65":0.7976977128627377,"EN-RW-STANFORD":0.34651214877896624,"EN-MTurk-771":0.6419135023914766,"EN-MEN-TR-3k":0.7416334258136106,"EN-MC-30":0.7703527977568851,"EN-MTurk-287":0.7018471763131711,"EN-SIMLEX-999":0.3136313686401098,"EN-WS-353-REL":0.6187929970256194,"EN-YP-130":0.5677384178586953,"EN-WS-353-ALL":0.6709186225681054,"EN-WS-353-SIM":0.7489727738520109,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=1_IN-OUT"},{"EN-VERB-143":0.293794487680594,"EN-SimVerb-3500":0.18530849752709455,"EN-RG-65":0.7902633368569092,"EN-RW-STANFORD":0.3725014771383483,"EN-MTurk-771":0.6323733469984892,"EN-MEN-TR-3k":0.7457781460832635,"EN-MC-30":0.8241386038481322,"EN-MTurk-287":0.7042991041049723,"EN-SIMLEX-999":0.2996988825311565,"EN-WS-353-REL":0.6281603576441328,"EN-YP-130":0.5334168437146736,"EN-WS-353-ALL":0.6793312110683178,"EN-WS-353-SIM":0.7601876217392147,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=1_OUT-IN"},{"EN-VERB-143":0.3618526336239312,"EN-SimVerb-3500":0.21067670902532204,"EN-RG-65":0.7812383588649701,"EN-RW-STANFORD":0.44079782828577935,"EN-MTurk-771":0.6018782376808429,"EN-MEN-TR-3k":0.7026096415362185,"EN-MC-30":0.8195749091783112,"EN-MTurk-287":0.6916516781800323,"EN-SIMLEX-999":0.342725195023711,"EN-WS-353-REL":0.5665471222187909,"EN-YP-130":0.37877770090173246,"EN-WS-353-ALL":0.6376140247372692,"EN-WS-353-SIM":0.7286156273636188,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=1_OUT-OUT"},{"EN-VERB-143":0.43209759666054154,"EN-SimVerb-3500":0.23544562272966205,"EN-RG-65":0.757610955356218,"EN-RW-STANFORD":0.40348676465050753,"EN-MTurk-771":0.6402097351735435,"EN-MEN-TR-3k":0.7095754482665626,"EN-MC-30":0.7679144067333603,"EN-MTurk-287":0.7107037608377934,"EN-SIMLEX-999":0.37094595773844524,"EN-WS-353-REL":0.5271806323793314,"EN-YP-130":0.4106054792781105,"EN-WS-353-ALL":0.6129030366953735,"EN-WS-353-SIM":0.7253282043234793,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=0_IN-IN"},{"EN-VERB-143":0.19613952215587332,"EN-SimVerb-3500":0.15227224930825273,"EN-RG-65":0.7899089789812812,"EN-RW-STANFORD":0.18964653801149017,"EN-MTurk-771":0.62792195586137,"EN-MEN-TR-3k":0.7483468905868389,"EN-MC-30":0.7661801158896115,"EN-MTurk-287":0.6411503770599779,"EN-SIMLEX-999":0.27961463816501597,"EN-WS-353-REL":0.5934671864929731,"EN-YP-130":0.5408165449838007,"EN-WS-353-ALL":0.6475607778649947,"EN-WS-353-SIM":0.7337138153881002,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=0_IN-OUT"},{"EN-VERB-143":0.1721977159693056,"EN-SimVerb-3500":0.15922561077810338,"EN-RG-65":0.7588174854795765,"EN-RW-STANFORD":0.26552655858557234,"EN-MTurk-771":0.6268771682534903,"EN-MEN-TR-3k":0.7514768566734827,"EN-MC-30":0.7693030477991942,"EN-MTurk-287":0.6747863652026351,"EN-SIMLEX-999":0.2576773858316027,"EN-WS-353-REL":0.5901239406543923,"EN-YP-130":0.5443242753700182,"EN-WS-353-ALL":0.6478611902949848,"EN-WS-353-SIM":0.748210127138964,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=0_OUT-IN"},{"EN-VERB-143":0.2664375570443653,"EN-SimVerb-3500":0.2280664561423968,"EN-RG-65":0.6554548837309623,"EN-RW-STANFORD":0.3905627220593135,"EN-MTurk-771":0.4690551629314346,"EN-MEN-TR-3k":0.5535507604441612,"EN-MC-30":0.7085723149879455,"EN-MTurk-287":0.491417393024701,"EN-SIMLEX-999":0.3503549070990918,"EN-WS-353-REL":0.4355833678743235,"EN-YP-130":0.31815352775682165,"EN-WS-353-ALL":0.5213974275899446,"EN-WS-353-SIM":0.5953153661760299,"_deepnote_index_column":"word2vec_mc=10_size=200_window=5_sg=0_OUT-OUT"},{"EN-VERB-143":0.4483029524987279,"EN-SimVerb-3500":0.19064605263773715,"EN-RG-65":0.7238007724809129,"EN-RW-STANFORD":0.42006934392463136,"EN-MTurk-771":0.6535392629685157,"EN-MEN-TR-3k":0.741670569450629,"EN-MC-30":0.8030705319225215,"EN-MTurk-287":0.7295293702263934,"EN-SIMLEX-999":0.3528835995512777,"EN-WS-353-REL":0.6218552333131754,"EN-YP-130":0.46147430516232923,"EN-WS-353-ALL":0.6604718871108356,"EN-WS-353-SIM":0.7244513059443951,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=1_IN-IN"},{"EN-VERB-143":0.3117958136473057,"EN-SimVerb-3500":0.17569485245988173,"EN-RG-65":0.7424752452799454,"EN-RW-STANFORD":0.3366027318442508,"EN-MTurk-771":0.6507808865477639,"EN-MEN-TR-3k":0.739563366515706,"EN-MC-30":0.7607749551362489,"EN-MTurk-287":0.7065071685442779,"EN-SIMLEX-999":0.32090304749910314,"EN-WS-353-REL":0.6375467096692866,"EN-YP-130":0.49886126139821474,"EN-WS-353-ALL":0.6581408834127934,"EN-WS-353-SIM":0.7075452930211038,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=1_IN-OUT"},{"EN-VERB-143":0.34873260387651317,"EN-SimVerb-3500":0.16965883358295622,"EN-RG-65":0.7525169309950915,"EN-RW-STANFORD":0.36791113729010666,"EN-MTurk-771":0.6462022277771391,"EN-MEN-TR-3k":0.7437929929411902,"EN-MC-30":0.8260608702042432,"EN-MTurk-287":0.7074334837593957,"EN-SIMLEX-999":0.2974087649668153,"EN-WS-353-REL":0.6301670461787422,"EN-YP-130":0.45433319181996024,"EN-WS-353-ALL":0.6701934000902744,"EN-WS-353-SIM":0.7343395798197694,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=1_OUT-IN"},{"EN-VERB-143":0.33857169806339626,"EN-SimVerb-3500":0.1851172855870234,"EN-RG-65":0.6883043129740053,"EN-RW-STANFORD":0.43427905030954006,"EN-MTurk-771":0.605227856885136,"EN-MEN-TR-3k":0.6963426043360693,"EN-MC-30":0.7799258744240701,"EN-MTurk-287":0.6920455837482556,"EN-SIMLEX-999":0.3504918566692387,"EN-WS-353-REL":0.5676579703889473,"EN-YP-130":0.36015276224561366,"EN-WS-353-ALL":0.6230790767749784,"EN-WS-353-SIM":0.6858752631450622,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=1_OUT-OUT"},{"EN-VERB-143":0.39746927488993555,"EN-SimVerb-3500":0.21733845931621254,"EN-RG-65":0.7339761489480742,"EN-RW-STANFORD":0.39634368317154417,"EN-MTurk-771":0.6553491491814395,"EN-MEN-TR-3k":0.7205426693458772,"EN-MC-30":0.7881115853499098,"EN-MTurk-287":0.7144052798698126,"EN-SIMLEX-999":0.3774817412189316,"EN-WS-353-REL":0.5544344817337636,"EN-YP-130":0.396154225645398,"EN-WS-353-ALL":0.6243607783815185,"EN-WS-353-SIM":0.7144208431625516,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_IN-IN"},{"EN-VERB-143":0.2045174598297288,"EN-SimVerb-3500":0.14130141318025138,"EN-RG-65":0.8019565031250883,"EN-RW-STANFORD":0.15197262267329859,"EN-MTurk-771":0.6531892297010656,"EN-MEN-TR-3k":0.7649573922625617,"EN-MC-30":0.8323022512021407,"EN-MTurk-287":0.6577932250425418,"EN-SIMLEX-999":0.28006676307827794,"EN-WS-353-REL":0.6367034822341671,"EN-YP-130":0.44303416827663616,"EN-WS-353-ALL":0.6667938624889508,"EN-WS-353-SIM":0.7245899624682062,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_IN-OUT"},{"EN-VERB-143":0.27155124547580356,"EN-SimVerb-3500":0.14497633751536212,"EN-RG-65":0.7986096159098365,"EN-RW-STANFORD":0.23111496297083287,"EN-MTurk-771":0.6463533134081745,"EN-MEN-TR-3k":0.7667695758642483,"EN-MC-30":0.8230561715516306,"EN-MTurk-287":0.679872611505997,"EN-SIMLEX-999":0.26235457814126206,"EN-WS-353-REL":0.6316461276242601,"EN-YP-130":0.4632022954239011,"EN-WS-353-ALL":0.6593507983208527,"EN-WS-353-SIM":0.7203525038393525,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_OUT-IN"},{"EN-VERB-143":0.2602141346223455,"EN-SimVerb-3500":0.1965678218321583,"EN-RG-65":0.6055483366333668,"EN-RW-STANFORD":0.4112718985787262,"EN-MTurk-771":0.4845241658924917,"EN-MEN-TR-3k":0.5902626534276089,"EN-MC-30":0.6881511709607714,"EN-MTurk-287":0.529686774390123,"EN-SIMLEX-999":0.3249865487373889,"EN-WS-353-REL":0.4758090741994607,"EN-YP-130":0.30044356848489134,"EN-WS-353-ALL":0.5453188344653882,"EN-WS-353-SIM":0.5949893592520222,"_deepnote_index_column":"word2vec_mc=10_size=100_window=5_sg=0_OUT-OUT"},{"EN-VERB-143":0.3564140220148129,"EN-SimVerb-3500":0.13336811051972736,"EN-RG-65":0.6932123959715126,"EN-RW-STANFORD":0.3655974638631209,"EN-MTurk-771":0.6074222506753659,"EN-MEN-TR-3k":0.704574110950045,"EN-MC-30":0.7516685110616038,"EN-MTurk-287":0.7042760197015054,"EN-SIMLEX-999":0.2538253091686459,"EN-WS-353-REL":0.5822182926810473,"EN-YP-130":0.43273043272821893,"EN-WS-353-ALL":0.6203286027234823,"EN-WS-353-SIM":0.6830094271486155,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=1_IN-IN"},{"EN-VERB-143":0.26340233831115056,"EN-SimVerb-3500":0.1617797088316474,"EN-RG-65":0.7107013667754948,"EN-RW-STANFORD":0.32741525414230455,"EN-MTurk-771":0.5891208647076046,"EN-MEN-TR-3k":0.7144095995972479,"EN-MC-30":0.7030379497365705,"EN-MTurk-287":0.6888464884700877,"EN-SIMLEX-999":0.25897123266027844,"EN-WS-353-REL":0.6031326632534574,"EN-YP-130":0.44015981042590413,"EN-WS-353-ALL":0.6445721488088555,"EN-WS-353-SIM":0.7035184800540938,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=1_IN-OUT"},{"EN-VERB-143":0.25988051011548446,"EN-SimVerb-3500":0.14436094276449365,"EN-RG-65":0.7146804927812505,"EN-RW-STANFORD":0.3408551470097199,"EN-MTurk-771":0.5846837003018424,"EN-MEN-TR-3k":0.7158173025353163,"EN-MC-30":0.7807018405783209,"EN-MTurk-287":0.6878825340341621,"EN-SIMLEX-999":0.22686730090155616,"EN-WS-353-REL":0.6125126770761868,"EN-YP-130":0.4049964913608744,"EN-WS-353-ALL":0.6464953611654878,"EN-WS-353-SIM":0.7041382606452867,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=1_OUT-IN"},{"EN-VERB-143":0.225828130418623,"EN-SimVerb-3500":0.11997115300423644,"EN-RG-65":0.6767635378449447,"EN-RW-STANFORD":0.3482463875314233,"EN-MTurk-771":0.5308978421535752,"EN-MEN-TR-3k":0.663713320962511,"EN-MC-30":0.7094888886341405,"EN-MTurk-287":0.666416739238733,"EN-SIMLEX-999":0.2666963883220157,"EN-WS-353-REL":0.48624416006140836,"EN-YP-130":0.27759850615137094,"EN-WS-353-ALL":0.5684913733759176,"EN-WS-353-SIM":0.6468582348377191,"_deepnote_index_column":"word2vec_mc=10_size=300_window=50_sg=1_OUT-OUT"},{"EN-VERB-143":0.32493012687840167,"EN-SimVerb-3500":0.2253549090868224,"EN-RG-65":0.8032237066864348,"EN-RW-STANFORD":0.4057753148360825,"EN-MTurk-771":0.6857498490288588,"EN-MEN-TR-3k":0.7553028465645841,"EN-MC-30":0.8804961034326553,"EN-MTurk-287":0.7367000674901923,"EN-SIMLEX-999":0.3799808701595419,"EN-WS-353-REL":0.6263070551484702,"EN-YP-130":0.5487915923871323,"EN-WS-353-ALL":0.6814887106011158,"EN-WS-353-SIM":0.7476879362317428,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=0_IN-IN"},{"EN-VERB-143":0.3704508810734785,"EN-SimVerb-3500":0.22131407905974806,"EN-RG-65":0.8016982154995586,"EN-RW-STANFORD":0.13594572608097097,"EN-MTurk-771":0.6844661497373187,"EN-MEN-TR-3k":0.7808016200215596,"EN-MC-30":0.8715153002599729,"EN-MTurk-287":0.7067819354759752,"EN-SIMLEX-999":0.3267419029337306,"EN-WS-353-REL":0.6860349243555525,"EN-YP-130":0.6245190280997256,"EN-WS-353-ALL":0.7148767498889143,"EN-WS-353-SIM":0.759300165108597,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=0_IN-OUT"},{"EN-VERB-143":0.3861565227515052,"EN-SimVerb-3500":0.227101506829363,"EN-RG-65":0.7910832204692134,"EN-RW-STANFORD":0.2714716011589376,"EN-MTurk-771":0.6746286043128058,"EN-MEN-TR-3k":0.7797222276413694,"EN-MC-30":0.896772486053877,"EN-MTurk-287":0.7210745267469999,"EN-SIMLEX-999":0.322724483856984,"EN-WS-353-REL":0.6535470761327732,"EN-YP-130":0.592756251573586,"EN-WS-353-ALL":0.6991186502144257,"EN-WS-353-SIM":0.76045889904114,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=0_OUT-IN"},{"EN-VERB-143":0.13280959774167678,"EN-SimVerb-3500":0.1693224236792094,"EN-RG-65":0.5497542000633383,"EN-RW-STANFORD":0.38846764641002957,"EN-MTurk-771":0.4495418523396525,"EN-MEN-TR-3k":0.5624733561130991,"EN-MC-30":0.6669604593219693,"EN-MTurk-287":0.4743195118010306,"EN-SIMLEX-999":0.29956887554829564,"EN-WS-353-REL":0.41725668351835277,"EN-YP-130":0.24585240544939732,"EN-WS-353-ALL":0.48083127501667494,"EN-WS-353-SIM":0.5211439542983681,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=0_OUT-OUT"},{"EN-VERB-143":0.4419818196155541,"EN-SimVerb-3500":0.25336211773918604,"EN-RG-65":0.7843345711390218,"EN-RW-STANFORD":0.40822867944407654,"EN-MTurk-771":0.6451997948371359,"EN-MEN-TR-3k":0.7119326245031785,"EN-MC-30":0.7991248712107093,"EN-MTurk-287":0.7094027661724546,"EN-SIMLEX-999":0.3907217297644958,"EN-WS-353-REL":0.535712833497675,"EN-YP-130":0.4427903562638864,"EN-WS-353-ALL":0.6176410245665116,"EN-WS-353-SIM":0.7317663569205097,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=0_IN-IN"},{"EN-VERB-143":0.17868008274844188,"EN-SimVerb-3500":0.1488850193748314,"EN-RG-65":0.8103394567935266,"EN-RW-STANFORD":0.19748141994970883,"EN-MTurk-771":0.6191982482495807,"EN-MEN-TR-3k":0.7472784260992319,"EN-MC-30":0.7550334000822752,"EN-MTurk-287":0.6224245724293687,"EN-SIMLEX-999":0.26883184539375377,"EN-WS-353-REL":0.5854426876561198,"EN-YP-130":0.5941915400426767,"EN-WS-353-ALL":0.6359080357393695,"EN-WS-353-SIM":0.7377825227959338,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=0_IN-OUT"},{"EN-VERB-143":0.15520052055423614,"EN-SimVerb-3500":0.14642322788421294,"EN-RG-65":0.7729204889708684,"EN-RW-STANFORD":0.2687269758910418,"EN-MTurk-771":0.6181723268535206,"EN-MEN-TR-3k":0.7490971822457327,"EN-MC-30":0.7797022604705187,"EN-MTurk-287":0.6571132983130754,"EN-SIMLEX-999":0.2539824374604909,"EN-WS-353-REL":0.5893229261821741,"EN-YP-130":0.5929505171704457,"EN-WS-353-ALL":0.6291290023989892,"EN-WS-353-SIM":0.7286351235291572,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=0_OUT-IN"},{"EN-VERB-143":0.2710290200607626,"EN-SimVerb-3500":0.23414951210494916,"EN-RG-65":0.6190636544896604,"EN-RW-STANFORD":0.3746409692081814,"EN-MTurk-771":0.4603334788974053,"EN-MEN-TR-3k":0.5339198562023569,"EN-MC-30":0.6912556804282499,"EN-MTurk-287":0.472873542065485,"EN-SIMLEX-999":0.35394055743588254,"EN-WS-353-REL":0.4153105521864149,"EN-YP-130":0.3172875951806109,"EN-WS-353-ALL":0.49638907515454306,"EN-WS-353-SIM":0.5650826042174983,"_deepnote_index_column":"word2vec_mc=10_size=300_window=5_sg=0_OUT-OUT"},{"EN-VERB-143":0.34364867152977013,"EN-SimVerb-3500":0.12943848212465275,"EN-RG-65":0.6310336598826135,"EN-RW-STANFORD":0.3649688482916669,"EN-MTurk-771":0.5991803750517057,"EN-MEN-TR-3k":0.7075337248991737,"EN-MC-30":0.7340927276765113,"EN-MTurk-287":0.678923738256862,"EN-SIMLEX-999":0.2706703639153277,"EN-WS-353-REL":0.5966809207080056,"EN-YP-130":0.39893649917422636,"EN-WS-353-ALL":0.6199358433026333,"EN-WS-353-SIM":0.6657482466460385,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=1_IN-IN"},{"EN-VERB-143":0.19443195493159934,"EN-SimVerb-3500":0.1317059188238995,"EN-RG-65":0.615200861369415,"EN-RW-STANFORD":0.29001360399185716,"EN-MTurk-771":0.5664905198177383,"EN-MEN-TR-3k":0.6979477184796585,"EN-MC-30":0.6862854927297835,"EN-MTurk-287":0.673872326627039,"EN-SIMLEX-999":0.24135853944488522,"EN-WS-353-REL":0.6071995384762843,"EN-YP-130":0.3704164092592268,"EN-WS-353-ALL":0.6205546350532968,"EN-WS-353-SIM":0.6615796910736056,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=1_IN-OUT"},{"EN-VERB-143":0.23543501102246628,"EN-SimVerb-3500":0.11538418579625377,"EN-RG-65":0.6390185307865072,"EN-RW-STANFORD":0.31361192552970457,"EN-MTurk-771":0.5606175145853833,"EN-MEN-TR-3k":0.6974327480587726,"EN-MC-30":0.7654410928084739,"EN-MTurk-287":0.6811855116053179,"EN-SIMLEX-999":0.20951308328084037,"EN-WS-353-REL":0.6031436542543513,"EN-YP-130":0.32584422942178237,"EN-WS-353-ALL":0.6272386095567212,"EN-WS-353-SIM":0.6799138167870667,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=1_OUT-IN"},{"EN-VERB-143":0.15918745518341587,"EN-SimVerb-3500":0.11339584519742406,"EN-RG-65":0.6314934124975747,"EN-RW-STANFORD":0.351778231529962,"EN-MTurk-771":0.5233499549386219,"EN-MEN-TR-3k":0.6505693912782459,"EN-MC-30":0.688476593857413,"EN-MTurk-287":0.6572671529498096,"EN-SIMLEX-999":0.2807466949180553,"EN-WS-353-REL":0.4798374240399144,"EN-YP-130":0.27310751461847693,"EN-WS-353-ALL":0.5420023968975516,"EN-WS-353-SIM":0.5922331143850751,"_deepnote_index_column":"word2vec_mc=10_size=100_window=50_sg=1_OUT-OUT"}],"rows_bottom":null},"text/plain":"                                                EN-VERB-143  EN-SimVerb-3500  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN       0.348385         0.136442   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT      0.235017         0.155150   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN      0.241199         0.134027   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT     0.200181         0.120344   \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN        0.517928         0.227086   \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT       0.299097         0.199233   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN       0.292260         0.195872   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT      0.393531         0.227743   \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN       0.394430         0.242295   \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT      0.364491         0.217746   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN      0.419148         0.219857   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT     0.102491         0.182186   \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN       0.416544         0.247136   \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT      0.409810         0.225474   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN      0.406600         0.223103   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT     0.095487         0.185821   \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN        0.482817         0.217846   \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT       0.296835         0.194336   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN       0.293794         0.185308   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT      0.361853         0.210677   \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN        0.432098         0.235446   \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT       0.196140         0.152272   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN       0.172198         0.159226   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT      0.266438         0.228066   \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN        0.448303         0.190646   \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT       0.311796         0.175695   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN       0.348733         0.169659   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT      0.338572         0.185117   \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN        0.397469         0.217338   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT       0.204517         0.141301   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN       0.271551         0.144976   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT      0.260214         0.196568   \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN       0.356414         0.133368   \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT      0.263402         0.161780   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN      0.259881         0.144361   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT     0.225828         0.119971   \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN       0.324930         0.225355   \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT      0.370451         0.221314   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN      0.386157         0.227102   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT     0.132810         0.169322   \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN        0.441982         0.253362   \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT       0.178680         0.148885   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN       0.155201         0.146423   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT      0.271029         0.234150   \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN       0.343649         0.129438   \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT      0.194432         0.131706   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN      0.235435         0.115384   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT     0.159187         0.113396   \n\n                                                EN-RG-65  EN-RW-STANFORD  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN    0.689558        0.371992   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT   0.692447        0.321379   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN   0.699191        0.342025   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT  0.662345        0.353782   \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN     0.788407        0.434912   \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT    0.807674        0.349348   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN    0.794775        0.376885   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT   0.791328        0.445182   \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN    0.810194        0.416176   \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT   0.806325        0.174929   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN   0.785515        0.305298   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT  0.609477        0.371939   \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN    0.799609        0.404248   \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT   0.800564        0.203236   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN   0.795472        0.321761   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT  0.614705        0.355765   \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN     0.789657        0.432369   \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT    0.797698        0.346512   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN    0.790263        0.372501   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT   0.781238        0.440798   \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN     0.757611        0.403487   \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT    0.789909        0.189647   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN    0.758817        0.265527   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT   0.655455        0.390563   \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN     0.723801        0.420069   \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT    0.742475        0.336603   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN    0.752517        0.367911   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT   0.688304        0.434279   \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN     0.733976        0.396344   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT    0.801957        0.151973   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN    0.798610        0.231115   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT   0.605548        0.411272   \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN    0.693212        0.365597   \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT   0.710701        0.327415   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN   0.714680        0.340855   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT  0.676764        0.348246   \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN    0.803224        0.405775   \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT   0.801698        0.135946   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN   0.791083        0.271472   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT  0.549754        0.388468   \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN     0.784335        0.408229   \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT    0.810339        0.197481   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN    0.772920        0.268727   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT   0.619064        0.374641   \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN    0.631034        0.364969   \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT   0.615201        0.290014   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN   0.639019        0.313612   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT  0.631493        0.351778   \n\n                                                EN-MTurk-771  EN-MEN-TR-3k  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN        0.600273      0.705429   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT       0.576795      0.705933   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN       0.570744      0.707308   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT      0.521671      0.655967   \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN         0.648054      0.744061   \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT        0.646708      0.754456   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN        0.635240      0.756149   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT       0.609784      0.707830   \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN        0.673047      0.748357   \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT       0.675458      0.767482   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN       0.666954      0.766901   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT      0.420810      0.532472   \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN        0.682964      0.750712   \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT       0.681842      0.771025   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN       0.683132      0.770652   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT      0.420963      0.514592   \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN         0.646149      0.738651   \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT        0.641914      0.741633   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN        0.632373      0.745778   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT       0.601878      0.702610   \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN         0.640210      0.709575   \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT        0.627922      0.748347   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN        0.626877      0.751477   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT       0.469055      0.553551   \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN         0.653539      0.741671   \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT        0.650781      0.739563   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN        0.646202      0.743793   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT       0.605228      0.696343   \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN         0.655349      0.720543   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT        0.653189      0.764957   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN        0.646353      0.766770   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT       0.484524      0.590263   \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN        0.607422      0.704574   \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT       0.589121      0.714410   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN       0.584684      0.715817   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT      0.530898      0.663713   \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN        0.685750      0.755303   \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT       0.684466      0.780802   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN       0.674629      0.779722   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT      0.449542      0.562473   \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN         0.645200      0.711933   \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT        0.619198      0.747278   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN        0.618172      0.749097   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT       0.460333      0.533920   \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN        0.599180      0.707534   \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT       0.566491      0.697948   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN       0.560618      0.697433   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT      0.523350      0.650569   \n\n                                                EN-MC-30  EN-MTurk-287  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN    0.748075      0.697174   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT   0.676273      0.681006   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN   0.774847      0.686461   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT  0.705394      0.663086   \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN     0.834629      0.703733   \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT    0.780756      0.691210   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN    0.825204      0.690761   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT   0.828334      0.685684   \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN    0.827492      0.729598   \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT   0.850240      0.688254   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN   0.846825      0.695786   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT  0.687255      0.451895   \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN    0.836952      0.735229   \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT   0.855956      0.675741   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN   0.837708      0.690433   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT  0.681678      0.429671   \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN     0.827377      0.715969   \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT    0.770353      0.701847   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN    0.824139      0.704299   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT   0.819575      0.691652   \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN     0.767914      0.710704   \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT    0.766180      0.641150   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN    0.769303      0.674786   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT   0.708572      0.491417   \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN     0.803071      0.729529   \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT    0.760775      0.706507   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN    0.826061      0.707433   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT   0.779926      0.692046   \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN     0.788112      0.714405   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT    0.832302      0.657793   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN    0.823056      0.679873   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT   0.688151      0.529687   \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN    0.751669      0.704276   \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT   0.703038      0.688846   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN   0.780702      0.687883   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT  0.709489      0.666417   \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN    0.880496      0.736700   \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT   0.871515      0.706782   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN   0.896772      0.721075   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT  0.666960      0.474320   \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN     0.799125      0.709403   \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT    0.755033      0.622425   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN    0.779702      0.657113   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT   0.691256      0.472874   \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN    0.734093      0.678924   \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT   0.686285      0.673872   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN   0.765441      0.681186   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT  0.688477      0.657267   \n\n                                                EN-SIMLEX-999  EN-WS-353-REL  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN         0.250338       0.576391   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT        0.244184       0.601608   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN        0.212156       0.606514   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT       0.258613       0.478582   \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN          0.345374       0.613786   \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT         0.316901       0.633388   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN         0.307551       0.638189   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT        0.352648       0.585010   \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN         0.384130       0.617595   \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT        0.328275       0.679162   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN        0.329116       0.652448   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT       0.310145       0.410912   \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN         0.393683       0.631586   \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT        0.334083       0.676360   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN        0.336993       0.660240   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT       0.315876       0.441169   \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN          0.338956       0.609330   \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT         0.313631       0.618793   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN         0.299699       0.628160   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT        0.342725       0.566547   \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN          0.370946       0.527181   \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT         0.279615       0.593467   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN         0.257677       0.590124   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT        0.350355       0.435583   \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN          0.352884       0.621855   \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT         0.320903       0.637547   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN         0.297409       0.630167   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT        0.350492       0.567658   \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN          0.377482       0.554434   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT         0.280067       0.636703   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN         0.262355       0.631646   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT        0.324987       0.475809   \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN         0.253825       0.582218   \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT        0.258971       0.603133   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN        0.226867       0.612513   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT       0.266696       0.486244   \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN         0.379981       0.626307   \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT        0.326742       0.686035   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN        0.322724       0.653547   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT       0.299569       0.417257   \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN          0.390722       0.535713   \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT         0.268832       0.585443   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN         0.253982       0.589323   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT        0.353941       0.415311   \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN         0.270670       0.596681   \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT        0.241359       0.607200   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN        0.209513       0.603144   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT       0.280747       0.479837   \n\n                                                EN-YP-130  EN-WS-353-ALL  \\\nword2vec_mc=10_size=200_window=50_sg=1_IN-IN     0.404015       0.617125   \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT    0.417910       0.637686   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN    0.358022       0.639168   \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT   0.264028       0.562823   \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN      0.496736       0.665041   \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT     0.595605       0.681078   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN     0.567946       0.684379   \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT    0.407597       0.642707   \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN     0.549107       0.682406   \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT    0.628606       0.722037   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN    0.604400       0.702297   \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT   0.223004       0.475832   \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN     0.536876       0.688147   \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT    0.658757       0.723916   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN    0.629736       0.702898   \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT   0.265035       0.482349   \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN      0.470148       0.664708   \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT     0.567738       0.670919   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN     0.533417       0.679331   \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT    0.378778       0.637614   \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN      0.410605       0.612903   \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT     0.540817       0.647561   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN     0.544324       0.647861   \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT    0.318154       0.521397   \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN      0.461474       0.660472   \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT     0.498861       0.658141   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN     0.454333       0.670193   \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT    0.360153       0.623079   \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN      0.396154       0.624361   \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT     0.443034       0.666794   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN     0.463202       0.659351   \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT    0.300444       0.545319   \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN     0.432730       0.620329   \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT    0.440160       0.644572   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN    0.404996       0.646495   \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT   0.277599       0.568491   \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN     0.548792       0.681489   \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT    0.624519       0.714877   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN    0.592756       0.699119   \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT   0.245852       0.480831   \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN      0.442790       0.617641   \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT     0.594192       0.635908   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN     0.592951       0.629129   \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT    0.317288       0.496389   \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN     0.398936       0.619936   \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT    0.370416       0.620555   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN    0.325844       0.627239   \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT   0.273108       0.542002   \n\n                                                EN-WS-353-SIM  \nword2vec_mc=10_size=200_window=50_sg=1_IN-IN         0.680832  \nword2vec_mc=10_size=200_window=50_sg=1_IN-OUT        0.696694  \nword2vec_mc=10_size=200_window=50_sg=1_OUT-IN        0.701967  \nword2vec_mc=10_size=200_window=50_sg=1_OUT-OUT       0.643725  \nword2vec_mc=10_size=300_window=5_sg=1_IN-IN          0.760809  \nword2vec_mc=10_size=300_window=5_sg=1_IN-OUT         0.756384  \nword2vec_mc=10_size=300_window=5_sg=1_OUT-IN         0.762446  \nword2vec_mc=10_size=300_window=5_sg=1_OUT-OUT        0.731489  \nword2vec_mc=10_size=200_window=50_sg=0_IN-IN         0.770362  \nword2vec_mc=10_size=200_window=50_sg=0_IN-OUT        0.797995  \nword2vec_mc=10_size=200_window=50_sg=0_OUT-IN        0.790754  \nword2vec_mc=10_size=200_window=50_sg=0_OUT-OUT       0.529964  \nword2vec_mc=10_size=300_window=50_sg=0_IN-IN         0.774493  \nword2vec_mc=10_size=300_window=50_sg=0_IN-OUT        0.809128  \nword2vec_mc=10_size=300_window=50_sg=0_OUT-IN        0.788447  \nword2vec_mc=10_size=300_window=50_sg=0_OUT-OUT       0.527552  \nword2vec_mc=10_size=200_window=5_sg=1_IN-IN          0.761616  \nword2vec_mc=10_size=200_window=5_sg=1_IN-OUT         0.748973  \nword2vec_mc=10_size=200_window=5_sg=1_OUT-IN         0.760188  \nword2vec_mc=10_size=200_window=5_sg=1_OUT-OUT        0.728616  \nword2vec_mc=10_size=200_window=5_sg=0_IN-IN          0.725328  \nword2vec_mc=10_size=200_window=5_sg=0_IN-OUT         0.733714  \nword2vec_mc=10_size=200_window=5_sg=0_OUT-IN         0.748210  \nword2vec_mc=10_size=200_window=5_sg=0_OUT-OUT        0.595315  \nword2vec_mc=10_size=100_window=5_sg=1_IN-IN          0.724451  \nword2vec_mc=10_size=100_window=5_sg=1_IN-OUT         0.707545  \nword2vec_mc=10_size=100_window=5_sg=1_OUT-IN         0.734340  \nword2vec_mc=10_size=100_window=5_sg=1_OUT-OUT        0.685875  \nword2vec_mc=10_size=100_window=5_sg=0_IN-IN          0.714421  \nword2vec_mc=10_size=100_window=5_sg=0_IN-OUT         0.724590  \nword2vec_mc=10_size=100_window=5_sg=0_OUT-IN         0.720353  \nword2vec_mc=10_size=100_window=5_sg=0_OUT-OUT        0.594989  \nword2vec_mc=10_size=300_window=50_sg=1_IN-IN         0.683009  \nword2vec_mc=10_size=300_window=50_sg=1_IN-OUT        0.703518  \nword2vec_mc=10_size=300_window=50_sg=1_OUT-IN        0.704138  \nword2vec_mc=10_size=300_window=50_sg=1_OUT-OUT       0.646858  \nword2vec_mc=10_size=100_window=50_sg=0_IN-IN         0.747688  \nword2vec_mc=10_size=100_window=50_sg=0_IN-OUT        0.759300  \nword2vec_mc=10_size=100_window=50_sg=0_OUT-IN        0.760459  \nword2vec_mc=10_size=100_window=50_sg=0_OUT-OUT       0.521144  \nword2vec_mc=10_size=300_window=5_sg=0_IN-IN          0.731766  \nword2vec_mc=10_size=300_window=5_sg=0_IN-OUT         0.737783  \nword2vec_mc=10_size=300_window=5_sg=0_OUT-IN         0.728635  \nword2vec_mc=10_size=300_window=5_sg=0_OUT-OUT        0.565083  \nword2vec_mc=10_size=100_window=50_sg=1_IN-IN         0.665748  \nword2vec_mc=10_size=100_window=50_sg=1_IN-OUT        0.661580  \nword2vec_mc=10_size=100_window=50_sg=1_OUT-IN        0.679914  \nword2vec_mc=10_size=100_window=50_sg=1_OUT-OUT       0.592233  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EN-VERB-143</th>\n      <th>EN-SimVerb-3500</th>\n      <th>EN-RG-65</th>\n      <th>EN-RW-STANFORD</th>\n      <th>EN-MTurk-771</th>\n      <th>EN-MEN-TR-3k</th>\n      <th>EN-MC-30</th>\n      <th>EN-MTurk-287</th>\n      <th>EN-SIMLEX-999</th>\n      <th>EN-WS-353-REL</th>\n      <th>EN-YP-130</th>\n      <th>EN-WS-353-ALL</th>\n      <th>EN-WS-353-SIM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_IN-IN</th>\n      <td>0.348385</td>\n      <td>0.136442</td>\n      <td>0.689558</td>\n      <td>0.371992</td>\n      <td>0.600273</td>\n      <td>0.705429</td>\n      <td>0.748075</td>\n      <td>0.697174</td>\n      <td>0.250338</td>\n      <td>0.576391</td>\n      <td>0.404015</td>\n      <td>0.617125</td>\n      <td>0.680832</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_IN-OUT</th>\n      <td>0.235017</td>\n      <td>0.155150</td>\n      <td>0.692447</td>\n      <td>0.321379</td>\n      <td>0.576795</td>\n      <td>0.705933</td>\n      <td>0.676273</td>\n      <td>0.681006</td>\n      <td>0.244184</td>\n      <td>0.601608</td>\n      <td>0.417910</td>\n      <td>0.637686</td>\n      <td>0.696694</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_OUT-IN</th>\n      <td>0.241199</td>\n      <td>0.134027</td>\n      <td>0.699191</td>\n      <td>0.342025</td>\n      <td>0.570744</td>\n      <td>0.707308</td>\n      <td>0.774847</td>\n      <td>0.686461</td>\n      <td>0.212156</td>\n      <td>0.606514</td>\n      <td>0.358022</td>\n      <td>0.639168</td>\n      <td>0.701967</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=1_OUT-OUT</th>\n      <td>0.200181</td>\n      <td>0.120344</td>\n      <td>0.662345</td>\n      <td>0.353782</td>\n      <td>0.521671</td>\n      <td>0.655967</td>\n      <td>0.705394</td>\n      <td>0.663086</td>\n      <td>0.258613</td>\n      <td>0.478582</td>\n      <td>0.264028</td>\n      <td>0.562823</td>\n      <td>0.643725</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=1_IN-IN</th>\n      <td>0.517928</td>\n      <td>0.227086</td>\n      <td>0.788407</td>\n      <td>0.434912</td>\n      <td>0.648054</td>\n      <td>0.744061</td>\n      <td>0.834629</td>\n      <td>0.703733</td>\n      <td>0.345374</td>\n      <td>0.613786</td>\n      <td>0.496736</td>\n      <td>0.665041</td>\n      <td>0.760809</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=1_IN-OUT</th>\n      <td>0.299097</td>\n      <td>0.199233</td>\n      <td>0.807674</td>\n      <td>0.349348</td>\n      <td>0.646708</td>\n      <td>0.754456</td>\n      <td>0.780756</td>\n      <td>0.691210</td>\n      <td>0.316901</td>\n      <td>0.633388</td>\n      <td>0.595605</td>\n      <td>0.681078</td>\n      <td>0.756384</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=1_OUT-IN</th>\n      <td>0.292260</td>\n      <td>0.195872</td>\n      <td>0.794775</td>\n      <td>0.376885</td>\n      <td>0.635240</td>\n      <td>0.756149</td>\n      <td>0.825204</td>\n      <td>0.690761</td>\n      <td>0.307551</td>\n      <td>0.638189</td>\n      <td>0.567946</td>\n      <td>0.684379</td>\n      <td>0.762446</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=1_OUT-OUT</th>\n      <td>0.393531</td>\n      <td>0.227743</td>\n      <td>0.791328</td>\n      <td>0.445182</td>\n      <td>0.609784</td>\n      <td>0.707830</td>\n      <td>0.828334</td>\n      <td>0.685684</td>\n      <td>0.352648</td>\n      <td>0.585010</td>\n      <td>0.407597</td>\n      <td>0.642707</td>\n      <td>0.731489</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=0_IN-IN</th>\n      <td>0.394430</td>\n      <td>0.242295</td>\n      <td>0.810194</td>\n      <td>0.416176</td>\n      <td>0.673047</td>\n      <td>0.748357</td>\n      <td>0.827492</td>\n      <td>0.729598</td>\n      <td>0.384130</td>\n      <td>0.617595</td>\n      <td>0.549107</td>\n      <td>0.682406</td>\n      <td>0.770362</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=0_IN-OUT</th>\n      <td>0.364491</td>\n      <td>0.217746</td>\n      <td>0.806325</td>\n      <td>0.174929</td>\n      <td>0.675458</td>\n      <td>0.767482</td>\n      <td>0.850240</td>\n      <td>0.688254</td>\n      <td>0.328275</td>\n      <td>0.679162</td>\n      <td>0.628606</td>\n      <td>0.722037</td>\n      <td>0.797995</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=0_OUT-IN</th>\n      <td>0.419148</td>\n      <td>0.219857</td>\n      <td>0.785515</td>\n      <td>0.305298</td>\n      <td>0.666954</td>\n      <td>0.766901</td>\n      <td>0.846825</td>\n      <td>0.695786</td>\n      <td>0.329116</td>\n      <td>0.652448</td>\n      <td>0.604400</td>\n      <td>0.702297</td>\n      <td>0.790754</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=50_sg=0_OUT-OUT</th>\n      <td>0.102491</td>\n      <td>0.182186</td>\n      <td>0.609477</td>\n      <td>0.371939</td>\n      <td>0.420810</td>\n      <td>0.532472</td>\n      <td>0.687255</td>\n      <td>0.451895</td>\n      <td>0.310145</td>\n      <td>0.410912</td>\n      <td>0.223004</td>\n      <td>0.475832</td>\n      <td>0.529964</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=0_IN-IN</th>\n      <td>0.416544</td>\n      <td>0.247136</td>\n      <td>0.799609</td>\n      <td>0.404248</td>\n      <td>0.682964</td>\n      <td>0.750712</td>\n      <td>0.836952</td>\n      <td>0.735229</td>\n      <td>0.393683</td>\n      <td>0.631586</td>\n      <td>0.536876</td>\n      <td>0.688147</td>\n      <td>0.774493</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=0_IN-OUT</th>\n      <td>0.409810</td>\n      <td>0.225474</td>\n      <td>0.800564</td>\n      <td>0.203236</td>\n      <td>0.681842</td>\n      <td>0.771025</td>\n      <td>0.855956</td>\n      <td>0.675741</td>\n      <td>0.334083</td>\n      <td>0.676360</td>\n      <td>0.658757</td>\n      <td>0.723916</td>\n      <td>0.809128</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=0_OUT-IN</th>\n      <td>0.406600</td>\n      <td>0.223103</td>\n      <td>0.795472</td>\n      <td>0.321761</td>\n      <td>0.683132</td>\n      <td>0.770652</td>\n      <td>0.837708</td>\n      <td>0.690433</td>\n      <td>0.336993</td>\n      <td>0.660240</td>\n      <td>0.629736</td>\n      <td>0.702898</td>\n      <td>0.788447</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=0_OUT-OUT</th>\n      <td>0.095487</td>\n      <td>0.185821</td>\n      <td>0.614705</td>\n      <td>0.355765</td>\n      <td>0.420963</td>\n      <td>0.514592</td>\n      <td>0.681678</td>\n      <td>0.429671</td>\n      <td>0.315876</td>\n      <td>0.441169</td>\n      <td>0.265035</td>\n      <td>0.482349</td>\n      <td>0.527552</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=1_IN-IN</th>\n      <td>0.482817</td>\n      <td>0.217846</td>\n      <td>0.789657</td>\n      <td>0.432369</td>\n      <td>0.646149</td>\n      <td>0.738651</td>\n      <td>0.827377</td>\n      <td>0.715969</td>\n      <td>0.338956</td>\n      <td>0.609330</td>\n      <td>0.470148</td>\n      <td>0.664708</td>\n      <td>0.761616</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=1_IN-OUT</th>\n      <td>0.296835</td>\n      <td>0.194336</td>\n      <td>0.797698</td>\n      <td>0.346512</td>\n      <td>0.641914</td>\n      <td>0.741633</td>\n      <td>0.770353</td>\n      <td>0.701847</td>\n      <td>0.313631</td>\n      <td>0.618793</td>\n      <td>0.567738</td>\n      <td>0.670919</td>\n      <td>0.748973</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=1_OUT-IN</th>\n      <td>0.293794</td>\n      <td>0.185308</td>\n      <td>0.790263</td>\n      <td>0.372501</td>\n      <td>0.632373</td>\n      <td>0.745778</td>\n      <td>0.824139</td>\n      <td>0.704299</td>\n      <td>0.299699</td>\n      <td>0.628160</td>\n      <td>0.533417</td>\n      <td>0.679331</td>\n      <td>0.760188</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=1_OUT-OUT</th>\n      <td>0.361853</td>\n      <td>0.210677</td>\n      <td>0.781238</td>\n      <td>0.440798</td>\n      <td>0.601878</td>\n      <td>0.702610</td>\n      <td>0.819575</td>\n      <td>0.691652</td>\n      <td>0.342725</td>\n      <td>0.566547</td>\n      <td>0.378778</td>\n      <td>0.637614</td>\n      <td>0.728616</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=0_IN-IN</th>\n      <td>0.432098</td>\n      <td>0.235446</td>\n      <td>0.757611</td>\n      <td>0.403487</td>\n      <td>0.640210</td>\n      <td>0.709575</td>\n      <td>0.767914</td>\n      <td>0.710704</td>\n      <td>0.370946</td>\n      <td>0.527181</td>\n      <td>0.410605</td>\n      <td>0.612903</td>\n      <td>0.725328</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=0_IN-OUT</th>\n      <td>0.196140</td>\n      <td>0.152272</td>\n      <td>0.789909</td>\n      <td>0.189647</td>\n      <td>0.627922</td>\n      <td>0.748347</td>\n      <td>0.766180</td>\n      <td>0.641150</td>\n      <td>0.279615</td>\n      <td>0.593467</td>\n      <td>0.540817</td>\n      <td>0.647561</td>\n      <td>0.733714</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=0_OUT-IN</th>\n      <td>0.172198</td>\n      <td>0.159226</td>\n      <td>0.758817</td>\n      <td>0.265527</td>\n      <td>0.626877</td>\n      <td>0.751477</td>\n      <td>0.769303</td>\n      <td>0.674786</td>\n      <td>0.257677</td>\n      <td>0.590124</td>\n      <td>0.544324</td>\n      <td>0.647861</td>\n      <td>0.748210</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=200_window=5_sg=0_OUT-OUT</th>\n      <td>0.266438</td>\n      <td>0.228066</td>\n      <td>0.655455</td>\n      <td>0.390563</td>\n      <td>0.469055</td>\n      <td>0.553551</td>\n      <td>0.708572</td>\n      <td>0.491417</td>\n      <td>0.350355</td>\n      <td>0.435583</td>\n      <td>0.318154</td>\n      <td>0.521397</td>\n      <td>0.595315</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=1_IN-IN</th>\n      <td>0.448303</td>\n      <td>0.190646</td>\n      <td>0.723801</td>\n      <td>0.420069</td>\n      <td>0.653539</td>\n      <td>0.741671</td>\n      <td>0.803071</td>\n      <td>0.729529</td>\n      <td>0.352884</td>\n      <td>0.621855</td>\n      <td>0.461474</td>\n      <td>0.660472</td>\n      <td>0.724451</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=1_IN-OUT</th>\n      <td>0.311796</td>\n      <td>0.175695</td>\n      <td>0.742475</td>\n      <td>0.336603</td>\n      <td>0.650781</td>\n      <td>0.739563</td>\n      <td>0.760775</td>\n      <td>0.706507</td>\n      <td>0.320903</td>\n      <td>0.637547</td>\n      <td>0.498861</td>\n      <td>0.658141</td>\n      <td>0.707545</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=1_OUT-IN</th>\n      <td>0.348733</td>\n      <td>0.169659</td>\n      <td>0.752517</td>\n      <td>0.367911</td>\n      <td>0.646202</td>\n      <td>0.743793</td>\n      <td>0.826061</td>\n      <td>0.707433</td>\n      <td>0.297409</td>\n      <td>0.630167</td>\n      <td>0.454333</td>\n      <td>0.670193</td>\n      <td>0.734340</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=1_OUT-OUT</th>\n      <td>0.338572</td>\n      <td>0.185117</td>\n      <td>0.688304</td>\n      <td>0.434279</td>\n      <td>0.605228</td>\n      <td>0.696343</td>\n      <td>0.779926</td>\n      <td>0.692046</td>\n      <td>0.350492</td>\n      <td>0.567658</td>\n      <td>0.360153</td>\n      <td>0.623079</td>\n      <td>0.685875</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_IN-IN</th>\n      <td>0.397469</td>\n      <td>0.217338</td>\n      <td>0.733976</td>\n      <td>0.396344</td>\n      <td>0.655349</td>\n      <td>0.720543</td>\n      <td>0.788112</td>\n      <td>0.714405</td>\n      <td>0.377482</td>\n      <td>0.554434</td>\n      <td>0.396154</td>\n      <td>0.624361</td>\n      <td>0.714421</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_IN-OUT</th>\n      <td>0.204517</td>\n      <td>0.141301</td>\n      <td>0.801957</td>\n      <td>0.151973</td>\n      <td>0.653189</td>\n      <td>0.764957</td>\n      <td>0.832302</td>\n      <td>0.657793</td>\n      <td>0.280067</td>\n      <td>0.636703</td>\n      <td>0.443034</td>\n      <td>0.666794</td>\n      <td>0.724590</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_OUT-IN</th>\n      <td>0.271551</td>\n      <td>0.144976</td>\n      <td>0.798610</td>\n      <td>0.231115</td>\n      <td>0.646353</td>\n      <td>0.766770</td>\n      <td>0.823056</td>\n      <td>0.679873</td>\n      <td>0.262355</td>\n      <td>0.631646</td>\n      <td>0.463202</td>\n      <td>0.659351</td>\n      <td>0.720353</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=5_sg=0_OUT-OUT</th>\n      <td>0.260214</td>\n      <td>0.196568</td>\n      <td>0.605548</td>\n      <td>0.411272</td>\n      <td>0.484524</td>\n      <td>0.590263</td>\n      <td>0.688151</td>\n      <td>0.529687</td>\n      <td>0.324987</td>\n      <td>0.475809</td>\n      <td>0.300444</td>\n      <td>0.545319</td>\n      <td>0.594989</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=1_IN-IN</th>\n      <td>0.356414</td>\n      <td>0.133368</td>\n      <td>0.693212</td>\n      <td>0.365597</td>\n      <td>0.607422</td>\n      <td>0.704574</td>\n      <td>0.751669</td>\n      <td>0.704276</td>\n      <td>0.253825</td>\n      <td>0.582218</td>\n      <td>0.432730</td>\n      <td>0.620329</td>\n      <td>0.683009</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=1_IN-OUT</th>\n      <td>0.263402</td>\n      <td>0.161780</td>\n      <td>0.710701</td>\n      <td>0.327415</td>\n      <td>0.589121</td>\n      <td>0.714410</td>\n      <td>0.703038</td>\n      <td>0.688846</td>\n      <td>0.258971</td>\n      <td>0.603133</td>\n      <td>0.440160</td>\n      <td>0.644572</td>\n      <td>0.703518</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=1_OUT-IN</th>\n      <td>0.259881</td>\n      <td>0.144361</td>\n      <td>0.714680</td>\n      <td>0.340855</td>\n      <td>0.584684</td>\n      <td>0.715817</td>\n      <td>0.780702</td>\n      <td>0.687883</td>\n      <td>0.226867</td>\n      <td>0.612513</td>\n      <td>0.404996</td>\n      <td>0.646495</td>\n      <td>0.704138</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=50_sg=1_OUT-OUT</th>\n      <td>0.225828</td>\n      <td>0.119971</td>\n      <td>0.676764</td>\n      <td>0.348246</td>\n      <td>0.530898</td>\n      <td>0.663713</td>\n      <td>0.709489</td>\n      <td>0.666417</td>\n      <td>0.266696</td>\n      <td>0.486244</td>\n      <td>0.277599</td>\n      <td>0.568491</td>\n      <td>0.646858</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=0_IN-IN</th>\n      <td>0.324930</td>\n      <td>0.225355</td>\n      <td>0.803224</td>\n      <td>0.405775</td>\n      <td>0.685750</td>\n      <td>0.755303</td>\n      <td>0.880496</td>\n      <td>0.736700</td>\n      <td>0.379981</td>\n      <td>0.626307</td>\n      <td>0.548792</td>\n      <td>0.681489</td>\n      <td>0.747688</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=0_IN-OUT</th>\n      <td>0.370451</td>\n      <td>0.221314</td>\n      <td>0.801698</td>\n      <td>0.135946</td>\n      <td>0.684466</td>\n      <td>0.780802</td>\n      <td>0.871515</td>\n      <td>0.706782</td>\n      <td>0.326742</td>\n      <td>0.686035</td>\n      <td>0.624519</td>\n      <td>0.714877</td>\n      <td>0.759300</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=0_OUT-IN</th>\n      <td>0.386157</td>\n      <td>0.227102</td>\n      <td>0.791083</td>\n      <td>0.271472</td>\n      <td>0.674629</td>\n      <td>0.779722</td>\n      <td>0.896772</td>\n      <td>0.721075</td>\n      <td>0.322724</td>\n      <td>0.653547</td>\n      <td>0.592756</td>\n      <td>0.699119</td>\n      <td>0.760459</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=0_OUT-OUT</th>\n      <td>0.132810</td>\n      <td>0.169322</td>\n      <td>0.549754</td>\n      <td>0.388468</td>\n      <td>0.449542</td>\n      <td>0.562473</td>\n      <td>0.666960</td>\n      <td>0.474320</td>\n      <td>0.299569</td>\n      <td>0.417257</td>\n      <td>0.245852</td>\n      <td>0.480831</td>\n      <td>0.521144</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=0_IN-IN</th>\n      <td>0.441982</td>\n      <td>0.253362</td>\n      <td>0.784335</td>\n      <td>0.408229</td>\n      <td>0.645200</td>\n      <td>0.711933</td>\n      <td>0.799125</td>\n      <td>0.709403</td>\n      <td>0.390722</td>\n      <td>0.535713</td>\n      <td>0.442790</td>\n      <td>0.617641</td>\n      <td>0.731766</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=0_IN-OUT</th>\n      <td>0.178680</td>\n      <td>0.148885</td>\n      <td>0.810339</td>\n      <td>0.197481</td>\n      <td>0.619198</td>\n      <td>0.747278</td>\n      <td>0.755033</td>\n      <td>0.622425</td>\n      <td>0.268832</td>\n      <td>0.585443</td>\n      <td>0.594192</td>\n      <td>0.635908</td>\n      <td>0.737783</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=0_OUT-IN</th>\n      <td>0.155201</td>\n      <td>0.146423</td>\n      <td>0.772920</td>\n      <td>0.268727</td>\n      <td>0.618172</td>\n      <td>0.749097</td>\n      <td>0.779702</td>\n      <td>0.657113</td>\n      <td>0.253982</td>\n      <td>0.589323</td>\n      <td>0.592951</td>\n      <td>0.629129</td>\n      <td>0.728635</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=300_window=5_sg=0_OUT-OUT</th>\n      <td>0.271029</td>\n      <td>0.234150</td>\n      <td>0.619064</td>\n      <td>0.374641</td>\n      <td>0.460333</td>\n      <td>0.533920</td>\n      <td>0.691256</td>\n      <td>0.472874</td>\n      <td>0.353941</td>\n      <td>0.415311</td>\n      <td>0.317288</td>\n      <td>0.496389</td>\n      <td>0.565083</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=1_IN-IN</th>\n      <td>0.343649</td>\n      <td>0.129438</td>\n      <td>0.631034</td>\n      <td>0.364969</td>\n      <td>0.599180</td>\n      <td>0.707534</td>\n      <td>0.734093</td>\n      <td>0.678924</td>\n      <td>0.270670</td>\n      <td>0.596681</td>\n      <td>0.398936</td>\n      <td>0.619936</td>\n      <td>0.665748</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=1_IN-OUT</th>\n      <td>0.194432</td>\n      <td>0.131706</td>\n      <td>0.615201</td>\n      <td>0.290014</td>\n      <td>0.566491</td>\n      <td>0.697948</td>\n      <td>0.686285</td>\n      <td>0.673872</td>\n      <td>0.241359</td>\n      <td>0.607200</td>\n      <td>0.370416</td>\n      <td>0.620555</td>\n      <td>0.661580</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=1_OUT-IN</th>\n      <td>0.235435</td>\n      <td>0.115384</td>\n      <td>0.639019</td>\n      <td>0.313612</td>\n      <td>0.560618</td>\n      <td>0.697433</td>\n      <td>0.765441</td>\n      <td>0.681186</td>\n      <td>0.209513</td>\n      <td>0.603144</td>\n      <td>0.325844</td>\n      <td>0.627239</td>\n      <td>0.679914</td>\n    </tr>\n    <tr>\n      <th>word2vec_mc=10_size=100_window=50_sg=1_OUT-OUT</th>\n      <td>0.159187</td>\n      <td>0.113396</td>\n      <td>0.631493</td>\n      <td>0.351778</td>\n      <td>0.523350</td>\n      <td>0.650569</td>\n      <td>0.688477</td>\n      <td>0.657267</td>\n      <td>0.280747</td>\n      <td>0.479837</td>\n      <td>0.273108</td>\n      <td>0.542002</td>\n      <td>0.592233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00035-eb722f10-fdc5-486f-91d6-c2049840470f"},"source":"","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"dict_keys(['score_matrix'])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Association","metadata":{"tags":[],"cell_id":"00036-06650a90-42a4-4128-bb47-aac9a6d8bf34"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00036-71254e37-732e-4fc1-9f2b-71d99ed9fa48","output_cleared":false},"source":"# all association result\ndef clean_association_model_name(name): return name.replace(\"mc=10_\", \"\").replace(\"_10_tp_score\", \"\")\nall_association_result = []\nfor result_file in tqdm(glob.glob(\"../output/word2vec/association/*\")):\n    with open(result_file, \"rb\") as f:\n        data = pickle.load(f)\n        sw_data = pd.DataFrame(data['score_matrix']['swow8500'])\n        eat_data = pd.DataFrame(data['score_matrix']['eat'])\n        # x.\n        association_result = []\n        for col in sw_data.describe().columns:\n            result = {}\n            for dataset_name, dataset in [(\"swow8500\", sw_data), (\"eat\", eat_data)]:\n                def get_stats(dataset_name, dataset):\n                    hit_rate = dataset[dataset[col]>0].shape[0] / dataset.shape[0] \n                    avg_coverage =  dataset.loc[:, col].mean()\n                    return {'col': clean_association_model_name(col), f'{dataset_name}_hit_rate': hit_rate, f'{dataset_name}_avg_coverage': avg_coverage}\n                result = {**result, **get_stats(dataset_name, dataset)}\n            association_result.append(result)\n        association_result = pd.DataFrame(association_result)\n        association_result.index = association_result['col']\n        association_result.drop(columns=['col'], inplace=True)\n        all_association_result.append(association_result)\nall_association_result = pd.concat(all_association_result)\nall_association_result.to_csv(\"../output/all_association_result_v2.csv\")","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00038-db707de3-e638-44bc-9885-8c023ab1ac8c"},"source":"# with open('../output/word2vec/association/word2vec_results_word2vec_mc=10_size=100_window=50_sg=0_association.pickle', 'rb') as f:\n#     data = pickle.load(f)\n#     sw_data = pd.DataFrame(data['score_matrix']['swow8500'])\n#     display(sw_data.describe())\n# # glob.glob(\"../output/word2vec/association/*\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00039-d5b842f4-a177-46de-b207-150820ad1970"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analogy","metadata":{"tags":[],"cell_id":"00040-8da342e7-4abd-48ad-bbb7-7ab46ecde5d6"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00041-94fc5e4a-afa6-45d4-88e7-6fb6c76d5237"},"source":"# all association result\n# def clean_association_model_name(name): return name.replace(\"mc=10_\", \"\").replace(\"_10_tp_score\", \"\")\nall_analogy_result = []\nfor result_file in tqdm(glob.glob(\"../output/word2vec/analogy/*\")):\n    with open(result_file, \"rb\") as f:\n        data = pickle.load(f)\n        model_name = re.findall( \"_word2vec.*\",result_file)[0].replace(\"_analogy.pickle\", \"\")\n        def extract_result(dataset_name, model_name):\n            dataset = pd.DataFrame(data['score_matrix'][dataset_name])\n            dataset = pd.DataFrame(dataset).groupby('method').mean()\n            dataset.columns = [dataset_name + \"_\" + str(x) for x in dataset.columns]\n            dataset.index = [model_name + \"_\" + x for x in dataset.index]\n            return dataset\n        result = pd.concat([extract_result('google_analogy', model_name), \n                              extract_result('bats_analogy', model_name)], axis=1)\n        all_analogy_result.append(result)\nall_analogy_result = pd.concat(all_analogy_result)\nall_analogy_result.to_csv(\"../output/all_analogy_result.csv\")","execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 12/12 [00:02<00:00,  5.79it/s]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00042-c650f31e-9ca4-417b-9aa5-eaceaacf0e4d","output_cleared":false},"source":"with open(glob.glob(\"../output/word2vec/analogy/*\")[5], \"rb\") as f:\n    data = pickle.load(f)\ndata['score_matrix']['google_analogy'].describe()\n","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":8,"column_count":2,"columns":[{"name":"cos3add_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0,"max":3976,"histogram":[{"bin_start":0,"bin_end":397.6,"count":7},{"bin_start":397.6,"bin_end":795.2,"count":0},{"bin_start":795.2,"bin_end":1192.8000000000002,"count":0},{"bin_start":1192.8000000000002,"bin_end":1590.4,"count":0},{"bin_start":1590.4,"bin_end":1988,"count":0},{"bin_start":1988,"bin_end":2385.6000000000004,"count":0},{"bin_start":2385.6000000000004,"bin_end":2783.2000000000003,"count":0},{"bin_start":2783.2000000000003,"bin_end":3180.8,"count":0},{"bin_start":3180.8,"bin_end":3578.4,"count":0},{"bin_start":3578.4,"bin_end":3976,"count":1}]}},{"name":"cos3mul_score","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":0,"max":3976,"histogram":[{"bin_start":0,"bin_end":397.6,"count":7},{"bin_start":397.6,"bin_end":795.2,"count":0},{"bin_start":795.2,"bin_end":1192.8000000000002,"count":0},{"bin_start":1192.8000000000002,"bin_end":1590.4,"count":0},{"bin_start":1590.4,"bin_end":1988,"count":0},{"bin_start":1988,"bin_end":2385.6000000000004,"count":0},{"bin_start":2385.6000000000004,"bin_end":2783.2000000000003,"count":0},{"bin_start":2783.2000000000003,"bin_end":3180.8,"count":0},{"bin_start":3180.8,"bin_end":3578.4,"count":0},{"bin_start":3578.4,"bin_end":3976,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"cos3add_score":3976,"cos3mul_score":3976,"_deepnote_index_column":"count"},{"cos3add_score":0.5369718309859155,"cos3mul_score":0.5339537223340041,"_deepnote_index_column":"mean"},{"cos3add_score":0.4986939270905541,"cos3mul_score":0.49890855654613286,"_deepnote_index_column":"std"},{"cos3add_score":0,"cos3mul_score":0,"_deepnote_index_column":"min"},{"cos3add_score":0,"cos3mul_score":0,"_deepnote_index_column":"25%"},{"cos3add_score":1,"cos3mul_score":1,"_deepnote_index_column":"50%"},{"cos3add_score":1,"cos3mul_score":1,"_deepnote_index_column":"75%"},{"cos3add_score":1,"cos3mul_score":1,"_deepnote_index_column":"max"}],"rows_bottom":null},"text/plain":"       cos3add_score  cos3mul_score\ncount    3976.000000    3976.000000\nmean        0.536972       0.533954\nstd         0.498694       0.498909\nmin         0.000000       0.000000\n25%         0.000000       0.000000\n50%         1.000000       1.000000\n75%         1.000000       1.000000\nmax         1.000000       1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cos3add_score</th>\n      <th>cos3mul_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3976.000000</td>\n      <td>3976.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.536972</td>\n      <td>0.533954</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.498694</td>\n      <td>0.498909</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00043-9caf419b-8c5c-4c6d-8d13-431c546e60c7"},"source":"import re\nre.findall( \"_word2vec.*\", glob.glob(\"../output/word2vec/analogy/*\")[0])","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":134,"data":{"text/plain":"['_word2vec_mc=10_size=100_window=50_sg=0_analogy.pickle']"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00044-f0cd999a-a174-44bd-ab89-78f6bf31afea"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparing the final results","metadata":{"tags":[],"cell_id":"00046-39798572-755d-47bb-ae83-411785ab38e1"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00048-77ea879e-69a6-4b81-a19a-079c0899522d"},"source":"# read and extract result files\nanalogy_result = pd.read_csv(\"../output/all_analogy_result.csv\")\nanalogy_result.loc[:, 'Unnamed: 0'] = analogy_result['Unnamed: 0'].apply(lambda x: x.replace(\"_word2vec_mc=10_\", \"word2vec_\"))\nanalogy_result.rename(columns={'Unnamed: 0': 'model_name'}, inplace=True)\nto_keep = ['model_name', 'google_analogy_cos3mul_score', 'bats_analogy_cos3mul_score']\nanalogy_result = analogy_result.loc[:, to_keep]\nassociation_result = pd.read_csv(\"../output/all_association_result.csv\")\nassociation_result.rename(columns={'col': 'model_name'}, inplace=True)\nrelatedness_result = pd.read_csv(\"../output/all_relatedness_table_v2.csv\")\nrelatedness_result.loc[:, 'Unnamed: 0'] = relatedness_result['Unnamed: 0'].apply(lambda x: x.replace(\"word2vec_mc=10_\", \"word2vec_\"))\nrelatedness_result.rename(columns={'Unnamed: 0': 'model_name'}, inplace=True)\nto_keep = ['model_name','EN-WS-353-ALL', 'EN-MEN-TR-3k', 'EN-YP-130', 'EN-SIMLEX-999', 'EN-VERB-143', 'EN-SimVerb-3500']\nrelatedness_result = relatedness_result.loc[:, to_keep]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00048-f1e0b73f-acd8-4bb2-b460-a216b88f3c33"},"source":"final_result = pd.merge(analogy_result, association_result, on='model_name')\nfinal_result = pd.merge(final_result, relatedness_result, on='model_name')\nfinal_result.shape","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"(48, 13)"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00049-0e5b7a04-fb24-4acf-a880-149d8349a8e7"},"source":"# !pip install seaborn\n# import seaborn as sns\n# %matplotlib inline\n# sns.heatmap(relatedness_result.corr(), annot=False)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f6ccdda0518>"},"metadata":{}},{"data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00051-b47d87f2-b149-4a6d-adf4-8c93cb42deb2"},"source":"final_result[['algorithm', 'dimension', 'window', 'method', 'model_type']] = final_result['model_name'].str.split(\"_\", expand=True)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00051-b1eaa046-f863-47ef-9c75-8014146caaaa"},"source":"","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":48,"column_count":5,"columns":[{"name":0,"dtype":"object","stats":{"unique_count":1,"nan_count":0,"categories":[{"name":"word2vec","count":48}]}},{"name":1,"dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"size=100","count":16},{"name":"size=300","count":16},{"name":"size=200","count":16}]}},{"name":2,"dtype":"object","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"window=50","count":24},{"name":"window=5","count":24}]}},{"name":3,"dtype":"object","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"sg=0","count":24},{"name":"sg=1","count":24}]}},{"name":4,"dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"IN-IN","count":12},{"name":"IN-OUT","count":12},{"name":"2 others","count":24}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=0","4":"IN-IN","_deepnote_index_column":0},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=0","4":"IN-OUT","_deepnote_index_column":1},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=0","4":"OUT-IN","_deepnote_index_column":2},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=0","4":"OUT-OUT","_deepnote_index_column":3},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=1","4":"IN-IN","_deepnote_index_column":4},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=1","4":"IN-OUT","_deepnote_index_column":5},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=1","4":"OUT-IN","_deepnote_index_column":6},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=1","4":"OUT-OUT","_deepnote_index_column":7},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=1","4":"IN-IN","_deepnote_index_column":8},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=1","4":"IN-OUT","_deepnote_index_column":9},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=1","4":"OUT-IN","_deepnote_index_column":10},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=1","4":"OUT-OUT","_deepnote_index_column":11},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=0","4":"IN-IN","_deepnote_index_column":12},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=0","4":"IN-OUT","_deepnote_index_column":13},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=0","4":"OUT-IN","_deepnote_index_column":14},{"0":"word2vec","1":"size=100","2":"window=5","3":"sg=0","4":"OUT-OUT","_deepnote_index_column":15},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=1","4":"IN-IN","_deepnote_index_column":16},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=1","4":"IN-OUT","_deepnote_index_column":17},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=1","4":"OUT-IN","_deepnote_index_column":18},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=1","4":"OUT-OUT","_deepnote_index_column":19},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=1","4":"IN-IN","_deepnote_index_column":20},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=1","4":"IN-OUT","_deepnote_index_column":21},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=1","4":"OUT-IN","_deepnote_index_column":22},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=1","4":"OUT-OUT","_deepnote_index_column":23},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=0","4":"IN-IN","_deepnote_index_column":24},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=0","4":"IN-OUT","_deepnote_index_column":25},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=0","4":"OUT-IN","_deepnote_index_column":26},{"0":"word2vec","1":"size=300","2":"window=50","3":"sg=0","4":"OUT-OUT","_deepnote_index_column":27},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=0","4":"IN-IN","_deepnote_index_column":28},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=0","4":"IN-OUT","_deepnote_index_column":29},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=0","4":"OUT-IN","_deepnote_index_column":30},{"0":"word2vec","1":"size=200","2":"window=50","3":"sg=0","4":"OUT-OUT","_deepnote_index_column":31},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=0","4":"IN-IN","_deepnote_index_column":32},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=0","4":"IN-OUT","_deepnote_index_column":33},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=0","4":"OUT-IN","_deepnote_index_column":34},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=0","4":"OUT-OUT","_deepnote_index_column":35},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=1","4":"IN-IN","_deepnote_index_column":36},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=1","4":"IN-OUT","_deepnote_index_column":37},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=1","4":"OUT-IN","_deepnote_index_column":38},{"0":"word2vec","1":"size=200","2":"window=5","3":"sg=1","4":"OUT-OUT","_deepnote_index_column":39},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=0","4":"IN-IN","_deepnote_index_column":40},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=0","4":"IN-OUT","_deepnote_index_column":41},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=0","4":"OUT-IN","_deepnote_index_column":42},{"0":"word2vec","1":"size=300","2":"window=5","3":"sg=0","4":"OUT-OUT","_deepnote_index_column":43},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=1","4":"IN-IN","_deepnote_index_column":44},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=1","4":"IN-OUT","_deepnote_index_column":45},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=1","4":"OUT-IN","_deepnote_index_column":46},{"0":"word2vec","1":"size=100","2":"window=50","3":"sg=1","4":"OUT-OUT","_deepnote_index_column":47}],"rows_bottom":null},"text/plain":"           0         1          2     3        4\n0   word2vec  size=100  window=50  sg=0    IN-IN\n1   word2vec  size=100  window=50  sg=0   IN-OUT\n2   word2vec  size=100  window=50  sg=0   OUT-IN\n3   word2vec  size=100  window=50  sg=0  OUT-OUT\n4   word2vec  size=100   window=5  sg=1    IN-IN\n5   word2vec  size=100   window=5  sg=1   IN-OUT\n6   word2vec  size=100   window=5  sg=1   OUT-IN\n7   word2vec  size=100   window=5  sg=1  OUT-OUT\n8   word2vec  size=300   window=5  sg=1    IN-IN\n9   word2vec  size=300   window=5  sg=1   IN-OUT\n10  word2vec  size=300   window=5  sg=1   OUT-IN\n11  word2vec  size=300   window=5  sg=1  OUT-OUT\n12  word2vec  size=100   window=5  sg=0    IN-IN\n13  word2vec  size=100   window=5  sg=0   IN-OUT\n14  word2vec  size=100   window=5  sg=0   OUT-IN\n15  word2vec  size=100   window=5  sg=0  OUT-OUT\n16  word2vec  size=200  window=50  sg=1    IN-IN\n17  word2vec  size=200  window=50  sg=1   IN-OUT\n18  word2vec  size=200  window=50  sg=1   OUT-IN\n19  word2vec  size=200  window=50  sg=1  OUT-OUT\n20  word2vec  size=300  window=50  sg=1    IN-IN\n21  word2vec  size=300  window=50  sg=1   IN-OUT\n22  word2vec  size=300  window=50  sg=1   OUT-IN\n23  word2vec  size=300  window=50  sg=1  OUT-OUT\n24  word2vec  size=300  window=50  sg=0    IN-IN\n25  word2vec  size=300  window=50  sg=0   IN-OUT\n26  word2vec  size=300  window=50  sg=0   OUT-IN\n27  word2vec  size=300  window=50  sg=0  OUT-OUT\n28  word2vec  size=200  window=50  sg=0    IN-IN\n29  word2vec  size=200  window=50  sg=0   IN-OUT\n30  word2vec  size=200  window=50  sg=0   OUT-IN\n31  word2vec  size=200  window=50  sg=0  OUT-OUT\n32  word2vec  size=200   window=5  sg=0    IN-IN\n33  word2vec  size=200   window=5  sg=0   IN-OUT\n34  word2vec  size=200   window=5  sg=0   OUT-IN\n35  word2vec  size=200   window=5  sg=0  OUT-OUT\n36  word2vec  size=200   window=5  sg=1    IN-IN\n37  word2vec  size=200   window=5  sg=1   IN-OUT\n38  word2vec  size=200   window=5  sg=1   OUT-IN\n39  word2vec  size=200   window=5  sg=1  OUT-OUT\n40  word2vec  size=300   window=5  sg=0    IN-IN\n41  word2vec  size=300   window=5  sg=0   IN-OUT\n42  word2vec  size=300   window=5  sg=0   OUT-IN\n43  word2vec  size=300   window=5  sg=0  OUT-OUT\n44  word2vec  size=100  window=50  sg=1    IN-IN\n45  word2vec  size=100  window=50  sg=1   IN-OUT\n46  word2vec  size=100  window=50  sg=1   OUT-IN\n47  word2vec  size=100  window=50  sg=1  OUT-OUT","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=50</td>\n      <td>sg=0</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>word2vec</td>\n      <td>size=200</td>\n      <td>window=5</td>\n      <td>sg=1</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>word2vec</td>\n      <td>size=300</td>\n      <td>window=5</td>\n      <td>sg=0</td>\n      <td>OUT-OUT</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>IN-IN</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>IN-OUT</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>OUT-IN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>word2vec</td>\n      <td>size=100</td>\n      <td>window=50</td>\n      <td>sg=1</td>\n      <td>OUT-OUT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00052-feeb23a4-7f5b-42a9-bc00-f26bc6d2117c"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Appendix","metadata":{"tags":[],"cell_id":"00054-e9276a1d-bbea-4496-8e76-fe3b2576891f"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00055-c2bfb316-b5f7-41c3-8ec7-ed99b835115f","output_cleared":false},"source":"!pip install colabcode","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting colabcode\n  Downloading colabcode-0.0.8-py3-none-any.whl (4.5 kB)\nCollecting pyngrok>=4.1.11\n  Downloading pyngrok-4.1.12.tar.gz (18 kB)\nCollecting future\n  Downloading future-0.18.2.tar.gz (829 kB)\n\u001b[K     |████████████████████████████████| 829 kB 5.0 MB/s eta 0:00:01\n\u001b[?25hCollecting PyYAML\n  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n\u001b[K     |████████████████████████████████| 269 kB 13.6 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyngrok, future, PyYAML\n  Building wheel for pyngrok (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyngrok: filename=pyngrok-4.1.12-py3-none-any.whl size=16808 sha256=9aaf8aaa414f24a441f7e518f244ac9d268f7806d27e944dda9d07953c329aef\n  Stored in directory: /home/jovyan/.cache/pip/wheels/c5/e6/f4/ed442f176b61127deccd76cf0d7615e13d99ec6b162dd36f5d\n  Building wheel for future (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=0dc886b43a8e680be6ff0f11781d2628ed0c812c49a76c3a535b59b112492560\n  Stored in directory: /home/jovyan/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=7dde14d9186a732c97d0b920f455d52bcfb918fd6e08b0f2c0cb9c32778c4e95\n  Stored in directory: /home/jovyan/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\nSuccessfully built pyngrok future PyYAML\nInstalling collected packages: future, PyYAML, pyngrok, colabcode\nSuccessfully installed PyYAML-5.3.1 colabcode-0.0.8 future-0.18.2 pyngrok-4.1.12\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00056-381d8f69-8e3e-4821-adca-197bf5313206","output_cleared":false},"source":"from colabcode import ColabCode\nColabCode(port=10000, password=\"mohit\")","execution_count":null,"outputs":[{"name":"stdout","text":"Code Server can be accessed on: https://dd467acbbfba.ngrok.io                                       \n[2020-09-13T08:13:42.784Z] info  Using config file ~/.config/code-server/config.yaml\n[2020-09-13T08:13:43.233Z] info  Using user-data-dir ~/.local/share/code-server\n[2020-09-13T08:13:43.245Z] info  code-server 3.5.0 de41646fc402b968ca6d555fdf2da7de9554d28a\n[2020-09-13T08:13:43.251Z] info  HTTP server listening on http://127.0.0.1:10000\n[2020-09-13T08:13:43.252Z] info      - Using password from $PASSWORD\n[2020-09-13T08:13:43.252Z] info      - To disable use `--auth none`\n[2020-09-13T08:13:43.252Z] info    - Not serving HTTPS\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-230620763635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolabcode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColabCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mColabCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mohit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/colabcode/code.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, port, password, mount_drive)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_install_extensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_install_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/colabcode/code.py\u001b[0m in \u001b[0;36m_run_code\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0muniversal_newlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         ) as proc:\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00057-5c8978a8-4587-4c8f-83b1-2a51cc2c2073"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"ee79aacb-fd8f-4052-af8b-c77445857e56","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}}}